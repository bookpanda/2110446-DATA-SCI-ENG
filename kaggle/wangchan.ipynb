{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T17:07:37.611549Z",
     "iopub.status.busy": "2025-02-11T17:07:37.611196Z",
     "iopub.status.idle": "2025-02-11T17:07:55.816510Z",
     "shell.execute_reply": "2025-02-11T17:07:55.815527Z",
     "shell.execute_reply.started": "2025-02-11T17:07:37.611501Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for tokenizers \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[159 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-universal2-cpython-312/tokenizers\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/__init__.py -> build/lib.macosx-10.9-universal2-cpython-312/tokenizers\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-universal2-cpython-312/tokenizers/models\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/models/__init__.py -> build/lib.macosx-10.9-universal2-cpython-312/tokenizers/models\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-universal2-cpython-312/tokenizers/decoders\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/decoders/__init__.py -> build/lib.macosx-10.9-universal2-cpython-312/tokenizers/decoders\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-universal2-cpython-312/tokenizers/normalizers\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/normalizers/__init__.py -> build/lib.macosx-10.9-universal2-cpython-312/tokenizers/normalizers\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-universal2-cpython-312/tokenizers/pre_tokenizers\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/pre_tokenizers/__init__.py -> build/lib.macosx-10.9-universal2-cpython-312/tokenizers/pre_tokenizers\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-universal2-cpython-312/tokenizers/processors\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/processors/__init__.py -> build/lib.macosx-10.9-universal2-cpython-312/tokenizers/processors\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-universal2-cpython-312/tokenizers/trainers\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/trainers/__init__.py -> build/lib.macosx-10.9-universal2-cpython-312/tokenizers/trainers\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-universal2-cpython-312/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/implementations/byte_level_bpe.py -> build/lib.macosx-10.9-universal2-cpython-312/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/implementations/sentencepiece_unigram.py -> build/lib.macosx-10.9-universal2-cpython-312/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/implementations/sentencepiece_bpe.py -> build/lib.macosx-10.9-universal2-cpython-312/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/implementations/base_tokenizer.py -> build/lib.macosx-10.9-universal2-cpython-312/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/implementations/__init__.py -> build/lib.macosx-10.9-universal2-cpython-312/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/implementations/char_level_bpe.py -> build/lib.macosx-10.9-universal2-cpython-312/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/implementations/bert_wordpiece.py -> build/lib.macosx-10.9-universal2-cpython-312/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-universal2-cpython-312/tokenizers/tools\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/tools/__init__.py -> build/lib.macosx-10.9-universal2-cpython-312/tokenizers/tools\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/tools/visualizer.py -> build/lib.macosx-10.9-universal2-cpython-312/tokenizers/tools\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/__init__.pyi -> build/lib.macosx-10.9-universal2-cpython-312/tokenizers\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/models/__init__.pyi -> build/lib.macosx-10.9-universal2-cpython-312/tokenizers/models\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/decoders/__init__.pyi -> build/lib.macosx-10.9-universal2-cpython-312/tokenizers/decoders\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/normalizers/__init__.pyi -> build/lib.macosx-10.9-universal2-cpython-312/tokenizers/normalizers\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/pre_tokenizers/__init__.pyi -> build/lib.macosx-10.9-universal2-cpython-312/tokenizers/pre_tokenizers\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/processors/__init__.pyi -> build/lib.macosx-10.9-universal2-cpython-312/tokenizers/processors\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/trainers/__init__.pyi -> build/lib.macosx-10.9-universal2-cpython-312/tokenizers/trainers\n",
      "  \u001b[31m   \u001b[0m copying py_src/tokenizers/tools/visualizer-styles.css -> build/lib.macosx-10.9-universal2-cpython-312/tokenizers/tools\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m running build_rust\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[32m    Updating\u001b[0m crates.io index\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[32m     Locking\u001b[0m 302 packages to latest compatible versions\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m aho-corasick v0.7.20 \u001b[1m\u001b[33m(latest: v1.1.3)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m base64 v0.13.1 \u001b[1m\u001b[33m(latest: v0.22.1)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m base64 v0.21.7 \u001b[1m\u001b[33m(latest: v0.22.1)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m bitflags v1.3.2 \u001b[1m\u001b[33m(latest: v2.8.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m bzip2 v0.4.4 \u001b[1m\u001b[33m(latest: v0.5.1)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m constant_time_eq v0.1.5 \u001b[1m\u001b[33m(latest: v0.4.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m core-foundation v0.9.4 \u001b[1m\u001b[33m(latest: v0.10.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m darling v0.14.4 \u001b[1m\u001b[33m(latest: v0.20.10)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m darling_core v0.14.4 \u001b[1m\u001b[33m(latest: v0.20.10)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m darling_macro v0.14.4 \u001b[1m\u001b[33m(latest: v0.20.10)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m derive_builder v0.12.0 \u001b[1m\u001b[33m(latest: v0.20.2)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m derive_builder_core v0.12.0 \u001b[1m\u001b[33m(latest: v0.20.2)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m derive_builder_macro v0.12.0 \u001b[1m\u001b[33m(latest: v0.20.2)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m dirs v4.0.0 \u001b[1m\u001b[33m(latest: v6.0.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m dirs-sys v0.3.7 \u001b[1m\u001b[33m(latest: v0.5.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m env_logger v0.7.1 \u001b[1m\u001b[33m(latest: v0.11.6)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m foreign-types v0.3.2 \u001b[1m\u001b[33m(latest: v0.5.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m foreign-types-shared v0.1.1 \u001b[1m\u001b[33m(latest: v0.3.1)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m generic-array v0.14.7 \u001b[1m\u001b[33m(latest: v1.2.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m getrandom v0.2.15 \u001b[1m\u001b[33m(latest: v0.3.1)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m h2 v0.3.26 \u001b[1m\u001b[33m(latest: v0.4.8)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m hermit-abi v0.1.19 \u001b[1m\u001b[33m(latest: v0.4.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m http v0.2.12 \u001b[1m\u001b[33m(latest: v1.2.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m http-body v0.4.6 \u001b[1m\u001b[33m(latest: v1.0.1)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m humantime v1.3.0 \u001b[1m\u001b[33m(latest: v2.1.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m hyper v0.14.32 \u001b[1m\u001b[33m(latest: v1.6.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m hyper-tls v0.5.0 \u001b[1m\u001b[33m(latest: v0.6.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m indicatif v0.15.0 \u001b[1m\u001b[33m(latest: v0.17.11)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m indicatif v0.16.2 \u001b[1m\u001b[33m(latest: v0.17.11)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m indoc v1.0.9 \u001b[1m\u001b[33m(latest: v2.0.5)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m itertools v0.8.2 \u001b[1m\u001b[33m(latest: v0.14.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m itertools v0.9.0 \u001b[1m\u001b[33m(latest: v0.14.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m linux-raw-sys v0.4.15 \u001b[1m\u001b[33m(latest: v0.9.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m macro_rules_attribute v0.1.3 \u001b[1m\u001b[33m(latest: v0.2.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m macro_rules_attribute-proc_macro v0.1.3 \u001b[1m\u001b[33m(latest: v0.2.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m matrixmultiply v0.2.4 \u001b[1m\u001b[33m(latest: v0.3.9)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m memoffset v0.8.0 \u001b[1m\u001b[33m(latest: v0.9.1)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m ndarray v0.13.1 \u001b[1m\u001b[33m(latest: v0.16.1)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m ndarray v0.15.6 \u001b[1m\u001b[33m(latest: v0.16.1)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m nom v7.1.3 \u001b[1m\u001b[33m(latest: v8.0.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m num-complex v0.2.4 \u001b[1m\u001b[33m(latest: v0.4.6)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m number_prefix v0.3.0 \u001b[1m\u001b[33m(latest: v0.4.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m numpy v0.18.0 \u001b[1m\u001b[33m(latest: v0.23.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m password-hash v0.4.2 \u001b[1m\u001b[33m(latest: v0.5.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m pbkdf2 v0.11.0 \u001b[1m\u001b[33m(latest: v0.12.2)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m pyo3 v0.18.3 \u001b[1m\u001b[33m(latest: v0.23.5)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m pyo3-build-config v0.18.3 \u001b[1m\u001b[33m(latest: v0.23.5)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m pyo3-ffi v0.18.3 \u001b[1m\u001b[33m(latest: v0.23.5)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m pyo3-macros v0.18.3 \u001b[1m\u001b[33m(latest: v0.23.5)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m pyo3-macros-backend v0.18.3 \u001b[1m\u001b[33m(latest: v0.23.5)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m quick-error v1.2.3 \u001b[1m\u001b[33m(latest: v2.0.1)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m rand v0.8.5 \u001b[1m\u001b[33m(latest: v0.9.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m rand_chacha v0.3.1 \u001b[1m\u001b[33m(latest: v0.9.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m rand_core v0.6.4 \u001b[1m\u001b[33m(latest: v0.9.2)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m rayon-cond v0.1.0 \u001b[1m\u001b[33m(latest: v0.3.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m redox_users v0.4.6 \u001b[1m\u001b[33m(latest: v0.5.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m regex-syntax v0.6.29 \u001b[1m\u001b[33m(latest: v0.8.5)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m reqwest v0.11.27 \u001b[1m\u001b[33m(latest: v0.12.12)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m rustc-hash v1.1.0 \u001b[1m\u001b[33m(latest: v2.1.1)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m rustls-pemfile v1.0.4 \u001b[1m\u001b[33m(latest: v2.2.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m security-framework v2.11.1 \u001b[1m\u001b[33m(latest: v3.2.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m strsim v0.10.0 \u001b[1m\u001b[33m(latest: v0.11.1)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m syn v1.0.109 \u001b[1m\u001b[33m(latest: v2.0.98)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m sync_wrapper v0.1.2 \u001b[1m\u001b[33m(latest: v1.0.2)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m system-configuration v0.5.1 \u001b[1m\u001b[33m(latest: v0.6.1)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m system-configuration-sys v0.5.0 \u001b[1m\u001b[33m(latest: v0.6.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m target-lexicon v0.12.16 \u001b[1m\u001b[33m(latest: v0.13.2)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m thiserror v1.0.69 \u001b[1m\u001b[33m(latest: v2.0.11)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m thiserror-impl v1.0.69 \u001b[1m\u001b[33m(latest: v2.0.11)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m tinystr v0.7.6 \u001b[1m\u001b[33m(latest: v0.8.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m unindent v0.1.11 \u001b[1m\u001b[33m(latest: v0.2.3)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m wasi v0.11.0+wasi-snapshot-preview1 \u001b[1m\u001b[33m(latest: v0.14.1+wasi-0.2.3)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m wasi v0.13.3+wasi-0.2.2 \u001b[1m\u001b[33m(latest: v0.14.1+wasi-0.2.3)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m windows-sys v0.48.0 \u001b[1m\u001b[33m(latest: v0.59.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m windows-sys v0.52.0 \u001b[1m\u001b[33m(latest: v0.59.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m windows-targets v0.48.5 \u001b[1m\u001b[33m(latest: v0.53.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m windows-targets v0.52.6 \u001b[1m\u001b[33m(latest: v0.53.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m windows_aarch64_gnullvm v0.48.5 \u001b[1m\u001b[33m(latest: v0.53.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m windows_aarch64_gnullvm v0.52.6 \u001b[1m\u001b[33m(latest: v0.53.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m windows_aarch64_msvc v0.48.5 \u001b[1m\u001b[33m(latest: v0.53.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m windows_aarch64_msvc v0.52.6 \u001b[1m\u001b[33m(latest: v0.53.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m windows_i686_gnu v0.48.5 \u001b[1m\u001b[33m(latest: v0.53.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m windows_i686_gnu v0.52.6 \u001b[1m\u001b[33m(latest: v0.53.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m windows_i686_gnullvm v0.52.6 \u001b[1m\u001b[33m(latest: v0.53.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m windows_i686_msvc v0.48.5 \u001b[1m\u001b[33m(latest: v0.53.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m windows_i686_msvc v0.52.6 \u001b[1m\u001b[33m(latest: v0.53.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m windows_x86_64_gnu v0.48.5 \u001b[1m\u001b[33m(latest: v0.53.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m windows_x86_64_gnu v0.52.6 \u001b[1m\u001b[33m(latest: v0.53.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m windows_x86_64_gnullvm v0.48.5 \u001b[1m\u001b[33m(latest: v0.53.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m windows_x86_64_gnullvm v0.52.6 \u001b[1m\u001b[33m(latest: v0.53.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m windows_x86_64_msvc v0.48.5 \u001b[1m\u001b[33m(latest: v0.53.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m windows_x86_64_msvc v0.52.6 \u001b[1m\u001b[33m(latest: v0.53.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m winreg v0.50.0 \u001b[1m\u001b[33m(latest: v0.55.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m wit-bindgen-rt v0.33.0 \u001b[1m\u001b[33m(latest: v0.39.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m writeable v0.5.5 \u001b[1m\u001b[33m(latest: v0.6.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m zerocopy v0.7.35 \u001b[1m\u001b[33m(latest: v0.8.20)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m zerocopy-derive v0.7.35 \u001b[1m\u001b[33m(latest: v0.8.20)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m zerovec v0.10.4 \u001b[1m\u001b[33m(latest: v0.11.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m zerovec-derive v0.10.3 \u001b[1m\u001b[33m(latest: v0.11.0)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m zip v0.6.6 \u001b[1m\u001b[33m(latest: v2.2.3)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m zstd v0.11.2+zstd.1.5.2 \u001b[1m\u001b[33m(latest: v0.13.3)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[36m      Adding\u001b[0m zstd-safe v5.0.2+zstd.1.5.2 \u001b[1m\u001b[33m(latest: v7.2.3)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1m\u001b[31merror\u001b[0m\u001b[1m:\u001b[0m failed to download `base64ct v1.7.0`\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Caused by:\n",
      "  \u001b[31m   \u001b[0m   unable to get packages from source\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Caused by:\n",
      "  \u001b[31m   \u001b[0m   failed to parse manifest at `/Users/idhibhatpankam/.cargo/registry/src/index.crates.io-6f17d22bba15001f/base64ct-1.7.0/Cargo.toml`\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Caused by:\n",
      "  \u001b[31m   \u001b[0m   feature `edition2024` is required\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m   The package requires the Cargo feature called `edition2024`, but that feature is not stabilized in this version of Cargo (1.82.0 (8f40fc59f 2024-08-21)).\n",
      "  \u001b[31m   \u001b[0m   Consider trying a newer version of Cargo (this may require the nightly release).\n",
      "  \u001b[31m   \u001b[0m   See https://doc.rust-lang.org/nightly/cargo/reference/unstable.html#edition-2024 for more information about the status of this feature.\n",
      "  \u001b[31m   \u001b[0m error: `cargo metadata --manifest-path Cargo.toml --format-version 1` failed with code 101\n",
      "  \u001b[31m   \u001b[0m -- Output captured from stdout:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for tokenizers\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (tokenizers)\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: peft==0.10.0 in /Users/idhibhatpankam/Code/courses/DATA-SCI/.venv/lib/python3.12/site-packages (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/idhibhatpankam/Code/courses/DATA-SCI/.venv/lib/python3.12/site-packages (from peft==0.10.0) (2.2.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/idhibhatpankam/Code/courses/DATA-SCI/.venv/lib/python3.12/site-packages (from peft==0.10.0) (24.2)\n",
      "Requirement already satisfied: psutil in /Users/idhibhatpankam/Code/courses/DATA-SCI/.venv/lib/python3.12/site-packages (from peft==0.10.0) (6.1.1)\n",
      "Requirement already satisfied: pyyaml in /Users/idhibhatpankam/Code/courses/DATA-SCI/.venv/lib/python3.12/site-packages (from peft==0.10.0) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /Users/idhibhatpankam/Code/courses/DATA-SCI/.venv/lib/python3.12/site-packages (from peft==0.10.0) (2.5.1)\n",
      "Requirement already satisfied: transformers in /Users/idhibhatpankam/Code/courses/DATA-SCI/.venv/lib/python3.12/site-packages (from peft==0.10.0) (4.49.0)\n",
      "Requirement already satisfied: tqdm in /Users/idhibhatpankam/Code/courses/DATA-SCI/.venv/lib/python3.12/site-packages (from peft==0.10.0) (4.67.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /Users/idhibhatpankam/Code/courses/DATA-SCI/.venv/lib/python3.12/site-packages (from peft==0.10.0) (1.4.0)\n",
      "Requirement already satisfied: safetensors in /Users/idhibhatpankam/Code/courses/DATA-SCI/.venv/lib/python3.12/site-packages (from peft==0.10.0) (0.5.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /Users/idhibhatpankam/Code/courses/DATA-SCI/.venv/lib/python3.12/site-packages (from peft==0.10.0) (0.27.1)\n",
      "Requirement already satisfied: filelock in /Users/idhibhatpankam/Code/courses/DATA-SCI/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/idhibhatpankam/Code/courses/DATA-SCI/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (2024.12.0)\n",
      "Requirement already satisfied: requests in /Users/idhibhatpankam/Code/courses/DATA-SCI/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/idhibhatpankam/Code/courses/DATA-SCI/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Users/idhibhatpankam/Code/courses/DATA-SCI/.venv/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.10.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/idhibhatpankam/Code/courses/DATA-SCI/.venv/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.10.0) (3.1.5)\n",
      "Requirement already satisfied: setuptools in /Users/idhibhatpankam/Code/courses/DATA-SCI/.venv/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.10.0) (75.7.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/idhibhatpankam/Code/courses/DATA-SCI/.venv/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.10.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/idhibhatpankam/Code/courses/DATA-SCI/.venv/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.13.0->peft==0.10.0) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/idhibhatpankam/Code/courses/DATA-SCI/.venv/lib/python3.12/site-packages (from transformers->peft==0.10.0) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/idhibhatpankam/Code/courses/DATA-SCI/.venv/lib/python3.12/site-packages (from transformers->peft==0.10.0) (0.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/idhibhatpankam/Code/courses/DATA-SCI/.venv/lib/python3.12/site-packages (from jinja2->torch>=1.13.0->peft==0.10.0) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/idhibhatpankam/Code/courses/DATA-SCI/.venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/idhibhatpankam/Code/courses/DATA-SCI/.venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/idhibhatpankam/Code/courses/DATA-SCI/.venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/idhibhatpankam/Code/courses/DATA-SCI/.venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (2024.12.14)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q  transformers==4.30.1 datasets evaluate thaixtransformers\n",
    "!pip install peft==0.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T17:10:23.519606Z",
     "iopub.status.busy": "2025-02-11T17:10:23.519176Z",
     "iopub.status.idle": "2025-02-11T17:10:23.526215Z",
     "shell.execute_reply": "2025-02-11T17:10:23.525590Z",
     "shell.execute_reply.started": "2025-02-11T17:10:23.519574Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from IPython.display import display\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T17:09:11.932222Z",
     "iopub.status.busy": "2025-02-11T17:09:11.931938Z",
     "iopub.status.idle": "2025-02-11T17:09:12.313384Z",
     "shell.execute_reply": "2025-02-11T17:09:12.312531Z",
     "shell.execute_reply.started": "2025-02-11T17:09:11.932200Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/idhibhatpankam/Code/courses/DATA-SCI/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "The `notebook_login` function can only be used in a notebook (Jupyter or Colab) and you need the `ipywidgets` module: `pip install ipywidgets`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/Code/courses/DATA-SCI/.venv/lib/python3.12/site-packages/huggingface_hub/_login.py:340\u001b[0m, in \u001b[0;36mnotebook_login\u001b[0;34m(new_session, write_permission)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mipywidgets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwidgets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwidgets\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m display  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ipywidgets'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m notebook_login\n\u001b[0;32m----> 3\u001b[0m \u001b[43mnotebook_login\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/courses/DATA-SCI/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:101\u001b[0m, in \u001b[0;36m_deprecate_arguments.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m         message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m custom_message\n\u001b[1;32m    100\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/courses/DATA-SCI/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:31\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m extra_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[1;32m     33\u001b[0m args_msg \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[38;5;241m-\u001b[39mextra_args:])\n\u001b[1;32m     36\u001b[0m ]\n",
      "File \u001b[0;32m~/Code/courses/DATA-SCI/.venv/lib/python3.12/site-packages/huggingface_hub/_login.py:343\u001b[0m, in \u001b[0;36mnotebook_login\u001b[0;34m(new_session, write_permission)\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m display  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m--> 343\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m    344\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `notebook_login` function can only be used in a notebook (Jupyter or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    345\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Colab) and you need the `ipywidgets` module: `pip install ipywidgets`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    346\u001b[0m     )\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m new_session \u001b[38;5;129;01mand\u001b[39;00m get_token() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser is already logged in.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: The `notebook_login` function can only be used in a notebook (Jupyter or Colab) and you need the `ipywidgets` module: `pip install ipywidgets`."
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>สำนักงานตำรวจแห่งชาติ</th>\n",
       "      <th>การรถไฟฟ้าขนส่งมวลชนแห่งประเทศไทย</th>\n",
       "      <th>สภาเด็กและเยาวชนกรุงเทพมหานคร</th>\n",
       "      <th>กรมควบคุมมลพิษ</th>\n",
       "      <th>กรมสรรพสามิต</th>\n",
       "      <th>การไฟฟ้านครหลวง</th>\n",
       "      <th>กรมทางหลวง</th>\n",
       "      <th>สำนักงานประกันสุขภาพแห่งชาติ</th>\n",
       "      <th>การประปานครหลวง</th>\n",
       "      <th>คณะกรรมการการพัฒนาเศรษฐกิจ</th>\n",
       "      <th>กระทรวงการท่องเที่ยวและกีฬา</th>\n",
       "      <th>สำนักงาน กสทช. ศูนย์รับแจ้งปัญหา 1200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>บริเวณนราธิวาส  แยกถนนจันทน์ ใกล้สวนสาธารณะช่อ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>บริเวณสะพานสามถนนจันทน์ เป็นจุดเปลี่ยนถ่ายสองแ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>เรื่องทางม้าลายหายไป บริเวณสี่แยกถนนจันทร์-เซน...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ปัญหาน้ำท่วมในซอยสวนพลู 1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1. ซ่อมสายไฟ กรีดขวางทางเท้า</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            comment  \\\n",
       "0   0  บริเวณนราธิวาส  แยกถนนจันทน์ ใกล้สวนสาธารณะช่อ...   \n",
       "1   1  บริเวณสะพานสามถนนจันทน์ เป็นจุดเปลี่ยนถ่ายสองแ...   \n",
       "2   2  เรื่องทางม้าลายหายไป บริเวณสี่แยกถนนจันทร์-เซน...   \n",
       "3   3                          ปัญหาน้ำท่วมในซอยสวนพลู 1   \n",
       "4   4                       1. ซ่อมสายไฟ กรีดขวางทางเท้า   \n",
       "\n",
       "   สำนักงานตำรวจแห่งชาติ  การรถไฟฟ้าขนส่งมวลชนแห่งประเทศไทย  \\\n",
       "0                      0                                  0   \n",
       "1                      0                                  0   \n",
       "2                      0                                  0   \n",
       "3                      0                                  0   \n",
       "4                      0                                  0   \n",
       "\n",
       "   สภาเด็กและเยาวชนกรุงเทพมหานคร  กรมควบคุมมลพิษ  กรมสรรพสามิต  \\\n",
       "0                              0               0             0   \n",
       "1                              0               0             0   \n",
       "2                              0               0             0   \n",
       "3                              0               0             0   \n",
       "4                              0               0             0   \n",
       "\n",
       "   การไฟฟ้านครหลวง  กรมทางหลวง  สำนักงานประกันสุขภาพแห่งชาติ  การประปานครหลวง  \\\n",
       "0                0           0                             0                0   \n",
       "1                0           0                             0                0   \n",
       "2                0           0                             0                0   \n",
       "3                0           0                             0                0   \n",
       "4                0           0                             0                0   \n",
       "\n",
       "   คณะกรรมการการพัฒนาเศรษฐกิจ  กระทรวงการท่องเที่ยวและกีฬา  \\\n",
       "0                           0                            0   \n",
       "1                           0                            0   \n",
       "2                           0                            0   \n",
       "3                           0                            0   \n",
       "4                           0                            0   \n",
       "\n",
       "   สำนักงาน กสทช. ศูนย์รับแจ้งปัญหา 1200  \n",
       "0                                      0  \n",
       "1                                      0  \n",
       "2                                      0  \n",
       "3                                      0  \n",
       "4                                      0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>สำนักงานตำรวจแห่งชาติ</th>\n",
       "      <th>การรถไฟฟ้าขนส่งมวลชนแห่งประเทศไทย</th>\n",
       "      <th>สภาเด็กและเยาวชนกรุงเทพมหานคร</th>\n",
       "      <th>กรมควบคุมมลพิษ</th>\n",
       "      <th>กรมสรรพสามิต</th>\n",
       "      <th>การไฟฟ้านครหลวง</th>\n",
       "      <th>กรมทางหลวง</th>\n",
       "      <th>สำนักงานประกันสุขภาพแห่งชาติ</th>\n",
       "      <th>การประปานครหลวง</th>\n",
       "      <th>คณะกรรมการการพัฒนาเศรษฐกิจ</th>\n",
       "      <th>กระทรวงการท่องเที่ยวและกีฬา</th>\n",
       "      <th>สำนักงาน กสทช. ศูนย์รับแจ้งปัญหา 1200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>204622.000000</td>\n",
       "      <td>204622.000000</td>\n",
       "      <td>204622.000000</td>\n",
       "      <td>204622.000000</td>\n",
       "      <td>204622.000000</td>\n",
       "      <td>204622.000000</td>\n",
       "      <td>204622.000000</td>\n",
       "      <td>204622.000000</td>\n",
       "      <td>204622.000000</td>\n",
       "      <td>204622.000000</td>\n",
       "      <td>204622.000000</td>\n",
       "      <td>204622.000000</td>\n",
       "      <td>204622.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>102310.500000</td>\n",
       "      <td>0.209635</td>\n",
       "      <td>0.019969</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.016034</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.167944</td>\n",
       "      <td>0.034542</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.024176</td>\n",
       "      <td>0.018478</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.023839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>59069.427728</td>\n",
       "      <td>0.407049</td>\n",
       "      <td>0.139892</td>\n",
       "      <td>0.006991</td>\n",
       "      <td>0.125608</td>\n",
       "      <td>0.010829</td>\n",
       "      <td>0.373817</td>\n",
       "      <td>0.182616</td>\n",
       "      <td>0.020136</td>\n",
       "      <td>0.153597</td>\n",
       "      <td>0.134672</td>\n",
       "      <td>0.007658</td>\n",
       "      <td>0.152548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>51155.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>102310.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>153465.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>204621.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id  สำนักงานตำรวจแห่งชาติ  \\\n",
       "count  204622.000000          204622.000000   \n",
       "mean   102310.500000               0.209635   \n",
       "std     59069.427728               0.407049   \n",
       "min         0.000000               0.000000   \n",
       "25%     51155.250000               0.000000   \n",
       "50%    102310.500000               0.000000   \n",
       "75%    153465.750000               0.000000   \n",
       "max    204621.000000               1.000000   \n",
       "\n",
       "       การรถไฟฟ้าขนส่งมวลชนแห่งประเทศไทย  สภาเด็กและเยาวชนกรุงเทพมหานคร  \\\n",
       "count                      204622.000000                  204622.000000   \n",
       "mean                            0.019969                       0.000049   \n",
       "std                             0.139892                       0.006991   \n",
       "min                             0.000000                       0.000000   \n",
       "25%                             0.000000                       0.000000   \n",
       "50%                             0.000000                       0.000000   \n",
       "75%                             0.000000                       0.000000   \n",
       "max                             1.000000                       1.000000   \n",
       "\n",
       "       กรมควบคุมมลพิษ   กรมสรรพสามิต  การไฟฟ้านครหลวง     กรมทางหลวง  \\\n",
       "count   204622.000000  204622.000000    204622.000000  204622.000000   \n",
       "mean         0.016034       0.000117         0.167944       0.034542   \n",
       "std          0.125608       0.010829         0.373817       0.182616   \n",
       "min          0.000000       0.000000         0.000000       0.000000   \n",
       "25%          0.000000       0.000000         0.000000       0.000000   \n",
       "50%          0.000000       0.000000         0.000000       0.000000   \n",
       "75%          0.000000       0.000000         0.000000       0.000000   \n",
       "max          1.000000       1.000000         1.000000       1.000000   \n",
       "\n",
       "       สำนักงานประกันสุขภาพแห่งชาติ  การประปานครหลวง  \\\n",
       "count                 204622.000000    204622.000000   \n",
       "mean                       0.000406         0.024176   \n",
       "std                        0.020136         0.153597   \n",
       "min                        0.000000         0.000000   \n",
       "25%                        0.000000         0.000000   \n",
       "50%                        0.000000         0.000000   \n",
       "75%                        0.000000         0.000000   \n",
       "max                        1.000000         1.000000   \n",
       "\n",
       "       คณะกรรมการการพัฒนาเศรษฐกิจ  กระทรวงการท่องเที่ยวและกีฬา  \\\n",
       "count               204622.000000                204622.000000   \n",
       "mean                     0.018478                     0.000059   \n",
       "std                      0.134672                     0.007658   \n",
       "min                      0.000000                     0.000000   \n",
       "25%                      0.000000                     0.000000   \n",
       "50%                      0.000000                     0.000000   \n",
       "75%                      0.000000                     0.000000   \n",
       "max                      1.000000                     1.000000   \n",
       "\n",
       "       สำนักงาน กสทช. ศูนย์รับแจ้งปัญหา 1200  \n",
       "count                          204622.000000  \n",
       "mean                                0.023839  \n",
       "std                                 0.152548  \n",
       "min                                 0.000000  \n",
       "25%                                 0.000000  \n",
       "50%                                 0.000000  \n",
       "75%                                 0.000000  \n",
       "max                                 1.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before dropna: (204622, 14)\n",
      "After dropna: (204622, 14)\n",
      "Before dropna: (10810, 2)\n",
      "After dropna: (10810, 2)\n",
      "(204622, 14) (10810, 2)\n"
     ]
    }
   ],
   "source": [
    "def drop_rows(df):\n",
    "    # drop rows with missing values, duplicates\n",
    "    print(f\"Before dropna: {df.shape}\")\n",
    "    df.dropna(inplace=True)\n",
    "    df.drop_duplicates(\"comment\", keep=\"first\", inplace=True)\n",
    "    df = df.reset_index(drop=True)\n",
    "    print(f\"After dropna: {df.shape}\")\n",
    "\n",
    "drop_rows(train_df)\n",
    "drop_rows(test_df)\n",
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contacts = train_df.columns[2:]\n",
    "train_df['label'] = train_df[contacts].apply(lambda x: list(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>บริเวณนราธิวาส  แยกถนนจันทน์ ใกล้สวนสาธารณะช่อ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>บริเวณสะพานสามถนนจันทน์ เป็นจุดเปลี่ยนถ่ายสองแ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>เรื่องทางม้าลายหายไป บริเวณสี่แยกถนนจันทร์-เซน...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ปัญหาน้ำท่วมในซอยสวนพลู 1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1. ซ่อมสายไฟ กรีดขวางทางเท้า</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  \\\n",
       "0  บริเวณนราธิวาส  แยกถนนจันทน์ ใกล้สวนสาธารณะช่อ...   \n",
       "1  บริเวณสะพานสามถนนจันทน์ เป็นจุดเปลี่ยนถ่ายสองแ...   \n",
       "2  เรื่องทางม้าลายหายไป บริเวณสี่แยกถนนจันทร์-เซน...   \n",
       "3                          ปัญหาน้ำท่วมในซอยสวนพลู 1   \n",
       "4                       1. ซ่อมสายไฟ กรีดขวางทางเท้า   \n",
       "\n",
       "                                  label  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.drop(contacts, axis=1, inplace=True)\n",
    "train_df.drop(\"id\", axis=1, inplace=True)\n",
    "test_df.drop(\"id\", axis=1, inplace=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]    102333\n",
       "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]     42212\n",
       "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]     32543\n",
       "[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]      5803\n",
       "[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]      4598\n",
       "                                         ...  \n",
       "[1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1]         1\n",
       "[1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0]         1\n",
       "[1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0]         1\n",
       "[1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0]         1\n",
       "[0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]         1\n",
       "Name: count, Length: 73, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['สำนักงานตำรวจแห่งชาติ', 'การรถไฟฟ้าขนส่งมวลชนแห่งประเทศไทย',\n",
       "       'สภาเด็กและเยาวชนกรุงเทพมหานคร', 'กรมควบคุมมลพิษ', 'กรมสรรพสามิต',\n",
       "       'การไฟฟ้านครหลวง', 'กรมทางหลวง', 'สำนักงานประกันสุขภาพแห่งชาติ',\n",
       "       'การประปานครหลวง', 'คณะกรรมการการพัฒนาเศรษฐกิจ',\n",
       "       'กระทรวงการท่องเที่ยวและกีฬา', 'สำนักงาน กสทช. ศูนย์รับแจ้งปัญหา 1200'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T17:40:11.919501Z",
     "iopub.status.busy": "2025-02-11T17:40:11.919167Z",
     "iopub.status.idle": "2025-02-11T17:40:11.933175Z",
     "shell.execute_reply": "2025-02-11T17:40:11.932377Z",
     "shell.execute_reply.started": "2025-02-11T17:40:11.919466Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Mappings\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 'สำนักงานตำรวจแห่งชาติ',\n",
       " 1: 'การรถไฟฟ้าขนส่งมวลชนแห่งประเทศไทย',\n",
       " 2: 'สภาเด็กและเยาวชนกรุงเทพมหานคร',\n",
       " 3: 'กรมควบคุมมลพิษ',\n",
       " 4: 'กรมสรรพสามิต',\n",
       " 5: 'การไฟฟ้านครหลวง',\n",
       " 6: 'กรมทางหลวง',\n",
       " 7: 'สำนักงานประกันสุขภาพแห่งชาติ',\n",
       " 8: 'การประปานครหลวง',\n",
       " 9: 'คณะกรรมการการพัฒนาเศรษฐกิจ',\n",
       " 10: 'กระทรวงการท่องเที่ยวและกีฬา',\n",
       " 11: 'สำนักงาน กสทช. ศูนย์รับแจ้งปัญหา 1200'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'สำนักงานตำรวจแห่งชาติ': 0,\n",
       " 'การรถไฟฟ้าขนส่งมวลชนแห่งประเทศไทย': 1,\n",
       " 'สภาเด็กและเยาวชนกรุงเทพมหานคร': 2,\n",
       " 'กรมควบคุมมลพิษ': 3,\n",
       " 'กรมสรรพสามิต': 4,\n",
       " 'การไฟฟ้านครหลวง': 5,\n",
       " 'กรมทางหลวง': 6,\n",
       " 'สำนักงานประกันสุขภาพแห่งชาติ': 7,\n",
       " 'การประปานครหลวง': 8,\n",
       " 'คณะกรรมการการพัฒนาเศรษฐกิจ': 9,\n",
       " 'กระทรวงการท่องเที่ยวและกีฬา': 10,\n",
       " 'สำนักงาน กสทช. ศูนย์รับแจ้งปัญหา 1200': 11}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = train_df.copy().to_numpy()\n",
    "\n",
    "label_2_num_map = dict(zip(contacts, range(len(contacts))))\n",
    "num_2_label_map = dict(zip(range(len(contacts)), contacts))\n",
    "\n",
    "print(\"Create Mappings\")\n",
    "display(num_2_label_map)\n",
    "display(label_2_num_map)\n",
    "\n",
    "# print(\"Before Mappings\")\n",
    "# display(data[:, 1])\n",
    "# data[:,1] = np.vectorize(label_2_num_map.get)(data[:,1])\n",
    "# print(\"After Mappings\")\n",
    "# display(data[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['บริเวณนราธิวาส  แยกถนนจันทน์ ใกล้สวนสาธารณะช่องนนทรี ทางเท้าเน่ามาก',\n",
       "        list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])],\n",
       "       ['บริเวณสะพานสามถนนจันทน์ เป็นจุดเปลี่ยนถ่ายสองแถวหลายสายมากมาย ทำให้สองแถวชอบจอดรอผู้โดยสาร และผู้โดยสารที่ต้องเปลี่ยนสายสองแถวก็จะมารอตรงนี้เช่นกัน ทำให้รถติด แต่ก็จำเป็นสำหรับคนในย่านมาก ถ้ามีการพัฒนาพื้นที่เปลี่ยนถ่ายให้ดี ลดการรบกวนจราจรแต่ยังตอบสนองวิถีชีวิตเดิมได้จะดีมาก',\n",
       "        list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])],\n",
       "       ['เรื่องทางม้าลายหายไป บริเวณสี่แยกถนนจันทร์-เซนต์หลุยส์',\n",
       "        list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])],\n",
       "       ...,\n",
       "       ['หมาจรในซอยเฉลิมพระเกียรติร.9 42 นี้ดุ วิ่งไล่กัดคนเดินผ่าน เดือดร้อนคนแถวนั้น',\n",
       "        list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])],\n",
       "       ['แท็กซี่จอดกีดขวางป้ายรถเมล์',\n",
       "        list([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])],\n",
       "       ['มีขอทานบนสะพานลอยหน้าโลตัสปิ่นเกล้า',\n",
       "        list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])]],\n",
       "      shape=(204622, 2), dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3 WangchanBERTa\n",
    "\n",
    "We ask you to train a WangchanBERTa-based model.\n",
    "\n",
    "We recommend you use the thaixtransformers fork (which we used in the PoS homework).\n",
    "https://github.com/PyThaiNLP/thaixtransformers\n",
    "\n",
    "The structure of the code will be very similar to the PoS homework. You will also find the huggingface [tutorial](https://huggingface.co/docs/transformers/en/tasks/sequence_classification) useful. Or you can also add a softmax layer by yourself just like in the previous homework.\n",
    "\n",
    "Which WangchanBERTa model will you use? Why? (Don't forget to clean your text accordingly).\n",
    "\n",
    "**Ans:**\n",
    "`airesearch/wangchanberta-base-att-spm-uncased` because it is suitable for text classification. It was train on these datasets for Multiclass text classification:\n",
    "- `wisesight_sentiment`: 4-class text classification task (positive, neutral, negative, and question) based on social media posts and tweets\n",
    "- `wongnai_reivews`: Users' review rating classification task (scale is ranging from 1 to 5)\n",
    "- `generated_reviews_enth`: Generated users' review rating classification task (scale is ranging from 1 to 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T17:59:18.118086Z",
     "iopub.status.busy": "2025-02-11T17:59:18.117771Z",
     "iopub.status.idle": "2025-02-11T17:59:18.122708Z",
     "shell.execute_reply": "2025-02-11T17:59:18.121859Z",
     "shell.execute_reply.started": "2025-02-11T17:59:18.118065Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'thaixtransformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LightningModule, Trainer\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Accuracy\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mthaixtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tokenizer\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mF\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'thaixtransformers'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline, DataCollatorWithPadding, AutoModel\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "from thaixtransformers import Tokenizer\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T17:49:00.938124Z",
     "iopub.status.busy": "2025-02-11T17:49:00.937771Z",
     "iopub.status.idle": "2025-02-11T17:49:01.101305Z",
     "shell.execute_reply": "2025-02-11T17:49:01.100362Z",
     "shell.execute_reply.started": "2025-02-11T17:49:00.938096Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'CamembertTokenizer'. \n",
      "The class this function is called from is 'WangchanbertaTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(\"airesearch/wangchanberta-base-att-spm-uncased\")\n",
    "tokenizer = Tokenizer(\"airesearch/wangchanberta-base-att-spm-uncased\")\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\"airesearch/wangchanberta-base-att-spm-uncased\")\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T17:40:18.606764Z",
     "iopub.status.busy": "2025-02-11T17:40:18.606194Z",
     "iopub.status.idle": "2025-02-11T17:40:18.613475Z",
     "shell.execute_reply": "2025-02-11T17:40:18.612523Z",
     "shell.execute_reply.started": "2025-02-11T17:40:18.606726Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [5, 10, 2856, 3, 265, 3, 265, 3, 1992, 8, 330, 28, 2753, 12, 8, 10, 3, 743, 2508, 3441, 8, 10, 3, 1276, 714, 8321, 110, 8, 3310, 2148, 14999, 8, 10, 1836, 4813, 11, 570, 8, 10, 177, 8, 9484, 2301, 2390, 5824, 204, 11545, 8, 10, 313, 2801, 11, 4573, 8, 10, 177, 6], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(data[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T17:40:21.220547Z",
     "iopub.status.busy": "2025-02-11T17:40:21.220170Z",
     "iopub.status.idle": "2025-02-11T17:40:23.523880Z",
     "shell.execute_reply": "2025-02-11T17:40:23.522926Z",
     "shell.execute_reply.started": "2025-02-11T17:40:21.220517Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13385it [00:02, 5829.12it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, sample in tqdm(enumerate(data)):\n",
    "    cleaned_sentence = sample[0].replace('ํา', \"ำ\") # only cleaning needed for WangchanBERTa\n",
    "    data[i, 0] = tokenizer(cleaned_sentence) # no padding as we will use DataCollatorWithPadding to pad within batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T17:40:24.385070Z",
     "iopub.status.busy": "2025-02-11T17:40:24.384788Z",
     "iopub.status.idle": "2025-02-11T17:40:24.390951Z",
     "shell.execute_reply": "2025-02-11T17:40:24.390012Z",
     "shell.execute_reply.started": "2025-02-11T17:40:24.385049Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13385,), (13385,))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data[:, 0]\n",
    "y = data[:, 1]\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T17:40:24.568933Z",
     "iopub.status.busy": "2025-02-11T17:40:24.568697Z",
     "iopub.status.idle": "2025-02-11T17:40:24.574189Z",
     "shell.execute_reply": "2025-02-11T17:40:24.573469Z",
     "shell.execute_reply.started": "2025-02-11T17:40:24.568913Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [5, 10, 2856, 3, 265, 3, 265, 3, 1992, 8, 330, 28, 2753, 12, 8, 10, 3, 743, 2508, 3441, 8, 10, 3, 1276, 714, 8321, 110, 8, 3310, 2148, 14999, 8, 10, 1836, 4813, 11, 570, 8, 10, 177, 8, 9484, 2301, 2390, 5824, 204, 11545, 8, 10, 313, 2801, 11, 4573, 8, 10, 177, 6], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T17:40:25.809932Z",
     "iopub.status.busy": "2025-02-11T17:40:25.809647Z",
     "iopub.status.idle": "2025-02-11T17:40:25.833882Z",
     "shell.execute_reply": "2025-02-11T17:40:25.833094Z",
     "shell.execute_reply.started": "2025-02-11T17:40:25.809911Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10708,) (10708,) (1338,) (1338,) (1339,) (1339,)\n"
     ]
    }
   ],
   "source": [
    "X_train: np.ndarray\n",
    "y_train: np.ndarray\n",
    "X_val: np.ndarray\n",
    "y_val: np.ndarray\n",
    "X_test: np.ndarray\n",
    "y_test: np.ndarray\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, stratify=y, test_size=0.2,random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, stratify=y_temp, test_size=0.5, random_state=42)\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T17:40:38.753236Z",
     "iopub.status.busy": "2025-02-11T17:40:38.752923Z",
     "iopub.status.idle": "2025-02-11T17:40:38.758751Z",
     "shell.execute_reply": "2025-02-11T17:40:38.757684Z",
     "shell.execute_reply.started": "2025-02-11T17:40:38.753214Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CallCenterDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {\n",
    "            key: torch.tensor(val) for key, val in self.encodings[idx].items()\n",
    "            if key in ['input_ids', 'attention_mask'] # take only input_ids and attention_mask fields\n",
    "        }\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T18:00:02.308472Z",
     "iopub.status.busy": "2025-02-11T18:00:02.308133Z",
     "iopub.status.idle": "2025-02-11T18:00:02.313469Z",
     "shell.execute_reply": "2025-02-11T18:00:02.312406Z",
     "shell.execute_reply.started": "2025-02-11T18:00:02.308447Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = CallCenterDataset(X_train, y_train)\n",
    "val_dataset = CallCenterDataset(X_val, y_val)\n",
    "test_dataset = CallCenterDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=data_collator)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, collate_fn=data_collator)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T18:05:22.110755Z",
     "iopub.status.busy": "2025-02-11T18:05:22.110363Z",
     "iopub.status.idle": "2025-02-11T18:05:22.117144Z",
     "shell.execute_reply": "2025-02-11T18:05:22.116193Z",
     "shell.execute_reply.started": "2025-02-11T18:05:22.110726Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   5,   10, 4811,    8,   10, 3240,    8,   10,  177, 7268, 4090,  879,\n",
       "           6])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset[0]['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T18:05:23.196708Z",
     "iopub.status.busy": "2025-02-11T18:05:23.196395Z",
     "iopub.status.idle": "2025-02-11T18:05:23.203198Z",
     "shell.execute_reply": "2025-02-11T18:05:23.202223Z",
     "shell.execute_reply.started": "2025-02-11T18:05:23.196686Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset[0]['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T18:00:08.376798Z",
     "iopub.status.busy": "2025-02-11T18:00:08.376469Z",
     "iopub.status.idle": "2025-02-11T18:00:08.383044Z",
     "shell.execute_reply": "2025-02-11T18:00:08.382007Z",
     "shell.execute_reply.started": "2025-02-11T18:00:08.376775Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BaseModel(LightningModule):\n",
    "    def __init__(\n",
    "          self,\n",
    "          model_name: str = 'airesearch/wangchanberta-base-att-spm-uncased',\n",
    "          learning_rate: float = 2e-5\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.encoder = AutoModel.from_pretrained(model_name)\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def get_embeddings(self, input_ids, attention_mask):\n",
    "        outputs = self.encoder(input_ids, attention_mask)\n",
    "        hidden_states = outputs.last_hidden_state\n",
    "\n",
    "        # [CLS] token is the first token in the sequence (index 0)\n",
    "        cls_embeddings = hidden_states[:, 0, :]  # [batch_size, hidden_size]\n",
    "        \n",
    "        return cls_embeddings\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        return self.get_embeddings(input_ids, attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T18:06:25.742175Z",
     "iopub.status.busy": "2025-02-11T18:06:25.741874Z",
     "iopub.status.idle": "2025-02-11T18:06:25.753015Z",
     "shell.execute_reply": "2025-02-11T18:06:25.752116Z",
     "shell.execute_reply.started": "2025-02-11T18:06:25.742152Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class LMWithLinearClassfier(BaseModel):\n",
    "    def __init__(\n",
    "          self,\n",
    "          model_name: str = 'airesearch/wangchanberta-base-att-spm-uncased',\n",
    "          ckpt_path: str = None,\n",
    "          learning_rate: float = 2e-5,\n",
    "          freeze_encoder_weights: bool = False\n",
    "    ):\n",
    "        super().__init__(\n",
    "            model_name,\n",
    "            learning_rate\n",
    "        )\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        if ckpt_path:\n",
    "            checkpoint = torch.load(ckpt_path)\n",
    "            encoder_state_dict = {k.replace(\"encoder.\", \"\"): v for k, v in checkpoint[\"state_dict\"].items() if k.startswith(\"encoder.\")}\n",
    "            self.encoder.load_state_dict(encoder_state_dict)\n",
    "\n",
    "        self.linear_layer = nn.Linear(768, 25)\n",
    "\n",
    "        if freeze_encoder_weights:\n",
    "          self.freeze_weights(self.encoder)  # Freeze model\n",
    "\n",
    "        self.accuracy = Accuracy(task='multiclass', num_classes=25)\n",
    "\n",
    "    def freeze_weights(self, model):\n",
    "        for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        cls_embeddings = self.get_embeddings(input_ids, attention_mask)\n",
    "        logits = self.linear_layer(cls_embeddings)\n",
    "        return logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "        logits = self.forward(input_ids, attention_mask)\n",
    "\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "\n",
    "        acc = self.accuracy(logits, labels)\n",
    "        self.log('train_acc', acc, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "        logits = self.forward(input_ids, attention_mask)\n",
    "\n",
    "        loss = F.binary_cross_entropy_with_logits(logits, labels)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "\n",
    "        acc = self.accuracy(logits, labels)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "        logits = self.forward(input_ids, attention_mask)\n",
    "\n",
    "        loss = F.binary_cross_entropy_with_logits(logits, labels)\n",
    "        self.log('test_loss', loss, prog_bar=True)\n",
    "\n",
    "        acc = self.accuracy(logits, labels)\n",
    "        self.log('test_acc', acc, prog_bar=True)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T18:59:27.283891Z",
     "iopub.status.busy": "2025-02-11T18:59:27.283548Z",
     "iopub.status.idle": "2025-02-11T18:59:28.511453Z",
     "shell.execute_reply": "2025-02-11T18:59:28.510775Z",
     "shell.execute_reply.started": "2025-02-11T18:59:27.283857Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at airesearch/wangchanberta-base-att-spm-uncased were not used when initializing CamembertModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing CamembertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = LMWithLinearClassfier(\n",
    "    'airesearch/wangchanberta-base-att-spm-uncased',\n",
    "    ckpt_path=None,\n",
    "    freeze_encoder_weights=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T18:59:30.458573Z",
     "iopub.status.busy": "2025-02-11T18:59:30.458210Z",
     "iopub.status.idle": "2025-02-11T18:59:30.504866Z",
     "shell.execute_reply": "2025-02-11T18:59:30.504146Z",
     "shell.execute_reply.started": "2025-02-11T18:59:30.458525Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    monitor=\"val_acc\",  # Metric to monitor\n",
    "    mode=\"max\",  # \"min\" for loss, \"max\" for accuracy\n",
    "    save_top_k=1,  # Save only the best model(s)\n",
    "    save_weights_only=True, # Saves only weights, not the entire model\n",
    "    dirpath=\"./checkpoints/\", # Path where the checkpoints will be saved\n",
    "    filename=\"best_pretrained_w_linear_model-{epoch}-{val_acc:.2f}\", # Customized name for the checkpoint\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "linear_trainer = Trainer(\n",
    "    max_epochs=5,\n",
    "    accelerator='auto',\n",
    "    callbacks=[checkpoint_callback], # Add the ModelCheckpoint callback\n",
    "    gradient_clip_val=1.0,\n",
    "    precision=16, # Mixed precision training\n",
    "    devices=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T18:59:34.253638Z",
     "iopub.status.busy": "2025-02-11T18:59:34.253290Z",
     "iopub.status.idle": "2025-02-11T19:03:04.460041Z",
     "shell.execute_reply": "2025-02-11T19:03:04.459239Z",
     "shell.execute_reply.started": "2025-02-11T18:59:34.253609Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "983b508e22d345c9bb3dd7093309c2a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 210.2021267414093\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# Train the model\n",
    "linear_trainer.fit(model, train_loader, val_loader)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Total time: {end_time - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T19:09:07.967475Z",
     "iopub.status.busy": "2025-02-11T19:09:07.967132Z",
     "iopub.status.idle": "2025-02-11T19:09:09.746040Z",
     "shell.execute_reply": "2025-02-11T19:09:09.745165Z",
     "shell.execute_reply.started": "2025-02-11T19:09:07.967418Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c78ea3a0032423ea600438799872963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6818521022796631     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     1.19138503074646      </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6818521022796631    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    1.19138503074646     \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 1.7742555141448975\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "result = linear_trainer.test(model, test_loader)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Total time: {end_time - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
