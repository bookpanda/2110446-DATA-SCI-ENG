{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T14:56:25.226155Z",
     "iopub.status.busy": "2025-02-26T14:56:25.225916Z",
     "iopub.status.idle": "2025-02-26T14:56:29.469373Z",
     "shell.execute_reply": "2025-02-26T14:56:29.468471Z",
     "shell.execute_reply.started": "2025-02-26T14:56:25.226135Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from IPython.display import display\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline, DataCollatorWithPadding, AutoModel\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from torchmetrics.classification import MultilabelAccuracy\n",
    "import pickle\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T14:56:29.470713Z",
     "iopub.status.busy": "2025-02-26T14:56:29.470235Z",
     "iopub.status.idle": "2025-02-26T14:56:29.852690Z",
     "shell.execute_reply": "2025-02-26T14:56:29.851599Z",
     "shell.execute_reply.started": "2025-02-26T14:56:29.470685Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "The `notebook_login` function can only be used in a notebook (Jupyter or Colab) and you need the `ipywidgets` module: `pip install ipywidgets`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/Code/courses/DATA-SCI/.venv/lib/python3.12/site-packages/huggingface_hub/_login.py:340\u001b[0m, in \u001b[0;36mnotebook_login\u001b[0;34m(new_session, write_permission)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mipywidgets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwidgets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwidgets\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m display  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ipywidgets'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m notebook_login\n\u001b[0;32m----> 3\u001b[0m \u001b[43mnotebook_login\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/courses/DATA-SCI/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:101\u001b[0m, in \u001b[0;36m_deprecate_arguments.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m         message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m custom_message\n\u001b[1;32m    100\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/courses/DATA-SCI/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:31\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m extra_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[1;32m     33\u001b[0m args_msg \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[38;5;241m-\u001b[39mextra_args:])\n\u001b[1;32m     36\u001b[0m ]\n",
      "File \u001b[0;32m~/Code/courses/DATA-SCI/.venv/lib/python3.12/site-packages/huggingface_hub/_login.py:343\u001b[0m, in \u001b[0;36mnotebook_login\u001b[0;34m(new_session, write_permission)\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m display  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m--> 343\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m    344\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `notebook_login` function can only be used in a notebook (Jupyter or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    345\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Colab) and you need the `ipywidgets` module: `pip install ipywidgets`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    346\u001b[0m     )\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m new_session \u001b[38;5;129;01mand\u001b[39;00m get_token() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser is already logged in.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: The `notebook_login` function can only be used in a notebook (Jupyter or Colab) and you need the `ipywidgets` module: `pip install ipywidgets`."
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T14:19:21.386176Z",
     "iopub.status.busy": "2025-02-26T14:19:21.385831Z",
     "iopub.status.idle": "2025-02-26T14:19:23.264350Z",
     "shell.execute_reply": "2025-02-26T14:19:23.263561Z",
     "shell.execute_reply.started": "2025-02-26T14:19:21.386151Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>สำนักงานตำรวจแห่งชาติ</th>\n",
       "      <th>การรถไฟฟ้าขนส่งมวลชนแห่งประเทศไทย</th>\n",
       "      <th>สภาเด็กและเยาวชนกรุงเทพมหานคร</th>\n",
       "      <th>กรมควบคุมมลพิษ</th>\n",
       "      <th>กรมสรรพสามิต</th>\n",
       "      <th>การไฟฟ้านครหลวง</th>\n",
       "      <th>กรมทางหลวง</th>\n",
       "      <th>สำนักงานประกันสุขภาพแห่งชาติ</th>\n",
       "      <th>การประปานครหลวง</th>\n",
       "      <th>คณะกรรมการการพัฒนาเศรษฐกิจ</th>\n",
       "      <th>กระทรวงการท่องเที่ยวและกีฬา</th>\n",
       "      <th>สำนักงาน กสทช. ศูนย์รับแจ้งปัญหา 1200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>บริเวณนราธิวาส  แยกถนนจันทน์ ใกล้สวนสาธารณะช่อ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>บริเวณสะพานสามถนนจันทน์ เป็นจุดเปลี่ยนถ่ายสองแ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>เรื่องทางม้าลายหายไป บริเวณสี่แยกถนนจันทร์-เซน...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ปัญหาน้ำท่วมในซอยสวนพลู 1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1. ซ่อมสายไฟ กรีดขวางทางเท้า</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            comment  \\\n",
       "0   0  บริเวณนราธิวาส  แยกถนนจันทน์ ใกล้สวนสาธารณะช่อ...   \n",
       "1   1  บริเวณสะพานสามถนนจันทน์ เป็นจุดเปลี่ยนถ่ายสองแ...   \n",
       "2   2  เรื่องทางม้าลายหายไป บริเวณสี่แยกถนนจันทร์-เซน...   \n",
       "3   3                          ปัญหาน้ำท่วมในซอยสวนพลู 1   \n",
       "4   4                       1. ซ่อมสายไฟ กรีดขวางทางเท้า   \n",
       "\n",
       "   สำนักงานตำรวจแห่งชาติ  การรถไฟฟ้าขนส่งมวลชนแห่งประเทศไทย  \\\n",
       "0                      0                                  0   \n",
       "1                      0                                  0   \n",
       "2                      0                                  0   \n",
       "3                      0                                  0   \n",
       "4                      0                                  0   \n",
       "\n",
       "   สภาเด็กและเยาวชนกรุงเทพมหานคร  กรมควบคุมมลพิษ  กรมสรรพสามิต  \\\n",
       "0                              0               0             0   \n",
       "1                              0               0             0   \n",
       "2                              0               0             0   \n",
       "3                              0               0             0   \n",
       "4                              0               0             0   \n",
       "\n",
       "   การไฟฟ้านครหลวง  กรมทางหลวง  สำนักงานประกันสุขภาพแห่งชาติ  การประปานครหลวง  \\\n",
       "0                0           0                             0                0   \n",
       "1                0           0                             0                0   \n",
       "2                0           0                             0                0   \n",
       "3                0           0                             0                0   \n",
       "4                0           0                             0                0   \n",
       "\n",
       "   คณะกรรมการการพัฒนาเศรษฐกิจ  กระทรวงการท่องเที่ยวและกีฬา  \\\n",
       "0                           0                            0   \n",
       "1                           0                            0   \n",
       "2                           0                            0   \n",
       "3                           0                            0   \n",
       "4                           0                            0   \n",
       "\n",
       "   สำนักงาน กสทช. ศูนย์รับแจ้งปัญหา 1200  \n",
       "0                                      0  \n",
       "1                                      0  \n",
       "2                                      0  \n",
       "3                                      0  \n",
       "4                                      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "# train_df = pd.read_csv('/kaggle/input/dataset/train.csv')\n",
    "# test_df = pd.read_csv('/kaggle/input/dataset/test.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T14:19:23.265622Z",
     "iopub.status.busy": "2025-02-26T14:19:23.265311Z",
     "iopub.status.idle": "2025-02-26T14:19:23.351296Z",
     "shell.execute_reply": "2025-02-26T14:19:23.350608Z",
     "shell.execute_reply.started": "2025-02-26T14:19:23.265599Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>สำนักงานตำรวจแห่งชาติ</th>\n",
       "      <th>การรถไฟฟ้าขนส่งมวลชนแห่งประเทศไทย</th>\n",
       "      <th>สภาเด็กและเยาวชนกรุงเทพมหานคร</th>\n",
       "      <th>กรมควบคุมมลพิษ</th>\n",
       "      <th>กรมสรรพสามิต</th>\n",
       "      <th>การไฟฟ้านครหลวง</th>\n",
       "      <th>กรมทางหลวง</th>\n",
       "      <th>สำนักงานประกันสุขภาพแห่งชาติ</th>\n",
       "      <th>การประปานครหลวง</th>\n",
       "      <th>คณะกรรมการการพัฒนาเศรษฐกิจ</th>\n",
       "      <th>กระทรวงการท่องเที่ยวและกีฬา</th>\n",
       "      <th>สำนักงาน กสทช. ศูนย์รับแจ้งปัญหา 1200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>204622.000000</td>\n",
       "      <td>204622.000000</td>\n",
       "      <td>204622.000000</td>\n",
       "      <td>204622.000000</td>\n",
       "      <td>204622.000000</td>\n",
       "      <td>204622.000000</td>\n",
       "      <td>204622.000000</td>\n",
       "      <td>204622.000000</td>\n",
       "      <td>204622.000000</td>\n",
       "      <td>204622.000000</td>\n",
       "      <td>204622.000000</td>\n",
       "      <td>204622.000000</td>\n",
       "      <td>204622.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>102310.500000</td>\n",
       "      <td>0.209635</td>\n",
       "      <td>0.019969</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.016034</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.167944</td>\n",
       "      <td>0.034542</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.024176</td>\n",
       "      <td>0.018478</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.023839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>59069.427728</td>\n",
       "      <td>0.407049</td>\n",
       "      <td>0.139892</td>\n",
       "      <td>0.006991</td>\n",
       "      <td>0.125608</td>\n",
       "      <td>0.010829</td>\n",
       "      <td>0.373817</td>\n",
       "      <td>0.182616</td>\n",
       "      <td>0.020136</td>\n",
       "      <td>0.153597</td>\n",
       "      <td>0.134672</td>\n",
       "      <td>0.007658</td>\n",
       "      <td>0.152548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>51155.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>102310.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>153465.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>204621.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id  สำนักงานตำรวจแห่งชาติ  \\\n",
       "count  204622.000000          204622.000000   \n",
       "mean   102310.500000               0.209635   \n",
       "std     59069.427728               0.407049   \n",
       "min         0.000000               0.000000   \n",
       "25%     51155.250000               0.000000   \n",
       "50%    102310.500000               0.000000   \n",
       "75%    153465.750000               0.000000   \n",
       "max    204621.000000               1.000000   \n",
       "\n",
       "       การรถไฟฟ้าขนส่งมวลชนแห่งประเทศไทย  สภาเด็กและเยาวชนกรุงเทพมหานคร  \\\n",
       "count                      204622.000000                  204622.000000   \n",
       "mean                            0.019969                       0.000049   \n",
       "std                             0.139892                       0.006991   \n",
       "min                             0.000000                       0.000000   \n",
       "25%                             0.000000                       0.000000   \n",
       "50%                             0.000000                       0.000000   \n",
       "75%                             0.000000                       0.000000   \n",
       "max                             1.000000                       1.000000   \n",
       "\n",
       "       กรมควบคุมมลพิษ   กรมสรรพสามิต  การไฟฟ้านครหลวง     กรมทางหลวง  \\\n",
       "count   204622.000000  204622.000000    204622.000000  204622.000000   \n",
       "mean         0.016034       0.000117         0.167944       0.034542   \n",
       "std          0.125608       0.010829         0.373817       0.182616   \n",
       "min          0.000000       0.000000         0.000000       0.000000   \n",
       "25%          0.000000       0.000000         0.000000       0.000000   \n",
       "50%          0.000000       0.000000         0.000000       0.000000   \n",
       "75%          0.000000       0.000000         0.000000       0.000000   \n",
       "max          1.000000       1.000000         1.000000       1.000000   \n",
       "\n",
       "       สำนักงานประกันสุขภาพแห่งชาติ  การประปานครหลวง  \\\n",
       "count                 204622.000000    204622.000000   \n",
       "mean                       0.000406         0.024176   \n",
       "std                        0.020136         0.153597   \n",
       "min                        0.000000         0.000000   \n",
       "25%                        0.000000         0.000000   \n",
       "50%                        0.000000         0.000000   \n",
       "75%                        0.000000         0.000000   \n",
       "max                        1.000000         1.000000   \n",
       "\n",
       "       คณะกรรมการการพัฒนาเศรษฐกิจ  กระทรวงการท่องเที่ยวและกีฬา  \\\n",
       "count               204622.000000                204622.000000   \n",
       "mean                     0.018478                     0.000059   \n",
       "std                      0.134672                     0.007658   \n",
       "min                      0.000000                     0.000000   \n",
       "25%                      0.000000                     0.000000   \n",
       "50%                      0.000000                     0.000000   \n",
       "75%                      0.000000                     0.000000   \n",
       "max                      1.000000                     1.000000   \n",
       "\n",
       "       สำนักงาน กสทช. ศูนย์รับแจ้งปัญหา 1200  \n",
       "count                          204622.000000  \n",
       "mean                                0.023839  \n",
       "std                                 0.152548  \n",
       "min                                 0.000000  \n",
       "25%                                 0.000000  \n",
       "50%                                 0.000000  \n",
       "75%                                 0.000000  \n",
       "max                                 1.000000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T14:19:23.353089Z",
     "iopub.status.busy": "2025-02-26T14:19:23.352838Z",
     "iopub.status.idle": "2025-02-26T14:19:23.485901Z",
     "shell.execute_reply": "2025-02-26T14:19:23.485110Z",
     "shell.execute_reply.started": "2025-02-26T14:19:23.353068Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before dropna: (204622, 14)\n",
      "After dropna: (204622, 14)\n",
      "Before dropna: (10810, 2)\n",
      "After dropna: (10810, 2)\n",
      "(204622, 14) (10810, 2)\n"
     ]
    }
   ],
   "source": [
    "def drop_rows(df):\n",
    "    # drop rows with missing values, duplicates\n",
    "    print(f\"Before dropna: {df.shape}\")\n",
    "    df.dropna(inplace=True)\n",
    "    df.drop_duplicates(\"comment\", keep=\"first\", inplace=True)\n",
    "    df = df.reset_index(drop=True)\n",
    "    print(f\"After dropna: {df.shape}\")\n",
    "\n",
    "drop_rows(train_df)\n",
    "drop_rows(test_df)\n",
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T14:19:23.487029Z",
     "iopub.status.busy": "2025-02-26T14:19:23.486792Z",
     "iopub.status.idle": "2025-02-26T14:19:24.565323Z",
     "shell.execute_reply": "2025-02-26T14:19:24.564652Z",
     "shell.execute_reply.started": "2025-02-26T14:19:23.487010Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>บริเวณนราธิวาส  แยกถนนจันทน์ ใกล้สวนสาธารณะช่อ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>บริเวณสะพานสามถนนจันทน์ เป็นจุดเปลี่ยนถ่ายสองแ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>เรื่องทางม้าลายหายไป บริเวณสี่แยกถนนจันทร์-เซน...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ปัญหาน้ำท่วมในซอยสวนพลู 1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1. ซ่อมสายไฟ กรีดขวางทางเท้า</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  \\\n",
       "0  บริเวณนราธิวาส  แยกถนนจันทน์ ใกล้สวนสาธารณะช่อ...   \n",
       "1  บริเวณสะพานสามถนนจันทน์ เป็นจุดเปลี่ยนถ่ายสองแ...   \n",
       "2  เรื่องทางม้าลายหายไป บริเวณสี่แยกถนนจันทร์-เซน...   \n",
       "3                          ปัญหาน้ำท่วมในซอยสวนพลู 1   \n",
       "4                       1. ซ่อมสายไฟ กรีดขวางทางเท้า   \n",
       "\n",
       "                                  label  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contacts = train_df.columns[2:]\n",
    "\n",
    "train_df['label'] = train_df[contacts].apply(lambda x: list(x), axis=1)\n",
    "train_df.drop(contacts, axis=1, inplace=True)\n",
    "train_df.drop(\"id\", axis=1, inplace=True)\n",
    "\n",
    "test_df.drop(\"id\", axis=1, inplace=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T14:19:24.607023Z",
     "iopub.status.busy": "2025-02-26T14:19:24.606711Z",
     "iopub.status.idle": "2025-02-26T14:19:24.681659Z",
     "shell.execute_reply": "2025-02-26T14:19:24.681012Z",
     "shell.execute_reply.started": "2025-02-26T14:19:24.606992Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]    102333\n",
       "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]     42212\n",
       "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]     32543\n",
       "[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]      5803\n",
       "[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]      4598\n",
       "                                         ...  \n",
       "[1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1]         1\n",
       "[1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0]         1\n",
       "[1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0]         1\n",
       "[1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0]         1\n",
       "[0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]         1\n",
       "Name: count, Length: 73, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102289, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]    42212\n",
       "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]    32543\n",
       "[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]     5803\n",
       "[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]     4598\n",
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]     3993\n",
       "                                        ...  \n",
       "[0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]        1\n",
       "[1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1]        1\n",
       "[1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0]        1\n",
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1]        1\n",
       "[0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1]        1\n",
       "Name: count, Length: 72, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.loc[train_df['label'].apply(lambda x: sum(x) != 0)]\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "print(train_df.shape)\n",
    "train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T14:19:24.683102Z",
     "iopub.status.busy": "2025-02-26T14:19:24.682810Z",
     "iopub.status.idle": "2025-02-26T14:19:24.703247Z",
     "shell.execute_reply": "2025-02-26T14:19:24.702643Z",
     "shell.execute_reply.started": "2025-02-26T14:19:24.683066Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['สำนักงานตำรวจแห่งชาติ', 'การรถไฟฟ้าขนส่งมวลชนแห่งประเทศไทย',\n",
       "       'สภาเด็กและเยาวชนกรุงเทพมหานคร', 'กรมควบคุมมลพิษ', 'กรมสรรพสามิต',\n",
       "       'การไฟฟ้านครหลวง', 'กรมทางหลวง', 'สำนักงานประกันสุขภาพแห่งชาติ',\n",
       "       'การประปานครหลวง', 'คณะกรรมการการพัฒนาเศรษฐกิจ',\n",
       "       'กระทรวงการท่องเที่ยวและกีฬา', 'สำนักงาน กสทช. ศูนย์รับแจ้งปัญหา 1200'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T14:19:26.872331Z",
     "iopub.status.busy": "2025-02-26T14:19:26.872042Z",
     "iopub.status.idle": "2025-02-26T14:19:26.905851Z",
     "shell.execute_reply": "2025-02-26T14:19:26.905111Z",
     "shell.execute_reply.started": "2025-02-26T14:19:26.872308Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Mappings\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 'สำนักงานตำรวจแห่งชาติ',\n",
       " 1: 'การรถไฟฟ้าขนส่งมวลชนแห่งประเทศไทย',\n",
       " 2: 'สภาเด็กและเยาวชนกรุงเทพมหานคร',\n",
       " 3: 'กรมควบคุมมลพิษ',\n",
       " 4: 'กรมสรรพสามิต',\n",
       " 5: 'การไฟฟ้านครหลวง',\n",
       " 6: 'กรมทางหลวง',\n",
       " 7: 'สำนักงานประกันสุขภาพแห่งชาติ',\n",
       " 8: 'การประปานครหลวง',\n",
       " 9: 'คณะกรรมการการพัฒนาเศรษฐกิจ',\n",
       " 10: 'กระทรวงการท่องเที่ยวและกีฬา',\n",
       " 11: 'สำนักงาน กสทช. ศูนย์รับแจ้งปัญหา 1200'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'สำนักงานตำรวจแห่งชาติ': 0,\n",
       " 'การรถไฟฟ้าขนส่งมวลชนแห่งประเทศไทย': 1,\n",
       " 'สภาเด็กและเยาวชนกรุงเทพมหานคร': 2,\n",
       " 'กรมควบคุมมลพิษ': 3,\n",
       " 'กรมสรรพสามิต': 4,\n",
       " 'การไฟฟ้านครหลวง': 5,\n",
       " 'กรมทางหลวง': 6,\n",
       " 'สำนักงานประกันสุขภาพแห่งชาติ': 7,\n",
       " 'การประปานครหลวง': 8,\n",
       " 'คณะกรรมการการพัฒนาเศรษฐกิจ': 9,\n",
       " 'กระทรวงการท่องเที่ยวและกีฬา': 10,\n",
       " 'สำนักงาน กสทช. ศูนย์รับแจ้งปัญหา 1200': 11}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = train_df.copy().to_numpy()\n",
    "test_data = test_df.copy().to_numpy()\n",
    "\n",
    "label_2_idx = dict(zip(contacts, range(len(contacts))))\n",
    "idx_2_label = dict(zip(range(len(contacts)), contacts))\n",
    "\n",
    "print(\"Create Mappings\")\n",
    "display(idx_2_label)\n",
    "display(label_2_idx)\n",
    "\n",
    "# print(\"Before Mappings\")\n",
    "# display(data[:, 1])\n",
    "# data[:,1] = np.vectorize(label_2_num_map.get)(data[:,1])\n",
    "# print(\"After Mappings\")\n",
    "# display(data[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T14:58:51.611056Z",
     "iopub.status.busy": "2025-02-26T14:58:51.610361Z",
     "iopub.status.idle": "2025-02-26T14:58:51.648092Z",
     "shell.execute_reply": "2025-02-26T14:58:51.647284Z",
     "shell.execute_reply.started": "2025-02-26T14:58:51.611022Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def set_random_seed(seed: int):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T14:58:51.649501Z",
     "iopub.status.busy": "2025-02-26T14:58:51.649229Z",
     "iopub.status.idle": "2025-02-26T14:58:52.331221Z",
     "shell.execute_reply": "2025-02-26T14:58:52.330574Z",
     "shell.execute_reply.started": "2025-02-26T14:58:51.649481Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Converting from Tiktoken failed, if a converter for SentencePiece is available, provide a model path with a SentencePiece tokenizer.model file.Currently available slow->fast convertors: ['AlbertTokenizer', 'BartTokenizer', 'BarthezTokenizer', 'BertTokenizer', 'BigBirdTokenizer', 'BlenderbotTokenizer', 'CamembertTokenizer', 'CLIPTokenizer', 'CodeGenTokenizer', 'ConvBertTokenizer', 'DebertaTokenizer', 'DebertaV2Tokenizer', 'DistilBertTokenizer', 'DPRReaderTokenizer', 'DPRQuestionEncoderTokenizer', 'DPRContextEncoderTokenizer', 'ElectraTokenizer', 'FNetTokenizer', 'FunnelTokenizer', 'GPT2Tokenizer', 'HerbertTokenizer', 'LayoutLMTokenizer', 'LayoutLMv2Tokenizer', 'LayoutLMv3Tokenizer', 'LayoutXLMTokenizer', 'LongformerTokenizer', 'LEDTokenizer', 'LxmertTokenizer', 'MarkupLMTokenizer', 'MBartTokenizer', 'MBart50Tokenizer', 'MPNetTokenizer', 'MobileBertTokenizer', 'MvpTokenizer', 'NllbTokenizer', 'OpenAIGPTTokenizer', 'PegasusTokenizer', 'Qwen2Tokenizer', 'RealmTokenizer', 'ReformerTokenizer', 'RemBertTokenizer', 'RetriBertTokenizer', 'RobertaTokenizer', 'RoFormerTokenizer', 'SeamlessM4TTokenizer', 'SqueezeBertTokenizer', 'T5Tokenizer', 'UdopTokenizer', 'WhisperTokenizer', 'XLMRobertaTokenizer', 'XLNetTokenizer', 'SplinterTokenizer', 'XGLMTokenizer', 'LlamaTokenizer', 'CodeLlamaTokenizer', 'GemmaTokenizer', 'Phi3Tokenizer']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/Code/courses/DATA-SCI/.venv/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:1585\u001b[0m, in \u001b[0;36mTikTokenConverter.extract_vocab_merges_from_model\u001b[0;34m(self, tiktoken_url)\u001b[0m\n\u001b[1;32m   1584\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1585\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtiktoken\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mload\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_tiktoken_bpe\n\u001b[1;32m   1586\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tiktoken'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/Code/courses/DATA-SCI/.venv/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:1725\u001b[0m, in \u001b[0;36mconvert_slow_tokenizer\u001b[0;34m(transformer_tokenizer, from_tiktoken)\u001b[0m\n\u001b[1;32m   1721\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverting from Tiktoken\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1722\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTikTokenConverter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1723\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformer_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1724\u001b[0m \u001b[43m        \u001b[49m\u001b[43madditional_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformer_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madditional_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 1725\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1726\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[0;32m~/Code/courses/DATA-SCI/.venv/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:1622\u001b[0m, in \u001b[0;36mTikTokenConverter.converted\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1621\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconverted\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tokenizer:\n\u001b[0;32m-> 1622\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1623\u001b[0m     tokenizer\u001b[38;5;241m.\u001b[39mpre_tokenizer \u001b[38;5;241m=\u001b[39m pre_tokenizers\u001b[38;5;241m.\u001b[39mSequence(\n\u001b[1;32m   1624\u001b[0m         [\n\u001b[1;32m   1625\u001b[0m             pre_tokenizers\u001b[38;5;241m.\u001b[39mSplit(Regex(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpattern), behavior\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124misolated\u001b[39m\u001b[38;5;124m\"\u001b[39m, invert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1626\u001b[0m             pre_tokenizers\u001b[38;5;241m.\u001b[39mByteLevel(add_prefix_space\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_prefix_space, use_regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1627\u001b[0m         ]\n\u001b[1;32m   1628\u001b[0m     )\n",
      "File \u001b[0;32m~/Code/courses/DATA-SCI/.venv/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:1615\u001b[0m, in \u001b[0;36mTikTokenConverter.tokenizer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1614\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtokenizer\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 1615\u001b[0m     vocab_scores, merges \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_vocab_merges_from_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1616\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m Tokenizer(BPE(vocab_scores, merges, fuse_unk\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "File \u001b[0;32m~/Code/courses/DATA-SCI/.venv/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:1587\u001b[0m, in \u001b[0;36mTikTokenConverter.extract_vocab_merges_from_model\u001b[0;34m(self, tiktoken_url)\u001b[0m\n\u001b[1;32m   1586\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m-> 1587\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1588\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tiktoken` is required to read a `tiktoken` file. Install it with \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip install tiktoken`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1589\u001b[0m     )\n\u001b[1;32m   1591\u001b[0m bpe_ranks \u001b[38;5;241m=\u001b[39m load_tiktoken_bpe(tiktoken_url)\n",
      "\u001b[0;31mValueError\u001b[0m: `tiktoken` is required to read a `tiktoken` file. Install it with `pip install tiktoken`.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mairesearch/wangchanberta-base-att-spm-uncased\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_max_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# tokenizer = Tokenizer(\"airesearch/wangchanberta-base-att-spm-uncased\")\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# model = AutoModelForSequenceClassification.from_pretrained(\"airesearch/wangchanberta-base-att-spm-uncased\")\u001b[39;00m\n\u001b[1;32m      4\u001b[0m data_collator \u001b[38;5;241m=\u001b[39m DataCollatorWithPadding(tokenizer\u001b[38;5;241m=\u001b[39mtokenizer)\n",
      "File \u001b[0;32m~/Code/courses/DATA-SCI/.venv/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py:963\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    960\u001b[0m tokenizer_class_py, tokenizer_class_fast \u001b[38;5;241m=\u001b[39m TOKENIZER_MAPPING[\u001b[38;5;28mtype\u001b[39m(config)]\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenizer_class_fast \u001b[38;5;129;01mand\u001b[39;00m (use_fast \u001b[38;5;129;01mor\u001b[39;00m tokenizer_class_py \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 963\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtokenizer_class_fast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer_class_py \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Code/courses/DATA-SCI/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2052\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2049\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2050\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from cache at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresolved_vocab_files[file_id]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2052\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresolved_vocab_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_configuration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2056\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2058\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2059\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2060\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2061\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_is_local\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2063\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2064\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/courses/DATA-SCI/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2292\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._from_pretrained\u001b[0;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2290\u001b[0m \u001b[38;5;66;03m# Instantiate the tokenizer.\u001b[39;00m\n\u001b[1;32m   2291\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2292\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2293\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m import_protobuf_decode_error():\n\u001b[1;32m   2294\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m   2295\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to load tokenizer model from SPM, loading from TikToken will be attempted instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2296\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(Google protobuf error: Tried to load SPM model with non-SPM vocab file).\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2297\u001b[0m     )\n",
      "File \u001b[0;32m~/Code/courses/DATA-SCI/.venv/lib/python3.12/site-packages/transformers/models/camembert/tokenization_camembert_fast.py:112\u001b[0m, in \u001b[0;36mCamembertTokenizerFast.__init__\u001b[0;34m(self, vocab_file, tokenizer_file, bos_token, eos_token, sep_token, cls_token, unk_token, pad_token, mask_token, additional_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     98\u001b[0m     vocab_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    109\u001b[0m ):\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;66;03m# Mask token behave like a normal word, i.e. include the space before it. Will have normalized = False\u001b[39;00m\n\u001b[1;32m    111\u001b[0m     mask_token \u001b[38;5;241m=\u001b[39m AddedToken(mask_token, lstrip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, special\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mask_token, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m mask_token\n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtokenizer_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbos_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbos_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meos_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43msep_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcls_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcls_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43munk_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munk_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43madditional_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madditional_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_file \u001b[38;5;241m=\u001b[39m vocab_file\n",
      "File \u001b[0;32m~/Code/courses/DATA-SCI/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_fast.py:139\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_file \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvocab_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madditional_special_tokens \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madditional_special_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m, [])\n\u001b[0;32m--> 139\u001b[0m     fast_tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_slow_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_tiktoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     slow_tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Code/courses/DATA-SCI/.venv/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:1727\u001b[0m, in \u001b[0;36mconvert_slow_tokenizer\u001b[0;34m(transformer_tokenizer, from_tiktoken)\u001b[0m\n\u001b[1;32m   1722\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m TikTokenConverter(\n\u001b[1;32m   1723\u001b[0m         vocab_file\u001b[38;5;241m=\u001b[39mtransformer_tokenizer\u001b[38;5;241m.\u001b[39mvocab_file,\n\u001b[1;32m   1724\u001b[0m         additional_special_tokens\u001b[38;5;241m=\u001b[39mtransformer_tokenizer\u001b[38;5;241m.\u001b[39madditional_special_tokens,\n\u001b[1;32m   1725\u001b[0m     )\u001b[38;5;241m.\u001b[39mconverted()\n\u001b[1;32m   1726\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m-> 1727\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1728\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverting from Tiktoken failed, if a converter for SentencePiece is available, provide a model path \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1729\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith a SentencePiece tokenizer.model file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1730\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrently available slow->fast convertors: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(SLOW_TO_FAST_CONVERTERS\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1731\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Converting from Tiktoken failed, if a converter for SentencePiece is available, provide a model path with a SentencePiece tokenizer.model file.Currently available slow->fast convertors: ['AlbertTokenizer', 'BartTokenizer', 'BarthezTokenizer', 'BertTokenizer', 'BigBirdTokenizer', 'BlenderbotTokenizer', 'CamembertTokenizer', 'CLIPTokenizer', 'CodeGenTokenizer', 'ConvBertTokenizer', 'DebertaTokenizer', 'DebertaV2Tokenizer', 'DistilBertTokenizer', 'DPRReaderTokenizer', 'DPRQuestionEncoderTokenizer', 'DPRContextEncoderTokenizer', 'ElectraTokenizer', 'FNetTokenizer', 'FunnelTokenizer', 'GPT2Tokenizer', 'HerbertTokenizer', 'LayoutLMTokenizer', 'LayoutLMv2Tokenizer', 'LayoutLMv3Tokenizer', 'LayoutXLMTokenizer', 'LongformerTokenizer', 'LEDTokenizer', 'LxmertTokenizer', 'MarkupLMTokenizer', 'MBartTokenizer', 'MBart50Tokenizer', 'MPNetTokenizer', 'MobileBertTokenizer', 'MvpTokenizer', 'NllbTokenizer', 'OpenAIGPTTokenizer', 'PegasusTokenizer', 'Qwen2Tokenizer', 'RealmTokenizer', 'ReformerTokenizer', 'RemBertTokenizer', 'RetriBertTokenizer', 'RobertaTokenizer', 'RoFormerTokenizer', 'SeamlessM4TTokenizer', 'SqueezeBertTokenizer', 'T5Tokenizer', 'UdopTokenizer', 'WhisperTokenizer', 'XLMRobertaTokenizer', 'XLNetTokenizer', 'SplinterTokenizer', 'XGLMTokenizer', 'LlamaTokenizer', 'CodeLlamaTokenizer', 'GemmaTokenizer', 'Phi3Tokenizer']"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"airesearch/wangchanberta-base-att-spm-uncased\", model_max_length=512, revision='main')\n",
    "# tokenizer = Tokenizer(\"airesearch/wangchanberta-base-att-spm-uncased\")\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\"airesearch/wangchanberta-base-att-spm-uncased\")\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T13:43:34.180808Z",
     "iopub.status.busy": "2025-02-26T13:43:34.180572Z",
     "iopub.status.idle": "2025-02-26T13:43:34.254030Z",
     "shell.execute_reply": "2025-02-26T13:43:34.252899Z",
     "shell.execute_reply.started": "2025-02-26T13:43:34.180787Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-332a125173f9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer(train_data[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T12:20:01.103651Z",
     "iopub.status.busy": "2025-02-26T12:20:01.103387Z",
     "iopub.status.idle": "2025-02-26T12:21:19.472916Z",
     "shell.execute_reply": "2025-02-26T12:21:19.472158Z",
     "shell.execute_reply.started": "2025-02-26T12:20:01.103630Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "204622it [01:18, 2611.62it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, sample in tqdm(enumerate(train_data)):\n",
    "    cleaned_sentence = sample[0].replace('ํา', \"ำ\") # only cleaning needed for WangchanBERTa\n",
    "    train_data[i, 0] = tokenizer(cleaned_sentence) # no padding as we will use DataCollatorWithPadding to pad within batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T12:21:19.473901Z",
     "iopub.status.busy": "2025-02-26T12:21:19.473652Z",
     "iopub.status.idle": "2025-02-26T12:21:24.237324Z",
     "shell.execute_reply": "2025-02-26T12:21:24.236534Z",
     "shell.execute_reply.started": "2025-02-26T12:21:19.473879Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10810it [00:04, 2272.48it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, sample in tqdm(enumerate(test_data)):\n",
    "    cleaned_sentence = sample[0].replace('ํา', \"ำ\") # only cleaning needed for WangchanBERTa\n",
    "    test_data[i, 0] = tokenizer(cleaned_sentence) # no padding as we will use DataCollatorWithPadding to pad within batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T13:44:06.675596Z",
     "iopub.status.busy": "2025-02-26T13:44:06.675293Z",
     "iopub.status.idle": "2025-02-26T13:44:06.700792Z",
     "shell.execute_reply": "2025-02-26T13:44:06.699543Z",
     "shell.execute_reply.started": "2025-02-26T13:44:06.675574Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-e481f31fdcc3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_data.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_data.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "with open('train_data.pkl', 'wb') as f:\n",
    "    pickle.dump(train_data, f)\n",
    "with open('test_data.pkl', 'wb') as f:\n",
    "    pickle.dump(test_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T15:02:29.758385Z",
     "iopub.status.busy": "2025-02-26T15:02:29.758096Z",
     "iopub.status.idle": "2025-02-26T15:02:34.417303Z",
     "shell.execute_reply": "2025-02-26T15:02:34.416324Z",
     "shell.execute_reply.started": "2025-02-26T15:02:29.758364Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open('/kaggle/input/pickle/train_data.pkl', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "with open('/kaggle/input/pickle/test_data.pkl', 'rb') as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T15:02:38.236468Z",
     "iopub.status.busy": "2025-02-26T15:02:38.236182Z",
     "iopub.status.idle": "2025-02-26T15:02:38.341962Z",
     "shell.execute_reply": "2025-02-26T15:02:38.341268Z",
     "shell.execute_reply.started": "2025-02-26T15:02:38.236448Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((204622,), (204622,), (10810,), (10810, 13))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_data[:, 0]\n",
    "y_train = train_data[:, 1]\n",
    "X_test = test_data[:, 0]\n",
    "y_test = np.array([([0] * 12) + [1] for _ in range(test_data.shape[0])])\n",
    "\n",
    "for y in y_train:\n",
    "    if y == [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]:\n",
    "        y.append(1)\n",
    "    else:\n",
    "        y.append(0)\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T15:02:40.333945Z",
     "iopub.status.busy": "2025-02-26T15:02:40.333629Z",
     "iopub.status.idle": "2025-02-26T15:02:40.340046Z",
     "shell.execute_reply": "2025-02-26T15:02:40.339199Z",
     "shell.execute_reply.started": "2025-02-26T15:02:40.333920Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [5, 10, 385, 3755, 8, 8, 10, 818, 501, 13080, 8, 10, 991, 12681, 488, 13773, 537, 8, 10, 75, 1548, 6161, 82, 6], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "{'input_ids': [5, 10, 3029, 1548, 39, 445, 32, 1981, 24925, 28, 317, 618, 1433, 9, 5099, 9, 2649, 6], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])\n",
    "print(y_train[0])\n",
    "\n",
    "print(X_test[0])\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T15:02:45.382976Z",
     "iopub.status.busy": "2025-02-26T15:02:45.382672Z",
     "iopub.status.idle": "2025-02-26T15:02:45.388310Z",
     "shell.execute_reply": "2025-02-26T15:02:45.387415Z",
     "shell.execute_reply.started": "2025-02-26T15:02:45.382952Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TraffyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels, device='cpu'):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        self.device = device\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {\n",
    "            key: torch.tensor(val[:512]).to(self.device) for key, val in self.encodings[idx].items()\n",
    "            if key in ['input_ids', 'attention_mask'] # take only input_ids and attention_mask fields\n",
    "        }\n",
    "        item['labels'] = torch.tensor(self.labels[idx]).to(self.device)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T15:02:48.819256Z",
     "iopub.status.busy": "2025-02-26T15:02:48.818957Z",
     "iopub.status.idle": "2025-02-26T15:02:48.846618Z",
     "shell.execute_reply": "2025-02-26T15:02:48.845588Z",
     "shell.execute_reply.started": "2025-02-26T15:02:48.819234Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = TraffyDataset(X_train, y_train, device='cuda')\n",
    "test_dataset = TraffyDataset(X_test, y_test, device='cuda')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=data_collator)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T15:02:50.257015Z",
     "iopub.status.busy": "2025-02-26T15:02:50.256680Z",
     "iopub.status.idle": "2025-02-26T15:02:50.264369Z",
     "shell.execute_reply": "2025-02-26T15:02:50.263444Z",
     "shell.execute_reply.started": "2025-02-26T15:02:50.256990Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    5,    10,   385,  3755,     8,     8,    10,   818,   501, 13080,\n",
       "            8,    10,   991, 12681,   488, 13773,   537,     8,    10,    75,\n",
       "         1548,  6161,    82,     6], device='cuda:0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset[0]['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T15:02:50.476090Z",
     "iopub.status.busy": "2025-02-26T15:02:50.475767Z",
     "iopub.status.idle": "2025-02-26T15:02:50.484827Z",
     "shell.execute_reply": "2025-02-26T15:02:50.483924Z",
     "shell.execute_reply.started": "2025-02-26T15:02:50.476064Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([    5,    10,   385,  3755,     8,     8,    10,   818,   501, 13080,\n",
      "            8,    10,   991, 12681,   488, 13773,   537,     8,    10,    75,\n",
      "         1548,  6161,    82,     6], device='cuda:0'), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       device='cuda:0'), 'labels': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')}\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(train_loader.dataset[0])\n",
    "print(test_loader.dataset[0]['labels'])\n",
    "print(train_loader.dataset[0]['labels'].float().dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T15:02:53.478303Z",
     "iopub.status.busy": "2025-02-26T15:02:53.478020Z",
     "iopub.status.idle": "2025-02-26T15:02:53.483902Z",
     "shell.execute_reply": "2025-02-26T15:02:53.483066Z",
     "shell.execute_reply.started": "2025-02-26T15:02:53.478282Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BaseModel(LightningModule):\n",
    "    def __init__(\n",
    "          self,\n",
    "          model_name: str = 'airesearch/wangchanberta-base-att-spm-uncased',\n",
    "          learning_rate: float = 2e-5\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.encoder = AutoModel.from_pretrained(model_name)\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def get_embeddings(self, input_ids, attention_mask):\n",
    "        outputs = self.encoder(input_ids, attention_mask)\n",
    "        hidden_states = outputs.last_hidden_state\n",
    "\n",
    "        # [CLS] token is the first token in the sequence (index 0)\n",
    "        cls_embeddings = hidden_states[:, 0, :]  # [batch_size, hidden_size]\n",
    "        \n",
    "        return cls_embeddings\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        return self.get_embeddings(input_ids, attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T15:03:00.628703Z",
     "iopub.status.busy": "2025-02-26T15:03:00.628391Z",
     "iopub.status.idle": "2025-02-26T15:03:00.638131Z",
     "shell.execute_reply": "2025-02-26T15:03:00.637112Z",
     "shell.execute_reply.started": "2025-02-26T15:03:00.628679Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class LMWithMultiLabelClassfier(BaseModel):\n",
    "    def __init__(\n",
    "          self,\n",
    "          model_name: str = 'airesearch/wangchanberta-base-att-spm-uncased',\n",
    "          ckpt_path: str = None,\n",
    "          learning_rate: float = 2e-5,\n",
    "          freeze_encoder_weights: bool = False,\n",
    "          num_labels: int = 13\n",
    "    ):\n",
    "        super().__init__(\n",
    "            model_name,\n",
    "            learning_rate\n",
    "        )\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        if ckpt_path:\n",
    "            checkpoint = torch.load(ckpt_path)\n",
    "            encoder_state_dict = {k.replace(\"encoder.\", \"\"): v for k, v in checkpoint[\"state_dict\"].items() if k.startswith(\"encoder.\")}\n",
    "            self.encoder.load_state_dict(encoder_state_dict)\n",
    "\n",
    "        self.linear_layer = nn.Linear(768, num_labels)\n",
    "\n",
    "        if freeze_encoder_weights:\n",
    "          self.freeze_weights(self.encoder)  # Freeze model\n",
    "\n",
    "        self.accuracy = MultilabelAccuracy(num_labels=num_labels, threshold=0.5)\n",
    "\n",
    "    def freeze_weights(self, model):\n",
    "        for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        cls_embeddings = self.get_embeddings(input_ids, attention_mask)\n",
    "        logits = self.linear_layer(cls_embeddings)\n",
    "        return logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['labels'].float()  # float for BCEWithLogitsLoss\n",
    "        logits = self.forward(input_ids, attention_mask)\n",
    "        print(f\"Logits: {logits}\")\n",
    "        print(f\"Labels: {labels}\")\n",
    "        print(f\"Logits shape: {logits.shape}\")\n",
    "        print(f\"Labels shape: {labels.shape}\")\n",
    "\n",
    "        loss = F.binary_cross_entropy_with_logits(logits, labels)\n",
    "        print(f\"loss: {loss}\")\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "\n",
    "        preds = torch.sigmoid(logits)\n",
    "        print(f\"preds: {preds}\")\n",
    "        acc = self.accuracy(preds, labels)\n",
    "        self.log('train_acc', acc, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['labels'].float()\n",
    "        logits = self.forward(input_ids, attention_mask)\n",
    "\n",
    "        loss = F.binary_cross_entropy_with_logits(logits, labels)\n",
    "        self.log('test_loss', loss, prog_bar=True)\n",
    "\n",
    "        preds = torch.sigmoid(logits)\n",
    "        acc = self.accuracy(preds, labels)\n",
    "        self.log('test_acc', acc, prog_bar=True)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T15:03:03.521396Z",
     "iopub.status.busy": "2025-02-26T15:03:03.521099Z",
     "iopub.status.idle": "2025-02-26T15:03:04.628106Z",
     "shell.execute_reply": "2025-02-26T15:03:04.627391Z",
     "shell.execute_reply.started": "2025-02-26T15:03:03.521374Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at airesearch/wangchanberta-base-att-spm-uncased were not used when initializing CamembertModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing CamembertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = LMWithMultiLabelClassfier(\n",
    "    'airesearch/wangchanberta-base-att-spm-uncased',\n",
    "    ckpt_path=None,\n",
    "    freeze_encoder_weights=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T15:03:05.723365Z",
     "iopub.status.busy": "2025-02-26T15:03:05.723063Z",
     "iopub.status.idle": "2025-02-26T15:03:05.768338Z",
     "shell.execute_reply": "2025-02-26T15:03:05.767718Z",
     "shell.execute_reply.started": "2025-02-26T15:03:05.723343Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    monitor=\"val_acc\",  # Metric to monitor\n",
    "    mode=\"max\",  # \"min\" for loss, \"max\" for accuracy\n",
    "    save_top_k=1,  # Save only the best model(s)\n",
    "    save_weights_only=True, # Saves only weights, not the entire model\n",
    "    dirpath=\"./checkpoints/\", # Path where the checkpoints will be saved\n",
    "    filename=\"best_pretrained_w_linear_model-{epoch}-{val_acc:.2f}\", # Customized name for the checkpoint\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "linear_trainer = Trainer(\n",
    "    max_epochs=5,\n",
    "    accelerator='auto',\n",
    "    callbacks=[checkpoint_callback], # Add the ModelCheckpoint callback\n",
    "    gradient_clip_val=1.0,\n",
    "    precision=\"16-mixed\", # Mixed precision training\n",
    "    devices=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T15:03:08.609882Z",
     "iopub.status.busy": "2025-02-26T15:03:08.609543Z",
     "iopub.status.idle": "2025-02-26T15:03:08.613694Z",
     "shell.execute_reply": "2025-02-26T15:03:08.612762Z",
     "shell.execute_reply.started": "2025-02-26T15:03:08.609857Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = '1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T15:03:08.810142Z",
     "iopub.status.busy": "2025-02-26T15:03:08.809883Z",
     "iopub.status.idle": "2025-02-26T15:03:09.200855Z",
     "shell.execute_reply": "2025-02-26T15:03:09.199585Z",
     "shell.execute_reply.started": "2025-02-26T15:03:08.810119Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!export CUDA_LAUNCH_BLOCKING=1\n",
    "!export TORCH_USE_CUDA_DSA=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T15:03:09.720888Z",
     "iopub.status.busy": "2025-02-26T15:03:09.720531Z",
     "iopub.status.idle": "2025-02-26T15:03:13.816062Z",
     "shell.execute_reply": "2025-02-26T15:03:13.814630Z",
     "shell.execute_reply.started": "2025-02-26T15:03:09.720856Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad79f4c154b4fe8993786027da65563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits: tensor([[-0.6641,  0.1681,  0.3337, -0.2815,  0.7729, -0.9214,  0.7051, -0.5391,\n",
      "         -1.5664, -0.4880,  0.8628, -0.5415,  1.2441],\n",
      "        [-0.9360,  0.2786, -0.1091, -0.3970,  1.0039, -0.1500,  0.6719, -0.6514,\n",
      "         -0.6572, -0.2627,  0.6851, -0.8164,  0.9688],\n",
      "        [-0.1284, -0.4253, -0.6201,  0.0895,  0.2605, -0.5215,  0.8389, -1.0928,\n",
      "         -0.5200, -0.4348,  1.1836, -0.2195,  0.1559],\n",
      "        [-0.3086,  0.1232, -0.1296, -0.3853,  0.2644, -0.2664,  0.4434, -0.1658,\n",
      "         -0.6914, -0.0790,  0.7461,  0.1228,  1.3623],\n",
      "        [-0.3000, -0.2139,  0.0617,  0.6738,  0.5508, -0.7974,  0.6895, -0.5205,\n",
      "         -0.2793, -0.6538,  0.4463, -0.8892,  1.0078],\n",
      "        [-1.2373,  0.1729, -0.6450,  0.5122,  0.6729, -0.6025,  1.3164, -0.0074,\n",
      "         -1.2666, -0.7368,  1.1172, -1.0254,  1.0830],\n",
      "        [-0.2822,  0.1558, -0.3228, -0.4836,  0.0550, -0.0098,  1.5020, -0.1030,\n",
      "         -0.7642, -0.5713,  0.6958, -0.1477,  1.0283],\n",
      "        [-0.8193,  0.1985, -0.2898, -0.5801,  0.3689, -0.0834,  0.9893, -0.7173,\n",
      "         -0.6265,  0.1326,  0.9512, -0.0592,  1.2158],\n",
      "        [ 0.5684, -0.0092, -0.8545, -0.7593, -0.3931, -0.8569,  0.3696,  0.0292,\n",
      "         -1.2383,  0.5044,  1.6670, -0.0267, -0.0757],\n",
      "        [-0.4851, -0.7266, -0.1864,  0.2325, -0.0732, -0.9722,  0.6807, -0.5439,\n",
      "         -1.3936,  0.0117,  0.5957,  0.6650,  1.0254],\n",
      "        [-0.5112,  0.1331, -0.4136, -0.1273,  0.5190, -0.4558,  0.9922, -0.0349,\n",
      "         -0.9312, -0.7285,  1.1035, -0.4058,  1.7832],\n",
      "        [ 0.2051,  0.3484, -1.3525, -0.0046, -0.7153, -0.6519, -0.6191,  0.4175,\n",
      "         -0.6987,  0.8066,  1.0547,  0.4487, -0.6797],\n",
      "        [-0.5796,  0.8984, -0.0241, -0.4949,  0.4304, -0.1721,  1.4141, -0.3059,\n",
      "         -0.6406, -0.3176,  0.7021,  0.0632,  1.1553],\n",
      "        [ 0.0856,  0.2030, -0.4719, -1.0078,  0.3711, -1.2598,  0.2401, -0.3965,\n",
      "         -1.4238,  0.0252,  2.0469,  0.2976, -0.3196],\n",
      "        [-0.7808,  0.1157, -0.6201, -0.1436,  0.6841, -0.5566,  1.1270, -0.7183,\n",
      "         -1.0547, -0.4761,  1.4678, -0.8716,  1.4082],\n",
      "        [-0.8213, -0.4756, -0.5215,  0.2325,  0.7041, -1.1904,  0.7168,  0.2260,\n",
      "         -1.1377, -0.3083,  1.3145, -0.4746,  1.2061]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "Labels: tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "Logits shape: torch.Size([16, 13])\n",
      "Labels shape: torch.Size([16, 13])\n",
      "loss: 0.7264066934585571\n",
      "preds: tensor([[0.3398, 0.5420, 0.5825, 0.4302, 0.6841, 0.2847, 0.6694, 0.3684, 0.1727,\n",
      "         0.3804, 0.7031, 0.3679, 0.7764],\n",
      "        [0.2817, 0.5693, 0.4727, 0.4021, 0.7319, 0.4626, 0.6621, 0.3428, 0.3413,\n",
      "         0.4348, 0.6650, 0.3066, 0.7251],\n",
      "        [0.4680, 0.3953, 0.3499, 0.5225, 0.5649, 0.3726, 0.6982, 0.2510, 0.3728,\n",
      "         0.3931, 0.7656, 0.4453, 0.5391],\n",
      "        [0.4233, 0.5308, 0.4675, 0.4048, 0.5659, 0.4338, 0.6089, 0.4587, 0.3337,\n",
      "         0.4802, 0.6782, 0.5308, 0.7959],\n",
      "        [0.4255, 0.4468, 0.5156, 0.6626, 0.6343, 0.3105, 0.6660, 0.3728, 0.4307,\n",
      "         0.3420, 0.6099, 0.2913, 0.7324],\n",
      "        [0.2249, 0.5430, 0.3440, 0.6255, 0.6621, 0.3538, 0.7886, 0.4980, 0.2198,\n",
      "         0.3237, 0.7534, 0.2639, 0.7471],\n",
      "        [0.4299, 0.5391, 0.4199, 0.3813, 0.5137, 0.4976, 0.8179, 0.4744, 0.3176,\n",
      "         0.3608, 0.6675, 0.4631, 0.7368],\n",
      "        [0.3059, 0.5493, 0.4280, 0.3589, 0.5913, 0.4792, 0.7290, 0.3279, 0.3484,\n",
      "         0.5332, 0.7212, 0.4851, 0.7715],\n",
      "        [0.6382, 0.4978, 0.2986, 0.3188, 0.4031, 0.2981, 0.5913, 0.5073, 0.2247,\n",
      "         0.6235, 0.8413, 0.4934, 0.4810],\n",
      "        [0.3811, 0.3259, 0.4536, 0.5581, 0.4817, 0.2744, 0.6641, 0.3672, 0.1989,\n",
      "         0.5029, 0.6445, 0.6602, 0.7358],\n",
      "        [0.3750, 0.5332, 0.3979, 0.4683, 0.6270, 0.3879, 0.7295, 0.4912, 0.2827,\n",
      "         0.3254, 0.7510, 0.3999, 0.8560],\n",
      "        [0.5513, 0.5864, 0.2054, 0.4988, 0.3284, 0.3425, 0.3501, 0.6030, 0.3320,\n",
      "         0.6914, 0.7417, 0.6104, 0.3364],\n",
      "        [0.3591, 0.7104, 0.4939, 0.3787, 0.6060, 0.4570, 0.8042, 0.4241, 0.3452,\n",
      "         0.4211, 0.6685, 0.5156, 0.7603],\n",
      "        [0.5215, 0.5508, 0.3843, 0.2673, 0.5918, 0.2211, 0.5596, 0.4021, 0.1941,\n",
      "         0.5063, 0.8857, 0.5737, 0.4209],\n",
      "        [0.3142, 0.5288, 0.3499, 0.4641, 0.6646, 0.3643, 0.7554, 0.3279, 0.2583,\n",
      "         0.3833, 0.8125, 0.2949, 0.8037],\n",
      "        [0.3054, 0.3833, 0.3726, 0.5581, 0.6689, 0.2332, 0.6719, 0.5562, 0.2428,\n",
      "         0.4236, 0.7881, 0.3835, 0.7695]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<SigmoidBackward0>)\n",
      "Logits: tensor([[-1.9226e-01, -3.6102e-02, -2.6855e-01,  9.6924e-02,  5.6592e-01,\n",
      "         -1.1377e+00,  9.9170e-01, -4.8267e-01, -9.0674e-01, -8.4900e-02,\n",
      "          1.4365e+00,  1.8225e-01, -6.6113e-01],\n",
      "        [ 3.0688e-01, -5.6982e-01,  6.7200e-02, -5.6152e-02,  2.2534e-01,\n",
      "         -6.8481e-02,  4.4043e-01,  1.4429e-01, -3.1494e-02,  1.5894e-01,\n",
      "          9.5068e-01,  9.8193e-01,  1.3550e-01],\n",
      "        [-7.3340e-01,  3.3936e-01, -3.1055e-01, -2.5708e-01,  3.5840e-01,\n",
      "         -3.8599e-01,  9.8486e-01,  1.9019e-01, -1.6006e+00, -4.9072e-01,\n",
      "          1.0586e+00, -1.8176e-01,  9.8975e-01],\n",
      "        [-6.4893e-01,  1.1505e-01, -5.5273e-01, -5.5786e-02,  2.9321e-01,\n",
      "         -5.4395e-01,  1.4521e+00, -7.3792e-02, -1.1123e+00, -1.7358e-01,\n",
      "          1.0898e+00, -5.1904e-01,  7.9346e-01],\n",
      "        [-6.0693e-01,  3.8574e-01,  1.2817e-01, -1.4368e-01,  4.8511e-01,\n",
      "         -9.7656e-01,  5.4639e-01, -1.5516e-03, -9.0771e-01, -3.2764e-01,\n",
      "          5.0391e-01,  2.9150e-01,  1.3652e+00],\n",
      "        [-1.7908e-01, -4.8755e-01, -1.1725e-01, -7.2693e-02,  6.4600e-01,\n",
      "         -1.4707e+00,  5.2393e-01, -3.8281e-01, -3.7280e-01, -1.5312e+00,\n",
      "          7.4170e-01, -4.0308e-01,  9.1748e-01],\n",
      "        [-9.1113e-01, -2.9202e-03, -6.1182e-01, -3.5706e-02,  7.4658e-01,\n",
      "         -4.1016e-02,  8.5205e-01, -8.1104e-01, -5.7471e-01, -5.4736e-01,\n",
      "          1.2617e+00, -5.4980e-01,  3.9746e-01],\n",
      "        [-7.6123e-01, -2.2119e-01, -5.5371e-01,  7.4890e-02,  1.1006e+00,\n",
      "         -3.6182e-01,  2.6758e-01, -4.4751e-01, -5.2686e-01, -6.6699e-01,\n",
      "          7.7588e-01, -5.0244e-01,  5.6982e-01],\n",
      "        [ 3.0200e-01, -7.7686e-01, -6.1230e-01, -6.9971e-01,  4.2114e-01,\n",
      "         -9.2334e-01,  5.0244e-01, -1.3574e+00, -6.8457e-01, -4.4800e-01,\n",
      "          5.9668e-01, -7.8809e-01, -1.8768e-02],\n",
      "        [-1.2314e+00, -1.4246e-01, -2.6758e-01,  1.4722e-01,  7.4951e-01,\n",
      "         -5.2832e-01,  5.8447e-01, -8.7207e-01, -4.4434e-01, -2.8516e-01,\n",
      "          1.0342e+00, -2.0276e-01,  5.7812e-01],\n",
      "        [-6.8701e-01,  4.8535e-01, -2.3328e-01, -2.7124e-01,  4.0967e-01,\n",
      "         -4.4824e-01,  1.1377e+00, -4.5630e-01, -9.7900e-01, -5.5566e-01,\n",
      "          1.2822e+00, -2.0227e-01,  1.0176e+00],\n",
      "        [ 1.8591e-01,  5.4199e-01,  5.5029e-01, -3.2031e-01,  6.0699e-02,\n",
      "         -6.2744e-01,  1.7920e+00, -3.9624e-01, -7.0007e-02, -7.1436e-01,\n",
      "          2.0654e-01,  4.7827e-01,  3.0273e-01],\n",
      "        [-6.7480e-01, -1.2659e-01, -1.4856e-01, -2.7271e-01,  2.8345e-01,\n",
      "         -2.6636e-01,  1.0333e-01, -1.3330e-01, -8.7451e-01, -2.9932e-01,\n",
      "          6.9629e-01, -3.8574e-01,  1.2520e+00],\n",
      "        [ 1.2830e-01, -5.4291e-02,  4.2450e-02, -3.0103e-01,  4.1040e-01,\n",
      "         -8.9355e-01,  1.5234e+00,  2.5122e-01, -1.2227e+00,  2.3962e-01,\n",
      "          1.0254e+00,  3.8745e-01,  5.8887e-01],\n",
      "        [-5.4535e-02,  2.5055e-02, -4.9731e-01, -1.4465e-01,  5.9082e-01,\n",
      "         -1.3525e-01,  1.1826e+00, -4.1455e-01, -5.3857e-01, -9.3506e-01,\n",
      "          9.4727e-01, -1.9897e-02,  1.4062e+00],\n",
      "        [-8.5107e-01,  4.0576e-01, -3.0127e-01, -1.9385e-01,  5.3760e-01,\n",
      "         -1.8823e-01,  1.2021e+00, -4.4385e-01, -1.0146e+00, -3.4814e-01,\n",
      "          8.9502e-01, -2.4988e-01,  9.3359e-01]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "Labels: tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\n",
      "Logits shape: torch.Size([16, 13])\n",
      "Labels shape: torch.Size([16, 13])\n",
      "loss: 0.7181525826454163\n",
      "preds: tensor([[0.4521, 0.4910, 0.4333, 0.5244, 0.6377, 0.2428, 0.7295, 0.3816, 0.2876,\n",
      "         0.4788, 0.8081, 0.5454, 0.3406],\n",
      "        [0.5762, 0.3613, 0.5166, 0.4861, 0.5562, 0.4829, 0.6084, 0.5361, 0.4922,\n",
      "         0.5396, 0.7212, 0.7275, 0.5337],\n",
      "        [0.3245, 0.5840, 0.4231, 0.4360, 0.5889, 0.4048, 0.7280, 0.5474, 0.1678,\n",
      "         0.3796, 0.7422, 0.4546, 0.7290],\n",
      "        [0.3433, 0.5288, 0.3652, 0.4861, 0.5728, 0.3672, 0.8105, 0.4814, 0.2474,\n",
      "         0.4568, 0.7485, 0.3730, 0.6885],\n",
      "        [0.3528, 0.5952, 0.5322, 0.4641, 0.6191, 0.2737, 0.6333, 0.4995, 0.2874,\n",
      "         0.4187, 0.6235, 0.5723, 0.7964],\n",
      "        [0.4553, 0.3804, 0.4707, 0.4819, 0.6562, 0.1869, 0.6279, 0.4055, 0.4080,\n",
      "         0.1779, 0.6772, 0.4006, 0.7144],\n",
      "        [0.2869, 0.4993, 0.3516, 0.4910, 0.6782, 0.4897, 0.7012, 0.3076, 0.3601,\n",
      "         0.3665, 0.7793, 0.3660, 0.5981],\n",
      "        [0.3184, 0.4448, 0.3650, 0.5186, 0.7505, 0.4104, 0.5664, 0.3899, 0.3713,\n",
      "         0.3391, 0.6846, 0.3770, 0.6387],\n",
      "        [0.5747, 0.3149, 0.3516, 0.3318, 0.6035, 0.2842, 0.6230, 0.2047, 0.3352,\n",
      "         0.3899, 0.6450, 0.3125, 0.4954],\n",
      "        [0.2260, 0.4644, 0.4336, 0.5366, 0.6792, 0.3708, 0.6421, 0.2949, 0.3906,\n",
      "         0.4292, 0.7378, 0.4495, 0.6406],\n",
      "        [0.3347, 0.6191, 0.4419, 0.4326, 0.6011, 0.3899, 0.7573, 0.3879, 0.2732,\n",
      "         0.3645, 0.7827, 0.4497, 0.7344],\n",
      "        [0.5464, 0.6323, 0.6343, 0.4207, 0.5151, 0.3481, 0.8569, 0.4021, 0.4824,\n",
      "         0.3286, 0.5513, 0.6172, 0.5752],\n",
      "        [0.3374, 0.4685, 0.4629, 0.4321, 0.5703, 0.4338, 0.5259, 0.4668, 0.2944,\n",
      "         0.4258, 0.6675, 0.4048, 0.7778],\n",
      "        [0.5322, 0.4863, 0.5107, 0.4253, 0.6011, 0.2903, 0.8208, 0.5625, 0.2274,\n",
      "         0.5596, 0.7358, 0.5957, 0.6431],\n",
      "        [0.4863, 0.5063, 0.3782, 0.4639, 0.6436, 0.4663, 0.7656, 0.3977, 0.3684,\n",
      "         0.2820, 0.7207, 0.4951, 0.8032],\n",
      "        [0.2993, 0.6001, 0.4253, 0.4517, 0.6313, 0.4531, 0.7690, 0.3909, 0.2661,\n",
      "         0.4138, 0.7100, 0.4377, 0.7178]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<SigmoidBackward0>)\n",
      "Logits: tensor([[-0.3462,  0.0310, -0.5132, -0.5518,  0.3660, -0.0031,  0.9189, -0.4517,\n",
      "         -1.2041, -0.2013,  0.5093, -0.3535,  1.7246],\n",
      "        [-0.5801, -0.1364, -0.5645, -0.0685,  0.0460, -0.5405,  0.7886, -0.8818,\n",
      "         -0.8882, -1.0205,  0.4790, -0.6558,  0.6143],\n",
      "        [-0.4089,  0.3264, -0.9243, -0.9966,  0.6440, -0.2395,  0.4429, -0.7495,\n",
      "         -0.7368, -0.5122,  1.0020, -0.0079,  0.9370],\n",
      "        [-0.0117, -0.3005, -0.3538, -0.7061,  0.5972, -0.2600,  0.4426, -0.3838,\n",
      "         -0.5962, -0.7383,  1.0811, -0.5420,  1.5166],\n",
      "        [-0.9277, -0.4692, -0.5010, -0.0916,  0.6494, -1.0322,  0.2491, -0.6587,\n",
      "         -1.2959, -1.0391,  0.5337, -0.3599,  0.7319],\n",
      "        [-0.0107, -0.4797, -0.4287,  0.0609,  0.4934, -0.8984,  0.3418, -0.6831,\n",
      "         -0.8887, -0.4265,  0.8921,  0.0273, -0.4714],\n",
      "        [ 0.4031,  1.0918, -0.2227, -1.0049,  1.1045, -1.6582,  0.2238, -0.3477,\n",
      "         -1.1807,  0.0551,  1.7930,  0.3450, -0.4187],\n",
      "        [-0.7563,  0.4194, -0.5635, -0.7178,  0.2366, -0.5317,  0.5474, -0.4260,\n",
      "         -0.9048, -0.4170,  1.0166, -0.4580,  0.8164],\n",
      "        [-0.8950, -0.6562, -0.5508, -0.0094,  0.5947, -0.9331,  0.4739, -0.8442,\n",
      "         -1.0615, -0.7700,  0.7686, -0.8765,  0.1209],\n",
      "        [ 0.1030,  0.1771,  0.1010, -0.6313,  0.3062, -0.7358,  1.1162, -0.9438,\n",
      "         -0.6270, -0.4861,  0.3665,  0.2498,  0.6792],\n",
      "        [-0.2047,  0.1797, -0.3535, -0.6450,  0.2983, -0.7515,  0.8276, -0.3608,\n",
      "         -0.9731, -0.8643,  0.0475, -0.0351,  1.5703],\n",
      "        [-1.1211,  0.0540, -0.5200, -0.4341,  0.1569, -0.9878,  0.7393, -0.2031,\n",
      "         -1.2881, -0.6733,  0.4631, -0.5703,  0.6387],\n",
      "        [-0.4731, -0.2795, -0.7280, -0.0201,  0.5703, -0.8433,  0.4626, -0.2854,\n",
      "         -1.4102, -0.6431,  0.4741, -0.8057,  0.9858],\n",
      "        [-0.7134,  0.1246, -1.0273, -0.3044,  1.0996,  0.1113,  0.6221, -0.5513,\n",
      "         -0.6885, -0.9634,  0.5693, -1.1709,  1.1699],\n",
      "        [-0.3208, -0.4526, -0.9526, -0.0325,  0.6221, -0.5200,  0.4778, -0.6357,\n",
      "         -1.3574, -0.6011,  0.0972, -0.6494,  0.7070],\n",
      "        [ 0.6406, -0.3657,  0.1038,  0.1235,  0.9800, -0.7505,  0.0273, -0.0691,\n",
      "         -1.5127,  1.1855,  0.1505, -0.5854,  0.7495]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "Labels: tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\n",
      "Logits shape: torch.Size([16, 13])\n",
      "Labels shape: torch.Size([16, 13])\n",
      "loss: 0.6813187599182129\n",
      "preds: tensor([[0.4143, 0.5078, 0.3745, 0.3655, 0.5903, 0.4993, 0.7148, 0.3889, 0.2307,\n",
      "         0.4500, 0.6245, 0.4126, 0.8486],\n",
      "        [0.3589, 0.4661, 0.3625, 0.4829, 0.5117, 0.3682, 0.6875, 0.2927, 0.2915,\n",
      "         0.2649, 0.6177, 0.3418, 0.6489],\n",
      "        [0.3992, 0.5811, 0.2842, 0.2695, 0.6558, 0.4404, 0.6089, 0.3210, 0.3237,\n",
      "         0.3748, 0.7314, 0.4980, 0.7183],\n",
      "        [0.4971, 0.4255, 0.4124, 0.3306, 0.6450, 0.4353, 0.6089, 0.4053, 0.3552,\n",
      "         0.3235, 0.7466, 0.3677, 0.8198],\n",
      "        [0.2834, 0.3848, 0.3772, 0.4771, 0.6567, 0.2627, 0.5620, 0.3411, 0.2148,\n",
      "         0.2612, 0.6304, 0.4109, 0.6753],\n",
      "        [0.4973, 0.3823, 0.3945, 0.5151, 0.6211, 0.2893, 0.5845, 0.3354, 0.2915,\n",
      "         0.3950, 0.7095, 0.5068, 0.3843],\n",
      "        [0.5996, 0.7485, 0.4446, 0.2681, 0.7510, 0.1600, 0.5557, 0.4141, 0.2350,\n",
      "         0.5137, 0.8574, 0.5854, 0.3967],\n",
      "        [0.3193, 0.6035, 0.3628, 0.3279, 0.5591, 0.3701, 0.6333, 0.3950, 0.2881,\n",
      "         0.3972, 0.7344, 0.3875, 0.6934],\n",
      "        [0.2900, 0.3416, 0.3657, 0.4976, 0.6445, 0.2822, 0.6162, 0.3005, 0.2571,\n",
      "         0.3164, 0.6831, 0.2939, 0.5303],\n",
      "        [0.5259, 0.5439, 0.5254, 0.3472, 0.5762, 0.3240, 0.7534, 0.2800, 0.3481,\n",
      "         0.3809, 0.5908, 0.5620, 0.6636],\n",
      "        [0.4490, 0.5449, 0.4126, 0.3440, 0.5742, 0.3206, 0.6958, 0.4106, 0.2742,\n",
      "         0.2964, 0.5117, 0.4912, 0.8276],\n",
      "        [0.2458, 0.5137, 0.3728, 0.3931, 0.5391, 0.2712, 0.6768, 0.4495, 0.2162,\n",
      "         0.3376, 0.6138, 0.3611, 0.6543],\n",
      "        [0.3838, 0.4307, 0.3257, 0.4949, 0.6387, 0.3008, 0.6138, 0.4292, 0.1962,\n",
      "         0.3445, 0.6162, 0.3088, 0.7280],\n",
      "        [0.3289, 0.5312, 0.2637, 0.4246, 0.7500, 0.5278, 0.6509, 0.3655, 0.3345,\n",
      "         0.2761, 0.6387, 0.2367, 0.7632],\n",
      "        [0.4204, 0.3887, 0.2783, 0.4919, 0.6509, 0.3728, 0.6172, 0.3462, 0.2047,\n",
      "         0.3540, 0.5244, 0.3430, 0.6699],\n",
      "        [0.6548, 0.4097, 0.5259, 0.5308, 0.7271, 0.3208, 0.5068, 0.4827, 0.1805,\n",
      "         0.7661, 0.5376, 0.3577, 0.6792]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<SigmoidBackward0>)\n",
      "Logits: tensor([[ 0.0131, -0.7603, -0.0933, -0.6953, -0.0690, -1.0439,  0.5137, -1.3467,\n",
      "         -0.3574, -0.0911,  0.6187,  0.4436, -0.6050],\n",
      "        [-1.0557, -0.2959, -0.1171, -0.6357,  0.1229, -1.0664,  0.4719, -0.9692,\n",
      "         -0.5918, -0.5308, -0.5083, -1.0225,  1.1445],\n",
      "        [-0.3701, -1.0938, -0.6509, -0.3376, -0.1387, -0.9761,  0.1327, -0.7593,\n",
      "         -1.0098, -0.9565, -0.2135, -0.5645,  0.7793],\n",
      "        [ 0.4390, -0.4487, -0.0800,  0.0267,  0.9487, -0.5933, -0.1714, -0.3269,\n",
      "         -1.4883,  0.9985,  0.0733, -0.6621,  0.6475],\n",
      "        [-0.2185,  0.4971,  0.1140, -0.3384,  0.7964, -1.2227,  0.5796, -0.9463,\n",
      "         -1.4307,  0.0186, -0.4395, -0.3206,  0.6802],\n",
      "        [-0.9194, -0.5957, -0.8408, -0.1234, -0.5747, -1.1592,  0.8521, -0.1130,\n",
      "         -1.5430, -0.7246, -0.4397, -0.3828,  1.0801],\n",
      "        [-1.3711, -0.5493, -1.0332, -0.5532,  0.2271, -0.8530,  0.8633, -1.0283,\n",
      "         -1.3125, -0.7368,  0.3198, -0.5703,  0.4727],\n",
      "        [-0.0953, -0.2111, -1.1133, -0.1935,  0.3674,  0.2522, -0.1084,  0.0248,\n",
      "         -1.5371,  0.2330,  0.0861,  0.1017, -0.0636],\n",
      "        [-0.6548, -0.5464, -1.2305, -0.5586,  0.2043, -0.3674, -0.0607, -0.7900,\n",
      "         -1.6895, -1.1172,  0.0076, -0.7651,  0.8364],\n",
      "        [-1.0645, -0.7974, -0.7085, -0.0762,  0.0689, -1.3730, -0.2349, -0.6978,\n",
      "         -1.4971, -0.7256,  0.2314, -0.8110,  0.2374],\n",
      "        [ 0.5845, -0.4512,  0.1218, -0.0989,  1.2451, -0.9951, -0.0164, -0.2991,\n",
      "         -1.4844,  1.0996,  0.1215, -0.6118,  0.8315],\n",
      "        [-0.8037, -0.1604, -1.1348, -0.5771, -0.1409, -1.3057, -0.3003, -0.0181,\n",
      "         -0.9941, -1.0693,  0.5605, -0.4890,  0.2722],\n",
      "        [-1.1152, -0.4038, -0.4800, -0.3438, -0.1464, -0.7651,  0.3965, -1.0684,\n",
      "         -1.3770, -1.0664,  0.1151, -0.2358,  0.6221],\n",
      "        [-0.9917, -0.5522, -1.0381, -0.4934,  0.2732, -0.8853,  0.3940, -0.8140,\n",
      "         -1.5723, -0.9033,  0.2983, -0.6890,  0.6533],\n",
      "        [-1.4248, -0.2510, -0.7524, -0.5898,  0.0385, -1.1953,  0.4802, -0.7222,\n",
      "         -1.6406, -0.9116, -0.0946, -0.8438,  1.2129],\n",
      "        [-0.3457, -0.7646, -1.0205, -0.5879, -0.2532, -0.7729, -0.4512, -0.3943,\n",
      "         -1.1553, -1.0205, -0.0094, -0.6978,  1.6221]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "Labels: tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "Logits shape: torch.Size([16, 13])\n",
      "Labels shape: torch.Size([16, 13])\n",
      "loss: 0.6068643927574158\n",
      "preds: tensor([[0.5034, 0.3186, 0.4768, 0.3328, 0.4827, 0.2605, 0.6255, 0.2064, 0.4116,\n",
      "         0.4773, 0.6499, 0.6089, 0.3533],\n",
      "        [0.2581, 0.4265, 0.4707, 0.3462, 0.5308, 0.2561, 0.6157, 0.2751, 0.3562,\n",
      "         0.3704, 0.3755, 0.2646, 0.7583],\n",
      "        [0.4084, 0.2510, 0.3428, 0.4163, 0.4653, 0.2737, 0.5332, 0.3188, 0.2671,\n",
      "         0.2776, 0.4468, 0.3625, 0.6855],\n",
      "        [0.6079, 0.3896, 0.4800, 0.5068, 0.7207, 0.3560, 0.4573, 0.4189, 0.1842,\n",
      "         0.7310, 0.5186, 0.3403, 0.6562],\n",
      "        [0.4456, 0.6216, 0.5283, 0.4163, 0.6890, 0.2274, 0.6411, 0.2795, 0.1930,\n",
      "         0.5049, 0.3918, 0.4207, 0.6636],\n",
      "        [0.2852, 0.3552, 0.3013, 0.4692, 0.3601, 0.2388, 0.7012, 0.4717, 0.1761,\n",
      "         0.3264, 0.3918, 0.4055, 0.7466],\n",
      "        [0.2024, 0.3660, 0.2625, 0.3652, 0.5566, 0.2988, 0.7031, 0.2634, 0.2120,\n",
      "         0.3237, 0.5791, 0.3611, 0.6162],\n",
      "        [0.4763, 0.4475, 0.2473, 0.4517, 0.5908, 0.5625, 0.4729, 0.5063, 0.1770,\n",
      "         0.5581, 0.5215, 0.5254, 0.4841],\n",
      "        [0.3418, 0.3667, 0.2261, 0.3638, 0.5508, 0.4092, 0.4849, 0.3123, 0.1559,\n",
      "         0.2466, 0.5020, 0.3176, 0.6978],\n",
      "        [0.2563, 0.3105, 0.3298, 0.4810, 0.5171, 0.2021, 0.4417, 0.3323, 0.1829,\n",
      "         0.3262, 0.5576, 0.3076, 0.5591],\n",
      "        [0.6421, 0.3892, 0.5303, 0.4753, 0.7764, 0.2700, 0.4958, 0.4258, 0.1848,\n",
      "         0.7500, 0.5303, 0.3516, 0.6968],\n",
      "        [0.3093, 0.4600, 0.2433, 0.3596, 0.4648, 0.2133, 0.4255, 0.4954, 0.2700,\n",
      "         0.2556, 0.6367, 0.3801, 0.5679],\n",
      "        [0.2469, 0.4004, 0.3823, 0.4148, 0.4634, 0.3176, 0.5977, 0.2556, 0.2015,\n",
      "         0.2561, 0.5288, 0.4414, 0.6509],\n",
      "        [0.2705, 0.3652, 0.2615, 0.3792, 0.5679, 0.2920, 0.5972, 0.3071, 0.1719,\n",
      "         0.2883, 0.5742, 0.3342, 0.6577],\n",
      "        [0.1940, 0.4375, 0.3203, 0.3567, 0.5098, 0.2323, 0.6177, 0.3269, 0.1624,\n",
      "         0.2866, 0.4763, 0.3008, 0.7710],\n",
      "        [0.4143, 0.3176, 0.2649, 0.3572, 0.4370, 0.3159, 0.3892, 0.4026, 0.2395,\n",
      "         0.2649, 0.4976, 0.3323, 0.8350]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<SigmoidBackward0>)\n",
      "Logits: tensor([[-6.6553e-01, -3.5767e-01, -7.5293e-01, -1.0322e+00,  7.2510e-01,\n",
      "          3.3032e-01, -3.5187e-02, -1.2305e+00, -6.6260e-01, -9.3359e-01,\n",
      "          4.1895e-01, -2.4707e-01,  6.2012e-01],\n",
      "        [-6.6602e-01, -6.0596e-01, -7.9541e-01, -5.0439e-01, -3.9886e-02,\n",
      "         -1.8518e-01, -2.1753e-01, -1.5439e+00, -9.0430e-01, -1.3174e+00,\n",
      "         -1.0852e-01, -5.5029e-01,  1.9702e-01],\n",
      "        [-8.1104e-01,  1.1676e-01, -5.0537e-01, -1.2939e+00, -2.0813e-01,\n",
      "         -1.0879e+00, -2.3621e-01, -5.6787e-01, -1.3516e+00, -7.6318e-01,\n",
      "          2.1301e-01, -3.7646e-01,  9.9902e-01],\n",
      "        [-8.5840e-01, -4.5703e-01,  1.8799e-01, -8.5742e-01, -5.5322e-01,\n",
      "         -4.8975e-01, -3.6133e-01, -1.0732e+00, -1.2480e+00, -1.1846e+00,\n",
      "          3.2153e-01, -9.0576e-01,  4.7119e-01],\n",
      "        [-8.3838e-01, -9.6387e-01, -6.8848e-01, -5.7959e-01, -1.9202e-01,\n",
      "         -1.2148e+00, -1.9135e-02, -6.0449e-01, -1.6611e+00, -1.5293e+00,\n",
      "          6.9397e-02, -6.6113e-01,  7.3584e-01],\n",
      "        [-1.0400e+00, -6.4209e-01, -1.2041e+00, -1.0645e+00, -1.8152e-01,\n",
      "         -4.4287e-01,  2.0728e-01, -1.1299e+00, -1.5957e+00, -1.1523e+00,\n",
      "          2.4561e-01, -6.1768e-01,  5.2148e-01],\n",
      "        [-6.3281e-01, -6.8359e-01,  6.2354e-01,  4.6802e-01,  2.2266e-01,\n",
      "         -1.2129e+00, -4.0924e-02, -6.9873e-01, -2.8125e-01, -1.1318e+00,\n",
      "          7.2937e-02, -1.3701e+00,  7.6416e-01],\n",
      "        [-4.8022e-01, -5.7715e-01, -2.4524e-01, -5.1074e-01, -1.6748e-01,\n",
      "         -1.5928e+00, -4.1138e-01, -8.0811e-01, -9.1260e-01, -1.5439e+00,\n",
      "         -1.3940e-01, -8.3301e-01,  1.0332e+00],\n",
      "        [-9.2871e-01, -9.3799e-01, -1.4111e+00, -5.5566e-01, -2.9395e-01,\n",
      "         -6.8652e-01, -8.0109e-04, -5.0391e-01, -1.8018e+00, -1.4658e+00,\n",
      "         -5.5078e-01, -9.9561e-01,  8.7793e-01],\n",
      "        [-9.5508e-01, -1.1152e+00, -6.5479e-01, -8.9648e-01, -3.5791e-01,\n",
      "         -1.3418e+00,  4.8120e-01, -8.9795e-01, -1.1855e+00, -7.7490e-01,\n",
      "         -2.3950e-01, -7.8662e-01,  9.1614e-02],\n",
      "        [-4.8730e-01, -1.1074e+00, -7.5000e-01, -8.6914e-01, -9.5886e-02,\n",
      "         -1.4355e+00,  1.1371e-01, -6.7188e-01, -1.2373e+00, -9.5215e-01,\n",
      "          7.1220e-03, -8.7354e-01,  9.5459e-01],\n",
      "        [ 4.6021e-01, -5.0244e-01,  4.4189e-02, -1.2103e-01,  1.0352e+00,\n",
      "         -1.1016e+00, -1.4702e-02, -2.6294e-01, -1.8184e+00,  1.0840e+00,\n",
      "          1.0559e-01, -5.8398e-01,  7.7100e-01],\n",
      "        [-8.0505e-02, -1.0938e+00, -5.9668e-01, -2.5708e-01, -3.8574e-01,\n",
      "         -7.9053e-01, -9.0234e-01, -6.2598e-01, -8.7109e-01, -1.0928e+00,\n",
      "          9.9258e-03, -5.5859e-01,  1.2490e+00],\n",
      "        [-1.0010e+00, -7.0752e-01,  1.9824e-01, -3.8721e-01, -4.1064e-01,\n",
      "         -6.8848e-01,  4.7314e-01, -9.5801e-01, -1.1904e+00, -9.7119e-01,\n",
      "         -6.0205e-01, -7.1826e-01, -1.5344e-01],\n",
      "        [-6.3721e-01, -2.5854e-01, -5.9033e-01, -1.2529e+00, -4.0723e-01,\n",
      "         -7.0703e-01,  2.3157e-01, -7.1924e-01, -1.1914e+00, -7.8027e-01,\n",
      "         -1.3684e-01, -3.0933e-01,  1.0918e+00],\n",
      "        [ 5.7251e-02, -3.7744e-01, -6.3379e-01, -6.0596e-01,  1.8005e-01,\n",
      "         -1.3037e+00, -3.0640e-01, -8.9502e-01, -1.1660e+00, -1.1211e+00,\n",
      "         -3.7720e-01, -1.7517e-01,  1.1689e+00]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "Labels: tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\n",
      "Logits shape: torch.Size([16, 13])\n",
      "Labels shape: torch.Size([16, 13])\n",
      "loss: 0.5299882888793945\n",
      "preds: tensor([[0.3396, 0.4116, 0.3201, 0.2627, 0.6738, 0.5820, 0.4912, 0.2261, 0.3401,\n",
      "         0.2822, 0.6030, 0.4385, 0.6504],\n",
      "        [0.3394, 0.3530, 0.3110, 0.3765, 0.4900, 0.4539, 0.4458, 0.1759, 0.2881,\n",
      "         0.2113, 0.4729, 0.3657, 0.5493],\n",
      "        [0.3076, 0.5293, 0.3762, 0.2152, 0.4482, 0.2520, 0.4412, 0.3618, 0.2056,\n",
      "         0.3179, 0.5532, 0.4070, 0.7310],\n",
      "        [0.2976, 0.3877, 0.5469, 0.2979, 0.3652, 0.3799, 0.4106, 0.2549, 0.2230,\n",
      "         0.2343, 0.5796, 0.2878, 0.6157],\n",
      "        [0.3018, 0.2761, 0.3345, 0.3591, 0.4521, 0.2289, 0.4951, 0.3533, 0.1597,\n",
      "         0.1781, 0.5176, 0.3406, 0.6763],\n",
      "        [0.2612, 0.3447, 0.2307, 0.2563, 0.4548, 0.3911, 0.5518, 0.2441, 0.1686,\n",
      "         0.2401, 0.5610, 0.3503, 0.6274],\n",
      "        [0.3469, 0.3354, 0.6509, 0.6147, 0.5557, 0.2292, 0.4897, 0.3320, 0.4302,\n",
      "         0.2438, 0.5181, 0.2026, 0.6821],\n",
      "        [0.3821, 0.3596, 0.4390, 0.3750, 0.4583, 0.1689, 0.3987, 0.3083, 0.2864,\n",
      "         0.1759, 0.4651, 0.3030, 0.7373],\n",
      "        [0.2832, 0.2812, 0.1960, 0.3645, 0.4270, 0.3347, 0.4998, 0.3767, 0.1416,\n",
      "         0.1876, 0.3657, 0.2698, 0.7065],\n",
      "        [0.2778, 0.2469, 0.3418, 0.2898, 0.4114, 0.2073, 0.6182, 0.2896, 0.2340,\n",
      "         0.3154, 0.4404, 0.3130, 0.5229],\n",
      "        [0.3806, 0.2483, 0.3208, 0.2954, 0.4761, 0.1923, 0.5283, 0.3381, 0.2249,\n",
      "         0.2786, 0.5020, 0.2944, 0.7222],\n",
      "        [0.6133, 0.3770, 0.5112, 0.4697, 0.7378, 0.2494, 0.4963, 0.4346, 0.1396,\n",
      "         0.7471, 0.5264, 0.3579, 0.6836],\n",
      "        [0.4800, 0.2510, 0.3552, 0.4360, 0.4048, 0.3120, 0.2886, 0.3484, 0.2949,\n",
      "         0.2510, 0.5024, 0.3638, 0.7773],\n",
      "        [0.2688, 0.3301, 0.5493, 0.4043, 0.3987, 0.3345, 0.6162, 0.2773, 0.2332,\n",
      "         0.2747, 0.3538, 0.3279, 0.4617],\n",
      "        [0.3459, 0.4358, 0.3564, 0.2222, 0.3997, 0.3303, 0.5576, 0.3276, 0.2330,\n",
      "         0.3142, 0.4658, 0.4233, 0.7485],\n",
      "        [0.5142, 0.4067, 0.3467, 0.3530, 0.5449, 0.2135, 0.4241, 0.2900, 0.2375,\n",
      "         0.2458, 0.4067, 0.4563, 0.7632]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<SigmoidBackward0>)\n",
      "Logits: tensor([[-1.2852, -0.7603, -0.9609, -0.7588, -0.3948, -1.2432, -0.2006, -1.2354,\n",
      "         -1.7256, -1.2861, -0.1624, -0.9346,  0.2820],\n",
      "        [-1.3027, -0.1102, -1.1064, -0.8906, -0.1655, -1.2285, -0.8682, -0.9854,\n",
      "         -1.2080, -1.5742, -0.2512, -0.7104,  1.0498],\n",
      "        [-0.9976, -1.1465, -1.4512, -0.7129, -0.8120, -0.9844, -0.1975, -1.4912,\n",
      "         -1.7764, -1.1660, -0.1318, -1.3701,  0.3713],\n",
      "        [-1.3447, -0.6963, -0.9448, -0.6260, -0.6797, -0.6885, -0.5620, -1.1719,\n",
      "         -2.1406, -1.3711, -0.6079,  0.1960,  0.8740],\n",
      "        [-0.2277, -1.0928, -0.8916, -0.6147, -0.4495, -0.6343, -0.2942, -0.3875,\n",
      "         -1.6191, -1.3701, -0.5415, -1.5322,  0.8130],\n",
      "        [-0.9971, -1.9600, -0.8208, -0.3621, -0.3640, -0.7065, -0.5098, -1.2969,\n",
      "         -1.6113, -1.8652, -0.8599, -0.9829,  0.1927],\n",
      "        [-0.4885, -0.9067, -1.0488, -0.6851, -0.0216, -0.5161, -0.5781, -1.1504,\n",
      "         -1.1924, -0.9326, -0.0537, -0.9019,  0.9800],\n",
      "        [-0.9707, -1.0635, -1.2334, -0.5669, -0.6274, -0.7510, -0.4417, -0.8550,\n",
      "         -2.0352, -1.6875, -0.6006, -0.7959,  1.1162],\n",
      "        [ 0.3030, -0.6353, -0.0880, -0.1583,  1.0371, -1.2236, -0.1925, -0.4309,\n",
      "         -1.8613,  0.9365,  0.0479, -0.6855,  0.7866],\n",
      "        [-0.2498, -0.5425, -1.2412, -0.2399,  0.1622,  0.0258, -0.2495, -0.2212,\n",
      "         -1.6006, -0.0525, -0.1975, -0.0658, -0.0940],\n",
      "        [-0.8647, -0.5464, -0.9614, -0.1002,  0.2744, -0.4609, -0.3379, -0.8203,\n",
      "         -1.4775, -0.6479,  0.8784, -0.2676,  0.2198],\n",
      "        [-0.6162, -0.8237, -0.2417, -0.8838, -0.0837, -0.3635,  0.1039, -1.4268,\n",
      "         -1.3115, -1.1807,  0.0291, -0.9224,  0.5752],\n",
      "        [-0.2810, -0.5117, -1.3301, -0.6802,  0.1793, -1.1484,  0.2043, -0.8379,\n",
      "         -1.5254, -1.3438,  0.4036, -0.3601, -0.1411],\n",
      "        [-0.8701, -0.7583, -0.6680, -0.7866, -0.3411, -1.2607,  0.2141, -1.0508,\n",
      "         -1.2871, -0.8682, -0.6689, -1.1055,  0.6333],\n",
      "        [-0.4170, -1.0498, -0.9326, -0.7051,  0.3877, -0.8784, -0.3359, -0.8584,\n",
      "         -1.6670, -1.2822, -0.3489, -0.7798,  0.5391],\n",
      "        [-1.0088, -1.4609, -0.7671, -0.7554, -0.7178, -1.1943, -0.1763, -1.0967,\n",
      "         -2.0527, -1.3516, -0.4983, -1.5674,  0.1879]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "Labels: tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\n",
      "Logits shape: torch.Size([16, 13])\n",
      "Labels shape: torch.Size([16, 13])\n",
      "loss: 0.4645193815231323\n",
      "preds: tensor([[0.2167, 0.3186, 0.2766, 0.3188, 0.4026, 0.2239, 0.4500, 0.2252, 0.1511,\n",
      "         0.2166, 0.4595, 0.2820, 0.5698],\n",
      "        [0.2137, 0.4724, 0.2485, 0.2910, 0.4587, 0.2264, 0.2957, 0.2717, 0.2301,\n",
      "         0.1716, 0.4375, 0.3296, 0.7407],\n",
      "        [0.2695, 0.2411, 0.1898, 0.3289, 0.3074, 0.2720, 0.4507, 0.1837, 0.1448,\n",
      "         0.2375, 0.4670, 0.2026, 0.5918],\n",
      "        [0.2068, 0.3325, 0.2800, 0.3484, 0.3364, 0.3345, 0.3630, 0.2366, 0.1052,\n",
      "         0.2024, 0.3525, 0.5488, 0.7056],\n",
      "        [0.4434, 0.2510, 0.2908, 0.3511, 0.3894, 0.3464, 0.4270, 0.4043, 0.1653,\n",
      "         0.2026, 0.3679, 0.1776, 0.6929],\n",
      "        [0.2695, 0.1235, 0.3057, 0.4104, 0.4099, 0.3303, 0.3752, 0.2147, 0.1664,\n",
      "         0.1340, 0.2974, 0.2722, 0.5479],\n",
      "        [0.3801, 0.2876, 0.2595, 0.3352, 0.4946, 0.3738, 0.3594, 0.2405, 0.2328,\n",
      "         0.2825, 0.4866, 0.2886, 0.7271],\n",
      "        [0.2747, 0.2566, 0.2256, 0.3621, 0.3481, 0.3206, 0.3914, 0.2983, 0.1155,\n",
      "         0.1561, 0.3542, 0.3108, 0.7534],\n",
      "        [0.5752, 0.3464, 0.4780, 0.4604, 0.7383, 0.2273, 0.4519, 0.3938, 0.1345,\n",
      "         0.7183, 0.5117, 0.3350, 0.6870],\n",
      "        [0.4380, 0.3677, 0.2242, 0.4404, 0.5405, 0.5063, 0.4380, 0.4448, 0.1678,\n",
      "         0.4868, 0.4507, 0.4836, 0.4766],\n",
      "        [0.2964, 0.3667, 0.2766, 0.4751, 0.5684, 0.3867, 0.4163, 0.3057, 0.1858,\n",
      "         0.3435, 0.7065, 0.4336, 0.5547],\n",
      "        [0.3506, 0.3049, 0.4399, 0.2925, 0.4790, 0.4102, 0.5259, 0.1936, 0.2123,\n",
      "         0.2350, 0.5073, 0.2844, 0.6401],\n",
      "        [0.4302, 0.3748, 0.2091, 0.3362, 0.5449, 0.2407, 0.5508, 0.3020, 0.1787,\n",
      "         0.2069, 0.5996, 0.4109, 0.4648],\n",
      "        [0.2952, 0.3191, 0.3389, 0.3130, 0.4155, 0.2208, 0.5532, 0.2590, 0.2163,\n",
      "         0.2957, 0.3386, 0.2487, 0.6533],\n",
      "        [0.3972, 0.2593, 0.2825, 0.3306, 0.5957, 0.2935, 0.4167, 0.2976, 0.1588,\n",
      "         0.2172, 0.4136, 0.3145, 0.6318],\n",
      "        [0.2673, 0.1884, 0.3171, 0.3196, 0.3279, 0.2325, 0.4561, 0.2502, 0.1138,\n",
      "         0.2056, 0.3779, 0.1726, 0.5469]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<SigmoidBackward0>)\n",
      "Logits: tensor([[-0.3511, -1.7734, -0.9180, -1.0107, -0.9268, -1.3643, -0.8315, -1.2852,\n",
      "         -1.6807, -1.7246, -0.7769, -1.1562,  0.1560],\n",
      "        [-0.4358, -1.1240, -0.8457, -0.7422, -0.9453, -0.9932, -0.9370, -1.9727,\n",
      "         -1.8799, -1.6338, -0.7603, -0.9482,  0.3608],\n",
      "        [-0.8711, -0.7246, -0.5234, -0.3599,  0.0714, -1.4238, -0.3787, -1.6104,\n",
      "         -1.3379,  0.0456,  0.8198,  0.1277, -0.4255],\n",
      "        [-1.5068, -1.4014, -1.1553, -0.6968, -0.9209, -1.2998, -0.7178, -1.4512,\n",
      "         -1.4629, -1.4971, -1.1084, -1.4326,  0.0275],\n",
      "        [-0.5151, -0.9780, -0.8848, -0.4941, -0.6582, -0.9702, -0.6421, -1.4756,\n",
      "         -1.9316, -1.5762, -1.1895, -0.7847,  0.7988],\n",
      "        [-0.5957, -1.4033, -1.1260, -0.7305, -0.5132, -0.6958, -0.5610, -1.6855,\n",
      "         -1.8047, -1.6621, -1.8125, -1.3154,  0.2786],\n",
      "        [ 0.1599, -0.4790, -1.3301, -1.2207,  0.2800, -1.2998, -0.8130, -1.2520,\n",
      "         -1.6689, -1.5713, -0.6094, -0.5327, -0.2515],\n",
      "        [-0.7944, -1.3262, -0.5410, -0.4631, -0.9370, -1.3496, -0.3604, -1.9434,\n",
      "         -1.4756, -1.5586, -1.1494, -0.9438,  0.1759],\n",
      "        [-1.1484, -0.9619, -1.0527, -1.0225, -0.8271, -1.2109, -0.7837, -1.1016,\n",
      "         -1.9902, -1.8408, -0.9868, -1.0820,  0.4216],\n",
      "        [ 0.0617, -1.4326, -0.8984, -0.8037, -0.2634, -0.6108, -0.3250, -1.4697,\n",
      "         -1.4951, -1.7158, -1.1084, -0.3481,  0.0535],\n",
      "        [-0.7627, -0.6621, -1.0830, -1.4336, -0.2301, -0.7178, -0.9355, -1.3506,\n",
      "         -1.4434, -1.5254, -1.0029, -1.3477,  0.6270],\n",
      "        [-0.8999, -0.7593, -0.6460, -1.2471, -0.4045, -1.4268, -0.6602, -1.6924,\n",
      "         -1.4707, -1.6572, -0.8618, -0.4451, -0.3457],\n",
      "        [-0.7178, -1.5859, -1.6250, -1.2090, -0.8525, -1.2002, -0.9946, -1.4023,\n",
      "         -1.9092, -1.7705, -1.2246, -0.9741,  0.0995],\n",
      "        [-0.2366,  0.4153, -1.1729,  0.3438,  0.0447, -1.2939,  0.3926,  0.6025,\n",
      "         -0.4146,  0.5205,  1.3428, -0.0991, -0.4060],\n",
      "        [ 0.3892, -0.4441, -0.1500,  0.2742,  0.2231, -0.6831, -0.1065,  0.1125,\n",
      "         -1.1445,  0.4258,  0.6963, -1.2441,  0.4258],\n",
      "        [-1.6592, -1.0586, -1.0107, -1.0488, -0.7715, -1.6973,  0.0308, -1.5898,\n",
      "         -1.9629, -1.7900, -0.4333, -1.4219,  0.5415]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "Labels: tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\n",
      "Logits shape: torch.Size([16, 13])\n",
      "Labels shape: torch.Size([16, 13])\n",
      "loss: 0.44045647978782654\n",
      "preds: tensor([[0.4131, 0.1451, 0.2854, 0.2668, 0.2837, 0.2035, 0.3032, 0.2167, 0.1570,\n",
      "         0.1512, 0.3149, 0.2394, 0.5391],\n",
      "        [0.3928, 0.2452, 0.3003, 0.3225, 0.2798, 0.2703, 0.2815, 0.1221, 0.1324,\n",
      "         0.1633, 0.3186, 0.2793, 0.5894],\n",
      "        [0.2949, 0.3264, 0.3721, 0.4109, 0.5181, 0.1941, 0.4065, 0.1665, 0.2079,\n",
      "         0.5112, 0.6943, 0.5317, 0.3953],\n",
      "        [0.1814, 0.1976, 0.2395, 0.3325, 0.2847, 0.2142, 0.3279, 0.1898, 0.1880,\n",
      "         0.1829, 0.2482, 0.1927, 0.5068],\n",
      "        [0.3740, 0.2732, 0.2922, 0.3789, 0.3411, 0.2749, 0.3447, 0.1860, 0.1266,\n",
      "         0.1714, 0.2334, 0.3132, 0.6899],\n",
      "        [0.3552, 0.1973, 0.2449, 0.3252, 0.3745, 0.3328, 0.3633, 0.1564, 0.1412,\n",
      "         0.1594, 0.1404, 0.2115, 0.5693],\n",
      "        [0.5400, 0.3826, 0.2091, 0.2278, 0.5693, 0.2142, 0.3074, 0.2224, 0.1586,\n",
      "         0.1720, 0.3523, 0.3699, 0.4375],\n",
      "        [0.3113, 0.2098, 0.3679, 0.3862, 0.2815, 0.2059, 0.4109, 0.1252, 0.1860,\n",
      "         0.1738, 0.2406, 0.2800, 0.5439],\n",
      "        [0.2407, 0.2766, 0.2588, 0.2646, 0.3042, 0.2295, 0.3135, 0.2494, 0.1202,\n",
      "         0.1370, 0.2715, 0.2532, 0.6040],\n",
      "        [0.5156, 0.1927, 0.2893, 0.3093, 0.4346, 0.3518, 0.4194, 0.1870, 0.1831,\n",
      "         0.1525, 0.2482, 0.4138, 0.5132],\n",
      "        [0.3181, 0.3403, 0.2529, 0.1925, 0.4426, 0.3279, 0.2817, 0.2058, 0.1910,\n",
      "         0.1787, 0.2683, 0.2063, 0.6519],\n",
      "        [0.2891, 0.3188, 0.3440, 0.2233, 0.4001, 0.1936, 0.3408, 0.1555, 0.1869,\n",
      "         0.1602, 0.2969, 0.3906, 0.4143],\n",
      "        [0.3279, 0.1699, 0.1646, 0.2299, 0.2988, 0.2314, 0.2700, 0.1974, 0.1290,\n",
      "         0.1455, 0.2272, 0.2742, 0.5249],\n",
      "        [0.4412, 0.6025, 0.2363, 0.5850, 0.5112, 0.2152, 0.5967, 0.6460, 0.3977,\n",
      "         0.6274, 0.7930, 0.4753, 0.3999],\n",
      "        [0.5962, 0.3909, 0.4626, 0.5684, 0.5557, 0.3354, 0.4734, 0.5283, 0.2415,\n",
      "         0.6050, 0.6675, 0.2238, 0.6050],\n",
      "        [0.1599, 0.2576, 0.2668, 0.2595, 0.3162, 0.1548, 0.5078, 0.1694, 0.1232,\n",
      "         0.1431, 0.3933, 0.1943, 0.6323]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<SigmoidBackward0>)\n",
      "Logits: tensor([[-7.7588e-01, -8.8477e-01, -8.9844e-01, -1.1377e+00, -6.7383e-01,\n",
      "         -5.4395e-01, -2.4951e-01, -1.4717e+00, -1.8896e+00, -1.3271e+00,\n",
      "         -8.7354e-01, -7.2900e-01,  6.5332e-01],\n",
      "        [-1.0654e+00, -3.5791e-01, -5.8643e-01, -2.2876e-01,  2.2937e-01,\n",
      "         -4.1333e-01,  4.1089e-01, -1.0742e+00, -1.8936e+00, -1.2363e+00,\n",
      "         -3.1714e-01, -8.1494e-01, -7.0862e-02],\n",
      "        [-2.4060e-01,  4.4165e-01, -1.1143e+00,  3.4521e-01, -8.3160e-03,\n",
      "         -1.2861e+00,  5.0928e-01,  6.9141e-01, -4.8706e-01,  5.7324e-01,\n",
      "          1.4102e+00,  1.2138e-02, -3.9111e-01],\n",
      "        [-9.7510e-01, -5.4590e-01,  1.7810e-01, -1.4172e-01, -4.4971e-01,\n",
      "         -1.6562e+00, -5.2539e-01, -1.4219e+00, -1.5312e+00, -1.2539e+00,\n",
      "         -3.6401e-01, -3.7402e-01, -8.8672e-01],\n",
      "        [-9.1919e-02, -3.0005e-01, -5.2783e-01, -6.8262e-01, -9.2969e-01,\n",
      "         -7.2461e-01,  7.3438e-01, -1.2881e+00, -7.1436e-01, -1.6309e+00,\n",
      "         -1.1260e+00, -4.5068e-01, -5.7373e-01],\n",
      "        [-7.5000e-01, -1.7842e+00, -1.0879e+00, -7.8516e-01, -7.8760e-01,\n",
      "         -6.8164e-01, -6.9922e-01, -1.7275e+00, -1.8740e+00, -1.9688e+00,\n",
      "         -1.2178e+00, -1.3291e+00,  1.2718e-02],\n",
      "        [-8.3740e-01, -1.4951e+00, -9.8438e-01, -9.1504e-01, -1.0137e+00,\n",
      "         -1.1855e+00, -1.1436e+00, -1.2754e+00, -2.2812e+00, -1.8984e+00,\n",
      "         -9.3701e-01, -1.0381e+00,  1.7712e-01],\n",
      "        [-4.1089e-01, -1.0947e+00, -7.7441e-01, -8.9795e-01, -4.8169e-01,\n",
      "         -1.4512e+00,  4.1656e-03, -1.3340e+00, -1.4434e+00, -1.0547e+00,\n",
      "         -8.3789e-01, -2.2864e-01, -4.7119e-01],\n",
      "        [-7.0508e-01, -1.2227e+00, -1.0254e+00, -9.4482e-01, -8.5254e-01,\n",
      "         -7.1680e-01, -4.3018e-01, -1.9141e+00, -1.6504e+00, -1.1475e+00,\n",
      "         -8.4082e-01, -9.3262e-01,  1.8298e-01],\n",
      "        [-1.1953e+00, -1.1631e+00, -1.0381e+00, -9.9023e-01, -7.2656e-01,\n",
      "         -1.3955e+00, -1.0176e+00, -1.6152e+00, -2.0352e+00, -1.4307e+00,\n",
      "         -1.0068e+00, -9.7412e-01, -1.4612e-01],\n",
      "        [-3.6670e-01, -4.5410e-01, -1.0654e+00, -1.1328e+00, -3.9160e-01,\n",
      "         -7.8223e-01, -6.7725e-01, -7.6514e-01, -1.3770e+00, -1.8369e+00,\n",
      "         -3.0591e-01, -9.2822e-01,  1.1865e+00],\n",
      "        [-9.4678e-01, -8.1201e-01, -1.0947e+00, -1.1211e+00, -9.2090e-01,\n",
      "         -1.0996e+00, -5.4565e-02, -1.0820e+00, -1.6924e+00, -1.8633e+00,\n",
      "         -1.2354e+00, -9.5752e-01, -2.2949e-01],\n",
      "        [-2.6685e-01, -1.8188e-01, -2.2110e-02,  3.6792e-01,  1.1328e-01,\n",
      "         -7.5391e-01, -6.8652e-01,  1.4896e-03, -6.0010e-01,  9.1125e-02,\n",
      "          1.7285e+00,  9.2346e-02, -1.0596e-01],\n",
      "        [-9.1992e-01, -1.0684e+00, -6.5527e-01, -4.6216e-01, -5.9912e-01,\n",
      "         -1.1553e+00, -5.5078e-01, -1.8311e+00, -1.3760e+00, -1.2832e+00,\n",
      "         -1.2469e-01, -9.6436e-01, -4.9170e-01],\n",
      "        [-1.1104e+00, -1.4326e+00, -1.4707e+00, -1.0469e+00, -9.9414e-01,\n",
      "         -1.0244e+00, -4.9194e-01, -1.5732e+00, -1.7734e+00, -1.8076e+00,\n",
      "         -1.0215e+00, -1.2920e+00, -1.3257e-01],\n",
      "        [-3.8672e-01, -1.0840e+00, -9.5459e-01, -5.5176e-01, -6.3135e-01,\n",
      "         -1.2881e+00, -1.3538e-01, -1.7080e+00, -1.5420e+00, -1.1201e+00,\n",
      "         -7.0166e-01, -5.7422e-01, -4.9341e-01]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "Labels: tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "Logits shape: torch.Size([16, 13])\n",
      "Labels shape: torch.Size([16, 13])\n",
      "loss: 0.45283788442611694\n",
      "preds: tensor([[0.3152, 0.2922, 0.2893, 0.2428, 0.3376, 0.3672, 0.4380, 0.1866, 0.1312,\n",
      "         0.2096, 0.2944, 0.3254, 0.6577],\n",
      "        [0.2563, 0.4114, 0.3574, 0.4431, 0.5571, 0.3982, 0.6011, 0.2546, 0.1309,\n",
      "         0.2251, 0.4214, 0.3069, 0.4822],\n",
      "        [0.4402, 0.6089, 0.2471, 0.5854, 0.4978, 0.2166, 0.6245, 0.6665, 0.3806,\n",
      "         0.6396, 0.8037, 0.5029, 0.4036],\n",
      "        [0.2739, 0.3667, 0.5444, 0.4646, 0.3894, 0.1603, 0.3716, 0.1943, 0.1779,\n",
      "         0.2220, 0.4099, 0.4075, 0.2917],\n",
      "        [0.4771, 0.4255, 0.3711, 0.3357, 0.2830, 0.3264, 0.6758, 0.2162, 0.3286,\n",
      "         0.1637, 0.2449, 0.3892, 0.3604],\n",
      "        [0.3208, 0.1438, 0.2520, 0.3132, 0.3127, 0.3359, 0.3320, 0.1509, 0.1331,\n",
      "         0.1225, 0.2283, 0.2094, 0.5034],\n",
      "        [0.3020, 0.1831, 0.2720, 0.2859, 0.2664, 0.2340, 0.2417, 0.2184, 0.0927,\n",
      "         0.1302, 0.2815, 0.2615, 0.5439],\n",
      "        [0.3987, 0.2507, 0.3154, 0.2896, 0.3818, 0.1898, 0.5010, 0.2085, 0.1910,\n",
      "         0.2583, 0.3020, 0.4431, 0.3843],\n",
      "        [0.3306, 0.2274, 0.2639, 0.2800, 0.2988, 0.3281, 0.3940, 0.1285, 0.1610,\n",
      "         0.2410, 0.3013, 0.2825, 0.5454],\n",
      "        [0.2323, 0.2382, 0.2615, 0.2708, 0.3259, 0.1985, 0.2654, 0.1659, 0.1155,\n",
      "         0.1930, 0.2676, 0.2742, 0.4636],\n",
      "        [0.4094, 0.3884, 0.2563, 0.2437, 0.4033, 0.3137, 0.3369, 0.3176, 0.2015,\n",
      "         0.1375, 0.4241, 0.2832, 0.7661],\n",
      "        [0.2795, 0.3074, 0.2507, 0.2458, 0.2847, 0.2498, 0.4863, 0.2532, 0.1555,\n",
      "         0.1343, 0.2252, 0.2773, 0.4429],\n",
      "        [0.4336, 0.4546, 0.4944, 0.5908, 0.5283, 0.3201, 0.3347, 0.5005, 0.3542,\n",
      "         0.5229, 0.8491, 0.5229, 0.4736],\n",
      "        [0.2849, 0.2556, 0.3418, 0.3865, 0.3545, 0.2395, 0.3657, 0.1381, 0.2017,\n",
      "         0.2170, 0.4688, 0.2761, 0.3794],\n",
      "        [0.2478, 0.1927, 0.1869, 0.2598, 0.2700, 0.2642, 0.3794, 0.1718, 0.1451,\n",
      "         0.1409, 0.2646, 0.2156, 0.4668],\n",
      "        [0.4045, 0.2527, 0.2781, 0.3655, 0.3472, 0.2162, 0.4663, 0.1534, 0.1763,\n",
      "         0.2460, 0.3315, 0.3604, 0.3792]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<SigmoidBackward0>)\n",
      "Logits: tensor([[-0.6401, -1.8604, -1.6084, -1.2031, -1.0049, -0.6382, -0.6831, -1.8760,\n",
      "         -1.7783, -1.9678, -1.7617, -1.4648, -0.2244],\n",
      "        [-0.4204, -0.4407, -0.6909, -1.3213, -0.6685, -1.7480, -0.6079, -0.3389,\n",
      "         -1.1201, -0.3552,  0.0935, -0.9868, -0.9683],\n",
      "        [-0.3159,  0.3735, -1.2402,  0.3196,  0.0452, -1.3301,  0.4924,  0.5415,\n",
      "         -0.4106,  0.4036,  1.3203, -0.0858, -0.4072],\n",
      "        [-0.5562, -0.1801, -1.0664, -1.4746,  0.4023, -1.5312, -0.4324, -0.1685,\n",
      "         -2.3047, -0.3862,  0.8721, -0.6616, -0.2690],\n",
      "        [-1.1514, -1.6182, -1.1367, -1.0508, -1.0117, -1.2705, -0.3740, -1.1504,\n",
      "         -1.5283, -2.1504, -1.2666, -1.5508,  0.2573],\n",
      "        [-0.9097, -1.9121, -1.6611, -0.6445, -1.0381, -1.1816, -1.5186, -1.7061,\n",
      "         -2.0352, -1.7832, -1.1240, -1.4561, -0.2629],\n",
      "        [-0.1700,  0.3130, -1.0986,  0.2832,  0.0358, -1.3711,  0.4709,  0.5957,\n",
      "         -0.3064,  0.5137,  1.3389,  0.0029, -0.4939],\n",
      "        [-0.7666, -0.8018, -1.2227, -0.7051, -0.8887, -0.8252, -0.6880, -1.3027,\n",
      "         -1.8848, -1.2207, -1.9385, -0.6660, -0.3037],\n",
      "        [-0.6782, -1.3174, -1.3760, -1.1709, -0.8291, -0.8149, -0.5659, -1.6201,\n",
      "         -2.0234, -1.6143, -0.9878, -1.4336,  0.8374],\n",
      "        [-0.8979, -1.3877, -0.9307, -1.2432, -1.1885, -0.9150, -0.9570, -1.7197,\n",
      "         -1.9844, -1.9111, -1.4785, -1.3945,  0.2681],\n",
      "        [-1.0840, -1.1992, -1.1338, -1.0918, -0.2893, -0.7832, -0.4143, -1.4932,\n",
      "         -1.6768, -1.5293, -1.1162, -0.9233,  0.4751],\n",
      "        [-1.2109, -1.5791, -1.1680, -1.1738, -1.2285, -1.2822, -0.6694, -1.5361,\n",
      "         -2.1035, -1.9287, -1.3350, -1.1748, -0.0240],\n",
      "        [-0.6182, -1.1367, -1.2402, -0.8398, -1.2412, -0.9561, -1.1025, -1.4824,\n",
      "         -1.3359, -2.4414, -0.7876, -1.6357,  0.1279],\n",
      "        [-1.0723, -0.6792, -0.6660, -1.1465, -0.0262, -1.1182, -1.6084, -1.5820,\n",
      "         -2.5957, -1.2725, -0.3105, -1.0889,  0.0211],\n",
      "        [-0.9556, -1.3809, -1.0166, -0.6284, -0.8770, -1.3604, -0.8398, -1.9160,\n",
      "         -2.1641, -1.4922, -0.9487, -1.0117, -0.5693],\n",
      "        [-1.8643, -1.3916, -0.9248, -0.6523, -1.0264, -1.5264, -0.9077, -1.5488,\n",
      "         -2.0645, -1.9883, -0.5869, -1.0898,  0.3489]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "Labels: tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
      "Logits shape: torch.Size([16, 13])\n",
      "Labels shape: torch.Size([16, 13])\n",
      "loss: 0.43962326645851135\n",
      "preds: tensor([[0.3452, 0.1346, 0.1669, 0.2310, 0.2681, 0.3457, 0.3354, 0.1328, 0.1445,\n",
      "         0.1226, 0.1466, 0.1877, 0.4441],\n",
      "        [0.3965, 0.3916, 0.3337, 0.2106, 0.3389, 0.1483, 0.3525, 0.4160, 0.2460,\n",
      "         0.4121, 0.5234, 0.2715, 0.2751],\n",
      "        [0.4216, 0.5923, 0.2244, 0.5791, 0.5112, 0.2091, 0.6206, 0.6323, 0.3987,\n",
      "         0.5996, 0.7891, 0.4785, 0.3997],\n",
      "        [0.3645, 0.4551, 0.2561, 0.1863, 0.5991, 0.1779, 0.3936, 0.4580, 0.0908,\n",
      "         0.4045, 0.7051, 0.3403, 0.4331],\n",
      "        [0.2402, 0.1654, 0.2429, 0.2590, 0.2666, 0.2191, 0.4075, 0.2405, 0.1782,\n",
      "         0.1043, 0.2198, 0.1749, 0.5640],\n",
      "        [0.2871, 0.1288, 0.1597, 0.3442, 0.2615, 0.2347, 0.1797, 0.1537, 0.1155,\n",
      "         0.1439, 0.2452, 0.1891, 0.4346],\n",
      "        [0.4575, 0.5776, 0.2500, 0.5703, 0.5088, 0.2024, 0.6157, 0.6445, 0.4241,\n",
      "         0.6255, 0.7925, 0.5005, 0.3789],\n",
      "        [0.3171, 0.3096, 0.2274, 0.3306, 0.2915, 0.3047, 0.3345, 0.2137, 0.1318,\n",
      "         0.2278, 0.1259, 0.3394, 0.4246],\n",
      "        [0.3367, 0.2113, 0.2017, 0.2367, 0.3040, 0.3069, 0.3621, 0.1652, 0.1168,\n",
      "         0.1660, 0.2712, 0.1925, 0.6978],\n",
      "        [0.2896, 0.1998, 0.2827, 0.2239, 0.2335, 0.2859, 0.2776, 0.1519, 0.1208,\n",
      "         0.1289, 0.1857, 0.1987, 0.5664],\n",
      "        [0.2527, 0.2316, 0.2434, 0.2512, 0.4282, 0.3137, 0.3979, 0.1835, 0.1575,\n",
      "         0.1781, 0.2467, 0.2842, 0.6167],\n",
      "        [0.2295, 0.1709, 0.2372, 0.2362, 0.2264, 0.2172, 0.3386, 0.1771, 0.1088,\n",
      "         0.1270, 0.2084, 0.2360, 0.4939],\n",
      "        [0.3501, 0.2429, 0.2244, 0.3015, 0.2242, 0.2776, 0.2493, 0.1851, 0.2081,\n",
      "         0.0801, 0.3127, 0.1631, 0.5317],\n",
      "        [0.2549, 0.3364, 0.3394, 0.2411, 0.4934, 0.2463, 0.1669, 0.1705, 0.0694,\n",
      "         0.2189, 0.4231, 0.2520, 0.5054],\n",
      "        [0.2778, 0.2009, 0.2656, 0.3479, 0.2937, 0.2042, 0.3015, 0.1283, 0.1030,\n",
      "         0.1836, 0.2791, 0.2666, 0.3613],\n",
      "        [0.1342, 0.1991, 0.2839, 0.3425, 0.2637, 0.1785, 0.2874, 0.1753, 0.1126,\n",
      "         0.1204, 0.3574, 0.2517, 0.5864]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<SigmoidBackward0>)\n",
      "Logits: tensor([[-1.0547, -1.8867, -1.5254, -1.0859, -1.7305, -1.6934, -1.4424, -1.7617,\n",
      "         -2.1934, -2.2910, -1.8643, -1.2988, -0.1852],\n",
      "        [-1.1963, -1.8779, -1.6230, -1.2402, -1.7148, -1.2939, -1.6084, -1.8398,\n",
      "         -2.3574, -2.1621, -1.8730, -1.4375, -0.1305],\n",
      "        [-0.6982, -1.0215, -1.0283, -1.6240, -1.2070, -0.9277, -1.0781, -1.6543,\n",
      "         -1.8711, -1.5850, -1.6045, -0.5435,  0.3005],\n",
      "        [-0.7827, -1.7734, -1.4775, -0.8647, -1.4580, -0.3650, -0.6479, -1.9971,\n",
      "         -1.8525, -2.1152, -1.7559, -0.9038, -0.7715],\n",
      "        [-1.0234, -1.9482, -1.6367, -1.2334, -1.3291, -1.2432, -1.6328, -1.7705,\n",
      "         -2.3125, -2.1992, -1.7998, -1.3730, -0.1460],\n",
      "        [-1.0342, -1.6387, -1.1992, -1.0547, -1.4316, -1.3535, -1.1709, -1.9209,\n",
      "         -2.2246, -2.1113, -1.2598, -1.2949, -0.2107],\n",
      "        [-0.7549, -1.8584, -1.1914, -1.2598, -1.2734, -1.2598, -1.2568, -2.1172,\n",
      "         -2.5137, -1.9180, -1.9971, -1.4219,  0.1045],\n",
      "        [-0.5801, -1.9238, -1.4775, -0.4790, -0.5063, -1.2578, -0.9019, -1.1396,\n",
      "         -1.1172, -0.8555, -0.8081, -0.5874,  0.3335],\n",
      "        [-1.0469, -2.1191, -1.2764, -1.4385, -1.4951, -1.2744, -1.0049, -1.8193,\n",
      "         -2.2559, -2.0469, -1.7100, -1.4277, -0.3262],\n",
      "        [-0.8320, -1.5801, -1.8760, -1.4307, -1.3916, -1.3379, -1.6885, -1.7383,\n",
      "         -1.8857, -1.9082, -1.7676, -1.0537,  0.0850],\n",
      "        [-0.6787, -1.0557, -1.6152, -1.2295, -0.4109, -0.9800, -0.9146, -1.4707,\n",
      "         -1.7373, -1.7969, -1.1602, -1.0146,  0.2832],\n",
      "        [ 0.0912, -0.6431, -0.4167, -0.4900, -0.2949, -0.8076,  0.0396, -0.1526,\n",
      "         -1.2656,  0.4175,  0.6509,  0.1562, -0.6079],\n",
      "        [-0.3367, -1.9756, -1.1895, -1.1670, -0.4519, -1.1914, -1.2578, -1.9551,\n",
      "         -1.6582, -2.2188, -1.4336, -1.4609, -0.5913],\n",
      "        [-0.8564, -1.6787, -1.2646, -1.1533, -1.1045, -1.2041, -1.5830, -1.5684,\n",
      "         -1.9492, -2.2793, -1.5566, -1.2539, -0.3445],\n",
      "        [-0.2413,  0.1726, -1.1797, -1.0508, -0.2440, -1.5068, -0.7334, -0.2004,\n",
      "         -0.7485,  0.5303,  1.1924, -0.1885, -0.6104],\n",
      "        [-0.6782, -1.5811, -1.2188, -1.2471, -1.2197, -1.1973, -0.8599, -2.0879,\n",
      "         -1.8740, -2.1152, -1.2637, -0.8511, -0.6772]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "Labels: tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "Logits shape: torch.Size([16, 13])\n",
      "Labels shape: torch.Size([16, 13])\n",
      "loss: 0.364280104637146\n",
      "preds: tensor([[0.2583, 0.1316, 0.1787, 0.2524, 0.1505, 0.1554, 0.1912, 0.1466, 0.1003,\n",
      "         0.0919, 0.1342, 0.2144, 0.4539],\n",
      "        [0.2322, 0.1326, 0.1648, 0.2244, 0.1526, 0.2152, 0.1669, 0.1371, 0.0865,\n",
      "         0.1032, 0.1332, 0.1919, 0.4675],\n",
      "        [0.3323, 0.2646, 0.2634, 0.1647, 0.2302, 0.2834, 0.2539, 0.1605, 0.1334,\n",
      "         0.1700, 0.1674, 0.3674, 0.5747],\n",
      "        [0.3137, 0.1451, 0.1858, 0.2964, 0.1887, 0.4097, 0.3435, 0.1195, 0.1356,\n",
      "         0.1076, 0.1473, 0.2883, 0.3162],\n",
      "        [0.2644, 0.1248, 0.1630, 0.2256, 0.2094, 0.2239, 0.1635, 0.1455, 0.0901,\n",
      "         0.0998, 0.1418, 0.2021, 0.4636],\n",
      "        [0.2622, 0.1626, 0.2316, 0.2583, 0.1929, 0.2053, 0.2367, 0.1278, 0.0975,\n",
      "         0.1080, 0.2211, 0.2150, 0.4475],\n",
      "        [0.3198, 0.1349, 0.2330, 0.2211, 0.2186, 0.2211, 0.2216, 0.1074, 0.0749,\n",
      "         0.1281, 0.1195, 0.1943, 0.5259],\n",
      "        [0.3589, 0.1274, 0.1858, 0.3826, 0.3760, 0.2213, 0.2886, 0.2424, 0.2466,\n",
      "         0.2983, 0.3083, 0.3572, 0.5825],\n",
      "        [0.2598, 0.1072, 0.2181, 0.1918, 0.1831, 0.2185, 0.2681, 0.1395, 0.0948,\n",
      "         0.1144, 0.1532, 0.1935, 0.4192],\n",
      "        [0.3032, 0.1708, 0.1328, 0.1930, 0.1991, 0.2079, 0.1560, 0.1495, 0.1317,\n",
      "         0.1292, 0.1459, 0.2585, 0.5215],\n",
      "        [0.3367, 0.2581, 0.1659, 0.2263, 0.3987, 0.2729, 0.2861, 0.1869, 0.1497,\n",
      "         0.1422, 0.2386, 0.2661, 0.5703],\n",
      "        [0.5229, 0.3445, 0.3972, 0.3799, 0.4268, 0.3083, 0.5098, 0.4619, 0.2200,\n",
      "         0.6030, 0.6572, 0.5391, 0.3525],\n",
      "        [0.4165, 0.1218, 0.2334, 0.2374, 0.3889, 0.2330, 0.2213, 0.1240, 0.1600,\n",
      "         0.0981, 0.1925, 0.1884, 0.3564],\n",
      "        [0.2981, 0.1572, 0.2202, 0.2399, 0.2489, 0.2307, 0.1704, 0.1725, 0.1246,\n",
      "         0.0928, 0.1741, 0.2220, 0.4148],\n",
      "        [0.4399, 0.5430, 0.2351, 0.2590, 0.4392, 0.1814, 0.3245, 0.4500, 0.3210,\n",
      "         0.6294, 0.7671, 0.4531, 0.3521],\n",
      "        [0.3367, 0.1707, 0.2281, 0.2233, 0.2280, 0.2319, 0.2974, 0.1103, 0.1331,\n",
      "         0.1076, 0.2203, 0.2993, 0.3369]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<SigmoidBackward0>)\n",
      "Logits: tensor([[-0.9043, -1.4805, -1.6641, -1.2402, -1.6982, -1.3398, -1.4941, -2.2754,\n",
      "         -1.8574, -2.0918, -1.6816, -2.2988, -0.1495],\n",
      "        [ 0.0201, -1.1533, -0.3669, -0.6440, -1.0117, -1.2432, -0.6929, -2.6211,\n",
      "         -2.0547, -0.5166, -0.6572, -1.1318, -0.7554],\n",
      "        [-0.9082, -2.0117, -1.6602, -1.1904, -1.3135, -1.2246, -1.9697, -1.9619,\n",
      "         -2.0684, -2.3281, -1.9756, -1.6191, -0.3833],\n",
      "        [-1.3262, -2.1367, -1.4189, -1.0410, -1.5566, -1.1973, -1.2754, -2.0684,\n",
      "         -2.0078, -2.4082, -2.1387, -1.8428, -0.5503],\n",
      "        [-0.4724, -1.2930, -1.2412, -0.7798, -0.8066, -0.7354, -0.7983, -1.5654,\n",
      "         -1.0244, -1.0234, -2.1348, -1.3193, -0.0786],\n",
      "        [-1.3633, -1.5449, -0.9927, -0.6992, -1.5176, -1.7598, -1.9082, -2.2168,\n",
      "         -1.8604, -1.9648, -1.6104, -0.8169, -0.6538],\n",
      "        [-0.3911, -1.6006, -1.3955, -1.2188, -1.3164, -1.2246, -0.6855, -1.8379,\n",
      "         -1.5986, -2.4473, -1.8896, -1.5283, -0.8306],\n",
      "        [-1.4551, -1.6807, -1.4355, -1.4531, -1.5322, -1.9170, -1.0762, -1.4883,\n",
      "         -2.0977, -1.6533, -1.0605, -1.5898, -0.3130],\n",
      "        [-1.0537, -1.7637, -1.5898, -2.0098, -1.7979, -1.5166, -1.2539, -1.9902,\n",
      "         -1.8418, -2.0039, -1.8330, -1.4775,  0.3354],\n",
      "        [-1.0615, -1.5498, -0.7002, -0.6260, -0.4141, -1.3330, -0.5571, -1.4697,\n",
      "         -1.6201, -0.9600, -1.2705, -0.6992, -0.4539],\n",
      "        [-0.9253, -1.5889, -1.4688, -1.1514, -0.9663, -1.1650, -1.4727, -2.4062,\n",
      "         -2.0078, -2.1816, -2.0430, -1.6357, -0.6909],\n",
      "        [-1.1709, -1.8281, -1.3721, -1.4111, -1.5889, -1.3447, -0.9932, -1.9160,\n",
      "         -2.3535, -2.3750, -1.6357, -1.5732, -0.1533],\n",
      "        [-1.2139, -1.8428, -1.2969, -1.0088, -1.5361, -1.3682, -1.1465, -2.1426,\n",
      "         -2.0938, -2.1348, -2.0430, -1.0664, -0.3726],\n",
      "        [-1.2422, -1.5576, -1.0674, -1.5693, -1.2949, -1.2314, -0.9424, -1.9443,\n",
      "         -1.6758, -1.7510, -1.7734, -1.4717,  0.3672],\n",
      "        [-0.9731, -0.8682, -1.0986, -1.6484, -1.4902, -1.5137, -1.0928, -1.4385,\n",
      "         -1.7666, -1.8379, -1.4619, -1.1846,  0.0274],\n",
      "        [-1.1855, -2.1230, -1.6865, -1.2988, -1.7822, -1.3447, -1.2861, -1.8340,\n",
      "         -2.2773, -2.5430, -2.0449, -1.9863, -0.4097]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "Labels: tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "Logits shape: torch.Size([16, 13])\n",
      "Labels shape: torch.Size([16, 13])\n",
      "loss: 0.2892334461212158\n",
      "preds: tensor([[0.2881, 0.1853, 0.1592, 0.2244, 0.1547, 0.2075, 0.1833, 0.0932, 0.1350,\n",
      "         0.1099, 0.1569, 0.0912, 0.4626],\n",
      "        [0.5049, 0.2399, 0.4092, 0.3442, 0.2666, 0.2239, 0.3335, 0.0678, 0.1136,\n",
      "         0.3735, 0.3413, 0.2438, 0.3196],\n",
      "        [0.2874, 0.1180, 0.1598, 0.2332, 0.2119, 0.2272, 0.1224, 0.1232, 0.1122,\n",
      "         0.0888, 0.1218, 0.1653, 0.4053],\n",
      "        [0.2098, 0.1056, 0.1948, 0.2610, 0.1741, 0.2319, 0.2184, 0.1122, 0.1184,\n",
      "         0.0825, 0.1054, 0.1367, 0.3657],\n",
      "        [0.3840, 0.2153, 0.2242, 0.3145, 0.3086, 0.3240, 0.3103, 0.1729, 0.2642,\n",
      "         0.2644, 0.1058, 0.2109, 0.4805],\n",
      "        [0.2037, 0.1758, 0.2703, 0.3320, 0.1798, 0.1469, 0.1292, 0.0983, 0.1346,\n",
      "         0.1229, 0.1665, 0.3064, 0.3420],\n",
      "        [0.4036, 0.1678, 0.1985, 0.2281, 0.2114, 0.2272, 0.3350, 0.1373, 0.1682,\n",
      "         0.0797, 0.1312, 0.1782, 0.3035],\n",
      "        [0.1892, 0.1570, 0.1923, 0.1896, 0.1776, 0.1282, 0.2542, 0.1842, 0.1093,\n",
      "         0.1606, 0.2573, 0.1694, 0.4224],\n",
      "        [0.2585, 0.1464, 0.1694, 0.1182, 0.1421, 0.1799, 0.2220, 0.1202, 0.1368,\n",
      "         0.1188, 0.1379, 0.1858, 0.5830],\n",
      "        [0.2571, 0.1752, 0.3318, 0.3484, 0.3979, 0.2086, 0.3643, 0.1870, 0.1652,\n",
      "         0.2769, 0.2191, 0.3320, 0.3884],\n",
      "        [0.2839, 0.1696, 0.1871, 0.2402, 0.2756, 0.2378, 0.1865, 0.0827, 0.1184,\n",
      "         0.1014, 0.1147, 0.1631, 0.3337],\n",
      "        [0.2367, 0.1384, 0.2023, 0.1960, 0.1696, 0.2068, 0.2703, 0.1283, 0.0868,\n",
      "         0.0851, 0.1631, 0.1718, 0.4617],\n",
      "        [0.2290, 0.1367, 0.2147, 0.2673, 0.1771, 0.2029, 0.2411, 0.1050, 0.1097,\n",
      "         0.1058, 0.1147, 0.2561, 0.4080],\n",
      "        [0.2240, 0.1740, 0.2559, 0.1724, 0.2150, 0.2260, 0.2805, 0.1251, 0.1577,\n",
      "         0.1479, 0.1451, 0.1866, 0.5908],\n",
      "        [0.2742, 0.2957, 0.2500, 0.1614, 0.1838, 0.1804, 0.2510, 0.1918, 0.1460,\n",
      "         0.1373, 0.1882, 0.2343, 0.5068],\n",
      "        [0.2340, 0.1069, 0.1562, 0.2144, 0.1440, 0.2068, 0.2166, 0.1378, 0.0930,\n",
      "         0.0729, 0.1146, 0.1207, 0.3989]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<SigmoidBackward0>)\n",
      "Logits: tensor([[-0.8135, -2.0801, -1.8896, -1.4199, -1.4062, -1.1807, -1.7305, -1.9824,\n",
      "         -2.0332, -2.4453, -2.1895, -1.5879, -0.2512],\n",
      "        [-1.1719, -1.7588, -0.9717, -1.0957, -1.3115, -1.2646, -1.4629, -1.9551,\n",
      "         -1.7129, -1.7471, -1.7559, -1.4141, -0.0373],\n",
      "        [-1.1113, -1.5410, -0.8984, -0.9126, -1.4551, -1.0303, -0.9546, -2.0566,\n",
      "         -1.8906, -1.5469, -1.7549, -0.6616, -0.6792],\n",
      "        [-1.2842, -1.3076, -0.7432, -0.9536, -0.4578, -0.5161, -1.2695, -1.5898,\n",
      "         -1.7988, -1.8340, -1.1602, -1.7988, -0.1045],\n",
      "        [-0.9771, -2.2402, -1.7900, -1.4941, -1.3760, -1.4189, -1.6914, -1.9150,\n",
      "         -2.0234, -2.4824, -1.9551, -1.5986, -0.4561],\n",
      "        [-0.9155, -2.1211, -1.3115, -1.1738, -1.5986, -0.9976, -1.4541, -2.3008,\n",
      "         -1.4619, -2.1992, -2.1055, -1.4033, -1.3789],\n",
      "        [-1.3408, -2.2520, -1.2627, -1.3750, -1.6035, -1.3555, -1.8047, -2.1602,\n",
      "         -2.0234, -2.3281, -1.5576, -1.5156, -0.7212],\n",
      "        [-0.0870, -1.8555, -1.5557, -1.2861, -0.8994, -0.7202, -0.9976, -1.9814,\n",
      "         -1.4238, -2.3281, -1.4434, -1.5527, -0.2898],\n",
      "        [-0.4734, -1.4180, -0.6694, -0.9956, -0.7402, -0.3301, -0.7124, -1.6934,\n",
      "         -1.6494, -1.8076, -2.0078, -0.5898, -0.0103],\n",
      "        [-0.7490, -1.6211, -1.2354, -1.0801, -1.3721, -1.0996, -1.1621, -1.9414,\n",
      "         -1.3770, -2.2383, -2.4043, -1.2471, -0.8608],\n",
      "        [-1.3193, -1.7422, -1.7764, -1.8379, -1.7451, -1.5469, -2.1953, -2.0469,\n",
      "         -2.1250, -2.3945, -1.9346, -1.4619, -0.3572],\n",
      "        [ 0.0693, -1.2822, -0.8140, -0.3596, -0.4238, -0.8975, -0.3550, -1.5762,\n",
      "         -2.1094, -1.8838, -1.3467, -0.7466, -0.4617],\n",
      "        [-1.3945, -2.0059, -1.4033, -0.9229, -1.8613, -1.5654, -1.5518, -2.0820,\n",
      "         -1.7666, -2.1387, -2.0098, -1.7676, -0.9048],\n",
      "        [-0.6782, -1.9258, -1.2773, -1.2871, -1.5410, -0.9897, -1.4697, -1.6572,\n",
      "         -2.1270, -2.3848, -2.0215, -1.6973, -0.6748],\n",
      "        [-0.6567, -2.2070, -1.2539, -1.0557, -0.8872, -1.6348, -1.7012, -1.9619,\n",
      "         -1.8350, -1.7207, -1.1436, -1.0361, -1.6621],\n",
      "        [-0.6704, -1.6719, -1.1992, -0.5566, -1.8916, -1.0674, -0.9448, -1.6846,\n",
      "         -1.6719, -1.3545, -1.4805, -0.4995,  0.0707]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "Labels: tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\n",
      "Logits shape: torch.Size([16, 13])\n",
      "Labels shape: torch.Size([16, 13])\n",
      "loss: 0.3119897246360779\n",
      "preds: tensor([[0.3071, 0.1110, 0.1312, 0.1947, 0.1968, 0.2350, 0.1505, 0.1210, 0.1158,\n",
      "         0.0798, 0.1007, 0.1697, 0.4375],\n",
      "        [0.2366, 0.1470, 0.2747, 0.2505, 0.2123, 0.2202, 0.1880, 0.1240, 0.1528,\n",
      "         0.1484, 0.1473, 0.1956, 0.4907],\n",
      "        [0.2477, 0.1764, 0.2893, 0.2864, 0.1892, 0.2629, 0.2781, 0.1134, 0.1312,\n",
      "         0.1755, 0.1475, 0.3403, 0.3364],\n",
      "        [0.2168, 0.2129, 0.3223, 0.2781, 0.3875, 0.3738, 0.2194, 0.1694, 0.1420,\n",
      "         0.1378, 0.2386, 0.1420, 0.4739],\n",
      "        [0.2734, 0.0962, 0.1431, 0.1833, 0.2017, 0.1948, 0.1556, 0.1284, 0.1168,\n",
      "         0.0771, 0.1240, 0.1682, 0.3879],\n",
      "        [0.2859, 0.1071, 0.2123, 0.2362, 0.1682, 0.2695, 0.1893, 0.0911, 0.1882,\n",
      "         0.0998, 0.1086, 0.1973, 0.2012],\n",
      "        [0.2074, 0.0952, 0.2205, 0.2018, 0.1675, 0.2050, 0.1412, 0.1034, 0.1168,\n",
      "         0.0888, 0.1740, 0.1801, 0.3271],\n",
      "        [0.4783, 0.1353, 0.1743, 0.2166, 0.2891, 0.3274, 0.2695, 0.1212, 0.1941,\n",
      "         0.0888, 0.1910, 0.1747, 0.4280],\n",
      "        [0.3838, 0.1949, 0.3386, 0.2698, 0.3230, 0.4182, 0.3291, 0.1554, 0.1611,\n",
      "         0.1409, 0.1184, 0.3567, 0.4973],\n",
      "        [0.3210, 0.1650, 0.2252, 0.2534, 0.2023, 0.2498, 0.2383, 0.1255, 0.2015,\n",
      "         0.0964, 0.0828, 0.2233, 0.2971],\n",
      "        [0.2109, 0.1490, 0.1448, 0.1373, 0.1487, 0.1755, 0.1002, 0.1144, 0.1067,\n",
      "         0.0836, 0.1262, 0.1882, 0.4116],\n",
      "        [0.5171, 0.2172, 0.3071, 0.4111, 0.3955, 0.2896, 0.4121, 0.1714, 0.1082,\n",
      "         0.1320, 0.2064, 0.3215, 0.3865],\n",
      "        [0.1987, 0.1186, 0.1973, 0.2844, 0.1345, 0.1729, 0.1748, 0.1108, 0.1460,\n",
      "         0.1054, 0.1182, 0.1459, 0.2881],\n",
      "        [0.3367, 0.1272, 0.2180, 0.2163, 0.1764, 0.2710, 0.1870, 0.1602, 0.1065,\n",
      "         0.0844, 0.1169, 0.1548, 0.3374],\n",
      "        [0.3416, 0.0991, 0.2220, 0.2581, 0.2917, 0.1632, 0.1543, 0.1232, 0.1377,\n",
      "         0.1517, 0.2417, 0.2620, 0.1594],\n",
      "        [0.3384, 0.1582, 0.2316, 0.3643, 0.1311, 0.2559, 0.2800, 0.1565, 0.1582,\n",
      "         0.2051, 0.1853, 0.3777, 0.5176]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<SigmoidBackward0>)\n",
      "Logits: tensor([[ 0.2917, -0.4885,  0.3093, -0.9072, -1.5479, -1.1641,  0.2559, -0.1588,\n",
      "         -0.9854,  0.1561,  0.7466, -0.4846, -0.1641],\n",
      "        [-1.2344, -2.0391, -1.8682, -1.5322, -1.6338, -1.5459, -2.3145, -2.1387,\n",
      "         -2.0254, -2.2363, -2.0449, -1.5693, -0.9580],\n",
      "        [ 0.0922, -1.7666, -1.8535, -1.0869, -1.0762, -1.2285, -1.6191, -2.0977,\n",
      "         -1.6875, -2.5586, -2.1758, -1.2773, -0.2817],\n",
      "        [ 0.4683, -1.4912, -1.1660, -0.8315, -0.9307, -1.7012, -1.0723, -1.4023,\n",
      "         -1.7861, -0.8970, -0.6812, -0.9150, -0.6685],\n",
      "        [-0.8184, -1.1973, -1.4678, -1.7334, -1.0264, -1.2627, -1.1494, -1.6094,\n",
      "         -2.3242, -1.5127, -0.6318, -0.9614, -0.3589],\n",
      "        [-0.3948, -1.5293, -1.7910, -1.2393, -1.0029, -1.3164, -2.3535, -2.3516,\n",
      "         -2.0137, -2.2891, -1.6377, -1.3291, -0.2307],\n",
      "        [-1.0068, -1.8877, -1.2090, -1.2256, -2.0137, -1.2529, -1.8945, -2.2871,\n",
      "         -1.5322, -2.0293, -2.0938, -1.5312,  0.1962],\n",
      "        [-0.3176, -2.2031, -1.5635, -1.1396, -1.3301, -1.5039, -1.1553, -1.7227,\n",
      "         -1.9727, -2.6094, -1.8184, -1.6064, -0.5640],\n",
      "        [-1.3438, -2.2988, -1.7510, -1.4248, -1.6670, -1.6504, -1.3281, -2.3672,\n",
      "         -1.7715, -2.3750, -1.9004, -2.3340, -0.7573],\n",
      "        [-0.6597, -1.3750, -1.2734, -0.9604, -1.2949, -0.9712, -0.8330, -1.6348,\n",
      "         -1.5684, -1.8818, -1.5430, -0.3643, -0.6104],\n",
      "        [-0.3865, -1.7568, -1.1504, -1.6094, -1.6943, -1.7139, -0.7192, -2.0449,\n",
      "         -1.4570, -2.8770, -1.9072, -1.5459, -1.3047],\n",
      "        [-0.2145, -2.4023, -1.0840, -1.0684, -1.4678, -1.6885, -1.6143, -1.9248,\n",
      "         -1.6553, -2.1914, -1.9668, -1.4121, -0.8892],\n",
      "        [-0.7432, -1.5312, -1.3857, -1.2539, -0.9814, -1.0635, -0.4382, -1.3066,\n",
      "         -2.0977, -2.1055, -1.6699, -1.9551, -0.3867],\n",
      "        [-0.8271, -2.0312, -1.0986, -0.8452, -1.3633, -1.8145, -0.9248, -2.2266,\n",
      "         -2.5898, -1.8896, -1.8652, -1.5391, -0.5664],\n",
      "        [-0.1713, -2.1992, -1.8613, -1.4619, -1.1543, -1.2783, -1.6914, -2.1973,\n",
      "         -1.6191, -2.1973, -1.8262, -1.3320, -0.0735],\n",
      "        [-0.5718, -1.0635, -0.4998, -1.2666, -0.7593, -1.6455, -1.1367, -1.1797,\n",
      "         -1.9131, -0.9551, -0.9263, -1.2930, -0.2783]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "Labels: tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\n",
      "Logits shape: torch.Size([16, 13])\n",
      "Labels shape: torch.Size([16, 13])\n",
      "loss: 0.3237009644508362\n",
      "preds: tensor([[0.5723, 0.3801, 0.5767, 0.2876, 0.1754, 0.2379, 0.5635, 0.4604, 0.2717,\n",
      "         0.5391, 0.6782, 0.3811, 0.4590],\n",
      "        [0.2255, 0.1152, 0.1338, 0.1776, 0.1633, 0.1757, 0.0899, 0.1054, 0.1166,\n",
      "         0.0966, 0.1146, 0.1724, 0.2773],\n",
      "        [0.5229, 0.1460, 0.1355, 0.2522, 0.2542, 0.2264, 0.1653, 0.1093, 0.1561,\n",
      "         0.0718, 0.1019, 0.2180, 0.4299],\n",
      "        [0.6147, 0.1837, 0.2375, 0.3032, 0.2827, 0.1543, 0.2549, 0.1974, 0.1436,\n",
      "         0.2898, 0.3359, 0.2859, 0.3389],\n",
      "        [0.3062, 0.2319, 0.1873, 0.1501, 0.2637, 0.2205, 0.2406, 0.1666, 0.0891,\n",
      "         0.1805, 0.3472, 0.2766, 0.4111],\n",
      "        [0.4026, 0.1781, 0.1429, 0.2246, 0.2683, 0.2114, 0.0868, 0.0869, 0.1178,\n",
      "         0.0920, 0.1627, 0.2094, 0.4426],\n",
      "        [0.2676, 0.1315, 0.2299, 0.2269, 0.1178, 0.2222, 0.1307, 0.0922, 0.1776,\n",
      "         0.1161, 0.1097, 0.1779, 0.5488],\n",
      "        [0.4211, 0.0995, 0.1731, 0.2424, 0.2091, 0.1819, 0.2395, 0.1515, 0.1221,\n",
      "         0.0685, 0.1396, 0.1671, 0.3625],\n",
      "        [0.2069, 0.0912, 0.1479, 0.1940, 0.1588, 0.1610, 0.2095, 0.0857, 0.1454,\n",
      "         0.0851, 0.1300, 0.0883, 0.3193],\n",
      "        [0.3408, 0.2018, 0.2186, 0.2769, 0.2150, 0.2747, 0.3030, 0.1632, 0.1725,\n",
      "         0.1322, 0.1761, 0.4099, 0.3521],\n",
      "        [0.4045, 0.1472, 0.2405, 0.1666, 0.1552, 0.1527, 0.3276, 0.1146, 0.1890,\n",
      "         0.0533, 0.1293, 0.1757, 0.2134],\n",
      "        [0.4465, 0.0830, 0.2527, 0.2556, 0.1873, 0.1560, 0.1660, 0.1273, 0.1604,\n",
      "         0.1005, 0.1227, 0.1959, 0.2913],\n",
      "        [0.3223, 0.1779, 0.2001, 0.2220, 0.2727, 0.2566, 0.3921, 0.2130, 0.1093,\n",
      "         0.1086, 0.1584, 0.1240, 0.4045],\n",
      "        [0.3042, 0.1160, 0.2500, 0.3005, 0.2037, 0.1401, 0.2839, 0.0974, 0.0698,\n",
      "         0.1312, 0.1340, 0.1766, 0.3621],\n",
      "        [0.4573, 0.0998, 0.1345, 0.1882, 0.2397, 0.2179, 0.1556, 0.1000, 0.1653,\n",
      "         0.1000, 0.1387, 0.2089, 0.4817],\n",
      "        [0.3608, 0.2566, 0.3777, 0.2198, 0.3188, 0.1617, 0.2429, 0.2351, 0.1287,\n",
      "         0.2778, 0.2837, 0.2153, 0.4309]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<SigmoidBackward0>)\n",
      "Logits: tensor([[-0.6108, -1.8506, -0.5449, -0.9888, -0.8101, -0.9863, -1.2266, -1.6436,\n",
      "         -1.9131, -1.8291, -1.4766, -0.9214, -0.4653],\n",
      "        [-1.4463, -2.0996, -1.4902, -1.5781, -1.9365, -1.5322, -1.1719, -2.0254,\n",
      "         -2.3359, -2.5664, -2.2090, -1.8955, -0.4443],\n",
      "        [-0.8403, -1.9990, -1.9082, -1.3906, -1.9375, -0.8281, -1.6162, -2.4902,\n",
      "         -1.5674, -2.1914, -2.0879, -1.4844, -1.2178],\n",
      "        [-1.0098, -2.3047, -1.9297, -1.6729, -1.8057, -1.0215, -1.6133, -2.2852,\n",
      "         -2.2559, -2.7012, -2.2949, -1.9717, -0.2993],\n",
      "        [-1.3076, -2.1035, -1.2539, -1.2227, -1.9258, -1.1113, -1.3564, -2.2539,\n",
      "         -1.6963, -2.1211, -2.1895, -2.1680, -1.0322],\n",
      "        [-0.9805, -1.7695, -1.6787, -1.6475, -1.8496, -0.7490, -1.6396, -2.4199,\n",
      "         -2.0410, -1.9414, -2.1777, -1.1533, -0.7212],\n",
      "        [ 0.0289, -0.0523, -0.1903,  0.1282, -0.6646, -0.6875, -0.2039, -0.1255,\n",
      "         -0.9658,  0.3250,  0.7368,  0.0408,  0.3057],\n",
      "        [ 0.0174, -1.8428, -1.5391, -1.2148, -1.4404, -0.9077, -1.4180, -2.4160,\n",
      "         -1.7842, -2.4844, -1.6904, -0.8452, -1.0547],\n",
      "        [-0.2937, -1.2803, -0.8735, -1.3018, -1.5566, -1.3545, -1.2959, -2.1660,\n",
      "         -2.1777, -1.7168, -1.7227, -1.2715, -0.3062],\n",
      "        [-1.0996, -2.4785, -1.7070, -1.3193, -1.6846, -1.5469, -2.2070, -2.1660,\n",
      "         -1.8154, -2.1230, -2.0488, -1.5850, -1.1133],\n",
      "        [-1.1143, -1.6787, -1.7559, -1.8955, -1.4688, -1.0254, -1.5557, -2.0859,\n",
      "         -1.9863, -2.3398, -1.9746, -1.6777, -0.7432],\n",
      "        [-1.2354, -2.5176, -1.5137, -1.4785, -1.7168, -1.5381, -1.7227, -2.4121,\n",
      "         -1.9707, -2.3750, -1.9531, -1.7266, -1.1621],\n",
      "        [-0.3779,  0.0850, -1.2979,  0.2546, -0.1350, -1.3965,  0.3936,  0.0714,\n",
      "         -0.3167, -0.0772,  0.9009, -0.3306, -0.6704],\n",
      "        [-0.4763, -1.2666, -1.2354, -1.7441, -0.8882, -0.6411, -1.5234, -1.8232,\n",
      "         -1.7266, -2.1777, -1.7695, -1.3516, -0.1971],\n",
      "        [-0.7080, -1.9375, -1.2686, -0.6216, -1.0996, -0.9336, -1.7217, -2.3145,\n",
      "         -1.8418, -1.8311, -1.8506, -0.7642, -1.0693],\n",
      "        [-1.3418, -2.0859, -1.5889, -1.9316, -1.8594, -1.3867, -1.5918, -2.0293,\n",
      "         -2.1426, -2.2031, -2.5469, -1.5801, -0.3994]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "Labels: tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\n",
      "Logits shape: torch.Size([16, 13])\n",
      "Labels shape: torch.Size([16, 13])\n",
      "loss: 0.32379141449928284\n",
      "preds: tensor([[0.3518, 0.1359, 0.3669, 0.2712, 0.3079, 0.2717, 0.2268, 0.1620, 0.1287,\n",
      "         0.1383, 0.1859, 0.2847, 0.3857],\n",
      "        [0.1906, 0.1091, 0.1838, 0.1710, 0.1260, 0.1776, 0.2366, 0.1166, 0.0882,\n",
      "         0.0714, 0.0989, 0.1306, 0.3906],\n",
      "        [0.3015, 0.1193, 0.1292, 0.1993, 0.1260, 0.3040, 0.1658, 0.0765, 0.1726,\n",
      "         0.1005, 0.1103, 0.1848, 0.2283],\n",
      "        [0.2671, 0.0908, 0.1268, 0.1581, 0.1411, 0.2646, 0.1661, 0.0923, 0.0948,\n",
      "         0.0629, 0.0916, 0.1222, 0.4258],\n",
      "        [0.2129, 0.1088, 0.2220, 0.2274, 0.1272, 0.2477, 0.2048, 0.0950, 0.1549,\n",
      "         0.1071, 0.1007, 0.1027, 0.2627],\n",
      "        [0.2727, 0.1456, 0.1572, 0.1615, 0.1359, 0.3210, 0.1625, 0.0817, 0.1150,\n",
      "         0.1255, 0.1017, 0.2399, 0.3271],\n",
      "        [0.5073, 0.4868, 0.4526, 0.5322, 0.3396, 0.3345, 0.4492, 0.4688, 0.2756,\n",
      "         0.5806, 0.6763, 0.5103, 0.5757],\n",
      "        [0.5044, 0.1367, 0.1766, 0.2289, 0.1915, 0.2874, 0.1949, 0.0820, 0.1438,\n",
      "         0.0770, 0.1558, 0.3005, 0.2583],\n",
      "        [0.4270, 0.2175, 0.2944, 0.2139, 0.1741, 0.2051, 0.2148, 0.1028, 0.1017,\n",
      "         0.1523, 0.1515, 0.2190, 0.4241],\n",
      "        [0.2498, 0.0774, 0.1536, 0.2109, 0.1565, 0.1755, 0.0991, 0.1028, 0.1400,\n",
      "         0.1069, 0.1142, 0.1700, 0.2473],\n",
      "        [0.2471, 0.1572, 0.1473, 0.1306, 0.1871, 0.2639, 0.1743, 0.1105, 0.1207,\n",
      "         0.0879, 0.1219, 0.1573, 0.3223],\n",
      "        [0.2252, 0.0746, 0.1804, 0.1857, 0.1523, 0.1768, 0.1515, 0.0823, 0.1223,\n",
      "         0.0851, 0.1242, 0.1510, 0.2383],\n",
      "        [0.4067, 0.5210, 0.2145, 0.5635, 0.4663, 0.1984, 0.5972, 0.5181, 0.4214,\n",
      "         0.4807, 0.7109, 0.4182, 0.3384],\n",
      "        [0.3831, 0.2198, 0.2252, 0.1488, 0.2915, 0.3450, 0.1790, 0.1390, 0.1510,\n",
      "         0.1017, 0.1456, 0.2056, 0.4509],\n",
      "        [0.3301, 0.1260, 0.2195, 0.3494, 0.2498, 0.2822, 0.1516, 0.0899, 0.1368,\n",
      "         0.1381, 0.1359, 0.3176, 0.2556],\n",
      "        [0.2073, 0.1105, 0.1696, 0.1266, 0.1348, 0.2000, 0.1692, 0.1161, 0.1050,\n",
      "         0.0995, 0.0726, 0.1708, 0.4014]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<SigmoidBackward0>)\n",
      "Logits: tensor([[-1.1582e+00, -2.1582e+00, -1.7744e+00, -1.5312e+00, -2.0020e+00,\n",
      "         -1.5049e+00, -2.1855e+00, -2.3086e+00, -2.3164e+00, -2.5254e+00,\n",
      "         -2.5215e+00, -1.5488e+00, -6.9385e-01],\n",
      "        [-7.3584e-01, -2.0215e+00, -1.5342e+00, -1.6514e+00, -1.3877e+00,\n",
      "         -1.2832e+00, -2.2832e+00, -2.3086e+00, -1.8535e+00, -2.3027e+00,\n",
      "         -2.4102e+00, -2.0801e+00, -7.0020e-01],\n",
      "        [-3.3350e-01, -8.4045e-02, -1.2988e+00,  2.6880e-01, -2.0410e-01,\n",
      "         -1.3076e+00,  1.9092e-01, -3.4485e-02, -2.7271e-01, -4.1138e-02,\n",
      "          8.2910e-01, -3.9404e-01, -6.8848e-01],\n",
      "        [-9.3164e-01, -2.3105e+00, -1.8115e+00, -1.5654e+00, -1.6533e+00,\n",
      "         -8.9697e-01, -1.7607e+00, -2.3594e+00, -2.3086e+00, -1.8398e+00,\n",
      "         -1.5322e+00, -1.2822e+00, -7.4170e-01],\n",
      "        [-1.8909e-01,  7.0190e-02, -1.3203e+00,  3.7817e-01, -1.1559e-03,\n",
      "         -1.4023e+00,  1.3501e-01,  1.1444e-01, -3.8330e-01,  1.3245e-01,\n",
      "          8.6572e-01, -2.3987e-01, -8.4912e-01],\n",
      "        [-1.0820e+00, -1.7344e+00, -1.9824e+00, -1.7803e+00, -1.6816e+00,\n",
      "         -1.3311e+00, -1.6572e+00, -2.0586e+00, -1.9062e+00, -2.3164e+00,\n",
      "         -1.8535e+00, -2.2754e+00, -7.7881e-01],\n",
      "        [-2.7222e-01, -2.0527e+00, -1.7588e+00, -5.0977e-01, -1.1758e+00,\n",
      "         -2.1875e+00, -1.2041e+00, -1.4805e+00, -2.1621e+00, -8.1641e-01,\n",
      "         -1.6445e+00, -1.4980e+00, -7.7393e-01],\n",
      "        [-1.4863e+00, -2.1582e+00, -1.7266e+00, -1.4424e+00, -1.9287e+00,\n",
      "         -1.3936e+00, -1.6260e+00, -1.9424e+00, -1.5293e+00, -2.6016e+00,\n",
      "         -2.2637e+00, -1.5420e+00,  9.2712e-02],\n",
      "        [-9.0137e-01, -2.4746e+00, -1.5664e+00, -1.2510e+00, -1.7227e+00,\n",
      "         -1.1074e+00, -1.4512e+00, -2.6074e+00, -2.0312e+00, -2.3809e+00,\n",
      "         -1.7471e+00, -1.7646e+00, -7.4463e-01],\n",
      "        [-7.0654e-01, -2.3730e+00, -1.4834e+00, -1.1201e+00, -1.9180e+00,\n",
      "         -1.7686e+00, -1.7490e+00, -1.9424e+00, -1.4854e+00, -2.1055e+00,\n",
      "         -2.5430e+00, -1.4199e+00, -1.3887e+00],\n",
      "        [-1.0977e+00, -1.8623e+00, -1.6084e+00, -1.8857e+00, -1.8125e+00,\n",
      "         -1.5322e+00, -1.7695e+00, -1.8105e+00, -1.9092e+00, -2.6836e+00,\n",
      "         -2.2305e+00, -1.5488e+00,  1.3794e-02],\n",
      "        [-8.7744e-01, -2.3984e+00, -1.7109e+00, -1.4971e+00, -2.3418e+00,\n",
      "         -1.4658e+00, -1.5654e+00, -2.1660e+00, -2.3359e+00, -2.6562e+00,\n",
      "         -2.5645e+00, -2.2324e+00, -4.7876e-01],\n",
      "        [-9.7607e-01, -1.4795e+00, -1.5254e+00, -1.9199e+00, -8.8721e-01,\n",
      "         -2.0820e+00, -1.1436e+00, -2.2422e+00, -2.3574e+00, -1.2998e+00,\n",
      "         -2.0625e+00, -1.4121e+00, -6.4648e-01],\n",
      "        [-1.9983e-01, -1.3438e+00, -1.2217e+00, -1.0459e+00, -1.8340e+00,\n",
      "         -1.9883e+00,  4.9774e-02, -1.4551e+00, -1.8340e+00, -7.1436e-01,\n",
      "         -2.5024e-01, -2.4673e-02, -1.1719e+00],\n",
      "        [-1.1611e+00, -2.4629e+00, -1.5762e+00, -1.7178e+00, -1.7822e+00,\n",
      "         -1.5938e+00, -1.8994e+00, -2.4688e+00, -2.0605e+00, -2.5996e+00,\n",
      "         -2.0488e+00, -1.5342e+00, -8.6914e-01],\n",
      "        [-3.2007e-01, -2.3594e+00, -1.7773e+00, -1.4785e+00, -1.3467e+00,\n",
      "         -1.2676e+00, -1.8867e+00, -2.0020e+00, -2.0625e+00, -2.1387e+00,\n",
      "         -1.7773e+00, -1.2031e+00, -4.7534e-01]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "Labels: tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\n",
      "Logits shape: torch.Size([16, 13])\n",
      "Labels shape: torch.Size([16, 13])\n",
      "loss: 0.33398211002349854\n",
      "preds: tensor([[0.2390, 0.1036, 0.1450, 0.1779, 0.1190, 0.1816, 0.1011, 0.0904, 0.0898,\n",
      "         0.0741, 0.0743, 0.1753, 0.3333],\n",
      "        [0.3240, 0.1169, 0.1774, 0.1609, 0.1998, 0.2170, 0.0925, 0.0904, 0.1355,\n",
      "         0.0909, 0.0824, 0.1110, 0.3318],\n",
      "        [0.4175, 0.4790, 0.2144, 0.5669, 0.4492, 0.2129, 0.5474, 0.4915, 0.4321,\n",
      "         0.4897, 0.6963, 0.4028, 0.3345],\n",
      "        [0.2825, 0.0903, 0.1405, 0.1729, 0.1606, 0.2898, 0.1467, 0.0863, 0.0904,\n",
      "         0.1371, 0.1776, 0.2172, 0.3228],\n",
      "        [0.4529, 0.5176, 0.2108, 0.5933, 0.4998, 0.1974, 0.5337, 0.5288, 0.4053,\n",
      "         0.5332, 0.7036, 0.4404, 0.2996],\n",
      "        [0.2532, 0.1500, 0.1210, 0.1443, 0.1569, 0.2090, 0.1602, 0.1132, 0.1294,\n",
      "         0.0898, 0.1355, 0.0932, 0.3147],\n",
      "        [0.4324, 0.1138, 0.1470, 0.3752, 0.2358, 0.1009, 0.2307, 0.1853, 0.1032,\n",
      "         0.3066, 0.1619, 0.1827, 0.3157],\n",
      "        [0.1844, 0.1036, 0.1510, 0.1912, 0.1270, 0.1989, 0.1644, 0.1254, 0.1781,\n",
      "         0.0690, 0.0942, 0.1763, 0.5229],\n",
      "        [0.2888, 0.0776, 0.1727, 0.2225, 0.1515, 0.2483, 0.1898, 0.0687, 0.1160,\n",
      "         0.0847, 0.1484, 0.1462, 0.3220],\n",
      "        [0.3303, 0.0853, 0.1849, 0.2460, 0.1281, 0.1458, 0.1482, 0.1254, 0.1846,\n",
      "         0.1086, 0.0729, 0.1947, 0.1996],\n",
      "        [0.2502, 0.1344, 0.1669, 0.1317, 0.1404, 0.1776, 0.1456, 0.1406, 0.1290,\n",
      "         0.0640, 0.0970, 0.1753, 0.5034],\n",
      "        [0.2937, 0.0833, 0.1531, 0.1829, 0.0877, 0.1876, 0.1729, 0.1028, 0.0882,\n",
      "         0.0656, 0.0715, 0.0969, 0.3826],\n",
      "        [0.2737, 0.1855, 0.1787, 0.1279, 0.2917, 0.1108, 0.2417, 0.0960, 0.0865,\n",
      "         0.2142, 0.1128, 0.1959, 0.3438],\n",
      "        [0.4502, 0.2069, 0.2277, 0.2600, 0.1378, 0.1204, 0.5122, 0.1892, 0.1378,\n",
      "         0.3286, 0.4377, 0.4939, 0.2366],\n",
      "        [0.2384, 0.0785, 0.1714, 0.1521, 0.1440, 0.1688, 0.1301, 0.0781, 0.1130,\n",
      "         0.0692, 0.1142, 0.1774, 0.2954],\n",
      "        [0.4207, 0.0863, 0.1447, 0.1857, 0.2064, 0.2197, 0.1316, 0.1190, 0.1128,\n",
      "         0.1054, 0.1447, 0.2310, 0.3833]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<SigmoidBackward0>)\n",
      "Logits: tensor([[-0.2742, -0.1742, -1.3457,  0.2142, -0.1956, -1.4893,  0.2181, -0.2001,\n",
      "         -0.3677, -0.2517,  0.7021, -0.4907, -0.8311],\n",
      "        [-0.9492, -2.4805, -1.8438, -1.2822, -1.3936, -2.1621, -1.5225, -2.5098,\n",
      "         -1.6807, -2.9434, -2.5391, -1.5850, -0.7446],\n",
      "        [-1.3623, -2.3711, -1.7256, -1.3037, -1.9473, -1.0527, -1.9980, -2.8203,\n",
      "         -1.6895, -2.4629, -2.2871, -1.7041, -1.1924],\n",
      "        [-0.8857, -2.5605, -1.8008, -1.7109, -2.0352, -0.8638, -1.5469, -2.5098,\n",
      "         -2.1680, -2.6602, -2.8418, -1.7568, -0.6768],\n",
      "        [-0.6748, -1.9893, -1.8174, -1.2676, -1.4170, -1.5166, -2.2891, -2.0059,\n",
      "         -1.3311, -2.1699, -2.1562, -1.0332, -1.1992],\n",
      "        [-0.4150, -0.1453, -1.3223,  0.1630, -0.3044, -1.3965,  0.2712, -0.2058,\n",
      "         -0.3022, -0.3474,  0.6631, -0.4158, -0.8037],\n",
      "        [-0.9536, -2.2871, -1.9736, -1.7666, -2.1934, -1.6387, -2.2871, -2.8281,\n",
      "         -1.8809, -2.5156, -2.5430, -1.4824, -0.4536],\n",
      "        [-1.7207, -1.9834, -1.5195, -1.2871, -2.3594, -1.6289, -2.1953, -2.5625,\n",
      "         -1.9414, -2.2168, -2.3262, -1.4053, -0.7349],\n",
      "        [-0.5757, -2.0332, -1.9121, -1.1738, -1.1533, -1.8516, -1.7773, -2.0156,\n",
      "         -2.0781, -2.6074, -2.1816, -1.8027, -0.1807],\n",
      "        [-1.3877, -1.8301, -1.9160, -1.6963, -2.1816, -1.7695, -1.6650, -1.7002,\n",
      "         -1.6904, -2.4355, -2.3691, -1.7266, -0.2612],\n",
      "        [-1.2646, -2.7129, -1.9502, -1.7568, -2.0215, -1.3379, -1.7852, -2.7734,\n",
      "         -2.2402, -3.0469, -2.7090, -1.9775, -0.7979],\n",
      "        [-1.1201, -2.4102, -2.0332, -1.7998, -2.1367, -1.3408, -2.0215, -2.4336,\n",
      "         -2.3652, -2.7539, -2.7715, -1.7998, -0.8184],\n",
      "        [-0.9761, -2.4102, -1.9336, -1.5361, -1.4434, -1.3496, -1.9961, -1.8877,\n",
      "         -2.0859, -2.6406, -2.7363, -2.0137, -0.9351],\n",
      "        [ 0.0701, -1.3057, -1.2021, -1.5234, -0.7524, -1.1973, -1.2529, -1.8828,\n",
      "         -1.0205, -2.0859, -1.1377, -0.9551, -1.0244],\n",
      "        [-0.1357, -2.0488, -1.6045, -1.6143, -1.5400, -0.9819, -1.7949, -2.7734,\n",
      "         -1.6182, -2.3262, -1.8682, -0.5654, -1.9229],\n",
      "        [-1.1133, -2.0117, -1.7627, -1.8809, -2.0605, -0.9766, -1.6357, -2.4609,\n",
      "         -1.8291, -1.8740, -1.7080, -1.4941, -0.7451]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "Labels: tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "Logits shape: torch.Size([16, 13])\n",
      "Labels shape: torch.Size([16, 13])\n",
      "loss: 0.29458004236221313\n",
      "preds: tensor([[0.4319, 0.4565, 0.2065, 0.5532, 0.4512, 0.1841, 0.5542, 0.4502, 0.4092,\n",
      "         0.4375, 0.6685, 0.3796, 0.3035],\n",
      "        [0.2791, 0.0772, 0.1366, 0.2172, 0.1989, 0.1032, 0.1791, 0.0752, 0.1570,\n",
      "         0.0500, 0.0732, 0.1700, 0.3220],\n",
      "        [0.2039, 0.0854, 0.1511, 0.2135, 0.1249, 0.2588, 0.1194, 0.0562, 0.1559,\n",
      "         0.0785, 0.0922, 0.1539, 0.2328],\n",
      "        [0.2920, 0.0717, 0.1417, 0.1531, 0.1155, 0.2966, 0.1755, 0.0752, 0.1027,\n",
      "         0.0654, 0.0551, 0.1472, 0.3369],\n",
      "        [0.3374, 0.1204, 0.1398, 0.2197, 0.1952, 0.1799, 0.0920, 0.1186, 0.2090,\n",
      "         0.1025, 0.1038, 0.2625, 0.2316],\n",
      "        [0.3977, 0.4639, 0.2104, 0.5405, 0.4246, 0.1984, 0.5674, 0.4487, 0.4250,\n",
      "         0.4141, 0.6602, 0.3975, 0.3093],\n",
      "        [0.2781, 0.0922, 0.1220, 0.1460, 0.1003, 0.1626, 0.0922, 0.0558, 0.1323,\n",
      "         0.0748, 0.0729, 0.1851, 0.3884],\n",
      "        [0.1517, 0.1210, 0.1796, 0.2163, 0.0863, 0.1639, 0.1002, 0.0716, 0.1255,\n",
      "         0.0983, 0.0890, 0.1970, 0.3242],\n",
      "        [0.3599, 0.1158, 0.1288, 0.2362, 0.2399, 0.1357, 0.1447, 0.1176, 0.1113,\n",
      "         0.0687, 0.1014, 0.1415, 0.4551],\n",
      "        [0.1998, 0.1382, 0.1283, 0.1549, 0.1014, 0.1456, 0.1591, 0.1544, 0.1558,\n",
      "         0.0805, 0.0856, 0.1510, 0.4351],\n",
      "        [0.2202, 0.0622, 0.1245, 0.1472, 0.1169, 0.2079, 0.1437, 0.0588, 0.0962,\n",
      "         0.0453, 0.0624, 0.1216, 0.3105],\n",
      "        [0.2460, 0.0824, 0.1158, 0.1418, 0.1056, 0.2074, 0.1169, 0.0806, 0.0859,\n",
      "         0.0599, 0.0589, 0.1418, 0.3062],\n",
      "        [0.2737, 0.0824, 0.1263, 0.1771, 0.1910, 0.2059, 0.1196, 0.1315, 0.1105,\n",
      "         0.0666, 0.0609, 0.1178, 0.2820],\n",
      "        [0.5176, 0.2133, 0.2311, 0.1790, 0.3203, 0.2319, 0.2222, 0.1321, 0.2649,\n",
      "         0.1105, 0.2428, 0.2778, 0.2642],\n",
      "        [0.4661, 0.1142, 0.1674, 0.1660, 0.1765, 0.2725, 0.1425, 0.0588, 0.1654,\n",
      "         0.0890, 0.1338, 0.3623, 0.1276],\n",
      "        [0.2473, 0.1180, 0.1465, 0.1323, 0.1130, 0.2737, 0.1631, 0.0786, 0.1383,\n",
      "         0.1331, 0.1534, 0.1833, 0.3218]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<SigmoidBackward0>)\n",
      "Logits: tensor([[-0.6597, -2.2461, -1.9902, -1.6602, -1.8291, -1.4541, -1.8213, -2.6543,\n",
      "         -2.0664, -2.6152, -3.1602, -1.6689, -0.7026],\n",
      "        [-1.1299, -2.1289, -1.6592, -1.9766, -2.1016, -1.3730, -2.1855, -2.0645,\n",
      "         -1.9561, -2.3203, -2.0449, -2.2773, -0.1864],\n",
      "        [-1.3652, -2.3027, -1.4150, -1.7373, -2.0234, -1.1250, -2.1406, -2.3984,\n",
      "         -2.4043, -2.0840, -2.4316, -1.7109, -0.5264],\n",
      "        [-1.2500, -1.7744, -1.4609, -1.4912, -1.4902, -1.7100, -2.3867, -2.3145,\n",
      "         -1.6406, -2.2441, -2.6016, -1.8516, -0.1182],\n",
      "        [-1.8701, -2.2285, -1.4053, -1.6113, -1.7871, -1.3184, -2.3203, -2.8184,\n",
      "         -1.8281, -2.6191, -2.0508, -1.6729, -0.6597],\n",
      "        [-0.7710, -1.5176, -1.3721, -1.6895, -0.5913, -1.2627, -1.9346, -2.1855,\n",
      "         -2.1699, -2.1250, -1.5107, -1.3623, -0.5757],\n",
      "        [-1.0547, -1.6445, -1.6016, -1.5811, -0.9170, -1.2197, -1.3730, -1.2090,\n",
      "         -1.3740, -2.2031, -2.3203, -2.1465, -1.0117],\n",
      "        [-0.8506, -2.2090, -1.4199, -1.7051, -1.3877, -1.4609, -1.9863, -2.1973,\n",
      "         -2.2637, -1.9531, -1.9170, -1.4365, -1.2607],\n",
      "        [-1.2979, -2.3809, -1.9463, -1.8926, -2.1445, -1.2959, -2.3555, -2.3340,\n",
      "         -2.2324, -2.8457, -2.3574, -2.1934, -0.3315],\n",
      "        [-1.0410, -2.0410, -2.0098, -1.8291, -2.0918, -1.7891, -1.7637, -2.6250,\n",
      "         -2.2695, -2.5566, -2.3281, -2.0859, -0.6973],\n",
      "        [-0.6694, -1.7217, -0.9414, -1.1416, -1.5117, -1.0195, -1.2207, -0.8828,\n",
      "         -1.1484, -1.3555, -0.9619, -0.7988, -1.2607],\n",
      "        [-1.2744, -2.3945, -2.0703, -2.2402, -2.2012, -1.3906, -2.2422, -2.5000,\n",
      "         -2.4570, -2.8730, -2.5859, -2.0664, -0.6021],\n",
      "        [-1.0635, -2.3379, -2.3535, -1.8486, -1.8193, -0.9619, -2.0996, -2.4512,\n",
      "         -1.9365, -2.3535, -2.2578, -1.8955, -0.8042],\n",
      "        [-0.8003, -1.5273, -2.0195, -1.7061, -1.5166, -1.8115, -1.7852, -2.2383,\n",
      "         -2.0332, -2.7031, -2.2891, -1.7656, -0.5107],\n",
      "        [-1.2129, -2.6348, -2.0742, -2.0410, -2.0898, -1.3545, -2.0938, -2.4414,\n",
      "         -2.3789, -2.8750, -2.9336, -2.0586, -0.5527],\n",
      "        [-0.1964, -1.7031, -1.4775, -1.2998, -1.8457, -0.4919, -2.5098, -1.9111,\n",
      "         -1.7754, -1.4648, -1.6240, -1.7969, -1.0967]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddmmBackward0>)\n",
      "Labels: tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\n",
      "Logits shape: torch.Size([16, 13])\n",
      "Labels shape: torch.Size([16, 13])\n",
      "loss: 0.2744051516056061\n",
      "preds: tensor([[0.3408, 0.0957, 0.1202, 0.1598, 0.1383, 0.1893, 0.1393, 0.0657, 0.1124,\n",
      "         0.0682, 0.0407, 0.1586, 0.3313],\n",
      "        [0.2441, 0.1063, 0.1599, 0.1217, 0.1089, 0.2021, 0.1011, 0.1126, 0.1239,\n",
      "         0.0895, 0.1146, 0.0930, 0.4536],\n",
      "        [0.2034, 0.0909, 0.1954, 0.1497, 0.1168, 0.2451, 0.1052, 0.0833, 0.0828,\n",
      "         0.1107, 0.0808, 0.1531, 0.3713],\n",
      "        [0.2227, 0.1450, 0.1884, 0.1837, 0.1838, 0.1532, 0.0842, 0.0899, 0.1624,\n",
      "         0.0959, 0.0690, 0.1357, 0.4705],\n",
      "        [0.1335, 0.0972, 0.1970, 0.1664, 0.1434, 0.2111, 0.0895, 0.0563, 0.1384,\n",
      "         0.0679, 0.1140, 0.1581, 0.3408],\n",
      "        [0.3162, 0.1798, 0.2023, 0.1559, 0.3564, 0.2205, 0.1262, 0.1011, 0.1025,\n",
      "         0.1067, 0.1808, 0.2039, 0.3599],\n",
      "        [0.2583, 0.1619, 0.1677, 0.1707, 0.2856, 0.2280, 0.2021, 0.2299, 0.2020,\n",
      "         0.0995, 0.0895, 0.1047, 0.2666],\n",
      "        [0.2993, 0.0989, 0.1947, 0.1538, 0.1998, 0.1884, 0.1207, 0.1000, 0.0942,\n",
      "         0.1242, 0.1282, 0.1921, 0.2208],\n",
      "        [0.2145, 0.0847, 0.1249, 0.1310, 0.1049, 0.2148, 0.0866, 0.0883, 0.0969,\n",
      "         0.0549, 0.0865, 0.1003, 0.4180],\n",
      "        [0.2610, 0.1150, 0.1182, 0.1383, 0.1099, 0.1432, 0.1464, 0.0676, 0.0937,\n",
      "         0.0720, 0.0888, 0.1105, 0.3325],\n",
      "        [0.3386, 0.1516, 0.2805, 0.2421, 0.1807, 0.2651, 0.2278, 0.2925, 0.2407,\n",
      "         0.2050, 0.2766, 0.3103, 0.2208],\n",
      "        [0.2185, 0.0836, 0.1120, 0.0962, 0.0997, 0.1993, 0.0960, 0.0759, 0.0789,\n",
      "         0.0535, 0.0701, 0.1124, 0.3538],\n",
      "        [0.2566, 0.0880, 0.0868, 0.1360, 0.1395, 0.2766, 0.1091, 0.0793, 0.1260,\n",
      "         0.0868, 0.0947, 0.1306, 0.3091],\n",
      "        [0.3101, 0.1783, 0.1172, 0.1537, 0.1799, 0.1405, 0.1437, 0.0964, 0.1158,\n",
      "         0.0628, 0.0920, 0.1461, 0.3750],\n",
      "        [0.2292, 0.0670, 0.1116, 0.1150, 0.1101, 0.2051, 0.1097, 0.0801, 0.0848,\n",
      "         0.0534, 0.0505, 0.1132, 0.3652],\n",
      "        [0.4512, 0.1541, 0.1858, 0.2142, 0.1364, 0.3794, 0.0752, 0.1289, 0.1449,\n",
      "         0.1877, 0.1647, 0.1422, 0.2502]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    574\u001b[0m         )\n\u001b[0;32m--> 575\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    981\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 982\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1025\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detect_anomaly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    454\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0;31m# in automatic optimization, there can only be one optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                     \u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautomatic_optimization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, optimizer, batch_idx, kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\u001b[0m in \u001b[0;36m_optimizer_step\u001b[0;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;31m# model hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         call._call_lightning_module_hook(\n\u001b[0m\u001b[1;32m    271\u001b[0m             \u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[LightningModule]{pl_module.__class__.__name__}.{hook_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/module.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[1;32m   1301\u001b[0m         \"\"\"\n\u001b[0;32m-> 1302\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer_closure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mstep_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/strategy.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLightningModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/amp.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mMisconfigurationException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"AMP and the LBFGS optimizer are not compatible.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mclosure_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\u001b[0m in \u001b[0;36mclosure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mClosureResult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mstep_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\u001b[0m in \u001b[0;36m_training_step\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mtraining_step_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_strategy_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"training_step\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# unused hook - call anyway for backward compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[Strategy]{trainer.strategy.__class__.__name__}.{hook_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/strategy.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    390\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_redirection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"training_step\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-823aa182aaec>\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# float for BCEWithLogitsLoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Logits: {logits}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-823aa182aaec>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mcls_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-1f49d0f3ab5e>\u001b[0m in \u001b[0;36mget_embeddings\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/camembert/modeling_camembert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    903\u001b[0m         )\n\u001b[0;32m--> 904\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/camembert/modeling_camembert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    540\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    542\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/camembert/modeling_camembert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/camembert/modeling_camembert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    351\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[0;32m--> 352\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    353\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/camembert/modeling_camembert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;31m# Normalize the attention scores to probabilities.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0mattention_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   2139\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2140\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-7568de6c8625>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlinear_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainerStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRUNNING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m         call._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    540\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0m_interrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_teardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0;31m# teardown might access the stage so we reset it after\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_teardown\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1003\u001b[0m         \"\"\"This is the Trainer's internal teardown, unrelated to the `teardown` hooks in LightningModule and Callback;\n\u001b[1;32m   1004\u001b[0m         those are handled by :meth:`_call_teardown_hook`.\"\"\"\n\u001b[0;32m-> 1005\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1006\u001b[0m         \u001b[0mloop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m         \u001b[0;31m# loop should never be `None` here but it can because we don't know the trainer stage with `ddp_spawn`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/strategy.py\u001b[0m in \u001b[0;36mteardown\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \"\"\"\n\u001b[0;32m--> 532\u001b[0;31m         \u001b[0m_optimizers_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning_fabric/utilities/optimizer.py\u001b[0m in \u001b[0;36m_optimizers_to_device\u001b[0;34m(optimizers, device)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;34m\"\"\"Moves optimizer states for a sequence of optimizers to the device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0m_optimizer_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning_fabric/utilities/optimizer.py\u001b[0m in \u001b[0;36m_optimizer_to_device\u001b[0;34m(optimizer, device)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# needs it. See https://github.com/pytorch/pytorch/issues/74424\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"step\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                 \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmove_data_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning_fabric/utilities/apply_func.py\u001b[0m in \u001b[0;36mmove_data_to_device\u001b[0;34m(batch, device)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mapply_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_TransferableDataType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning_utilities/core/apply_func.py\u001b[0m in \u001b[0;36mapply_to_collection\u001b[0;34m(data, dtype, function, wrong_dtype, include_none, allow_frozen, *args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;31m# fast path for the most common cases:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# single element\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mlist\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# 1d homogeneous list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning_fabric/utilities/apply_func.py\u001b[0m in \u001b[0;36mbatch_to\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_BLOCKING_DEVICE_TYPES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"non_blocking\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mdata_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata_output\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdata_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# Train the model\n",
    "linear_trainer.fit(model, train_loader)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Total time: {end_time - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T12:24:49.569899Z",
     "iopub.status.busy": "2025-02-26T12:24:49.569526Z",
     "iopub.status.idle": "2025-02-26T12:24:49.601274Z",
     "shell.execute_reply": "2025-02-26T12:24:49.600283Z",
     "shell.execute_reply.started": "2025-02-26T12:24:49.569867Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-18bf08814031>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/memory.py\u001b[0m in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m    190\u001b[0m     \"\"\"\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_emptyCache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-02-26T11:28:19.116450Z",
     "iopub.status.idle": "2025-02-26T11:28:19.116797Z",
     "shell.execute_reply": "2025-02-26T11:28:19.116646Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "result = linear_trainer.test(model, test_loader)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Total time: {end_time - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6744969,
     "sourceId": 10858447,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6746445,
     "sourceId": 10860349,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
