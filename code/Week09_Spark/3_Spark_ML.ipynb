{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVz2eEh_7k_g"
      },
      "source": [
        "# Spark ML: Predicting Avocado Prices\n",
        "\n",
        "This notebook introduces how to train a ML model using Spark ML.  This bases on an excellent article in Towards Data Science [First Steps in Machine Learning with Apache Spark](https://towardsdatascience.com/first-steps-in-machine-learning-with-apache-spark-672fe31799a3) using [Avocado Prices dataset](https://www.kaggle.com/datasets/neuromusic/avocado-prices) in Kaggle.\n",
        "\n",
        "The objective of this model is to predict the average price of avocado given datetime, supply amounts, and region."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g89cnDJJ7k_k"
      },
      "source": [
        "## Spark Cluster Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "h4SFo0ff7k_l"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nNVSgBhY7k_n"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    !apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "    !wget -q https://dlcdn.apache.org/spark/spark-3.5.5/spark-3.5.5-bin-hadoop3.tgz\n",
        "    !tar xf spark-3.5.5-bin-hadoop3.tgz\n",
        "    !mv spark-3.5.5-bin-hadoop3 spark\n",
        "    !pip install -q findspark\n",
        "    import os\n",
        "    os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "    os.environ[\"SPARK_HOME\"] = \"/content/spark\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EYJl07v17k_n"
      },
      "outputs": [],
      "source": [
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MguOO_kv7k_o"
      },
      "outputs": [],
      "source": [
        "spark_url = 'local'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "H1HtH6hP7k_o"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "HGKtuTso7k_p"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder\\\n",
        "        .master(spark_url)\\\n",
        "        .appName('Spark SQL')\\\n",
        "        .getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQtd3eFl7k_q"
      },
      "source": [
        "## Data Preparation\n",
        "\n",
        "First, we read a csv file.  We can provide option such as delimiter and header.  We then rename the colume names to remove dot ('.') in the names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Lrmvnsmi7k_r"
      },
      "outputs": [],
      "source": [
        "path = 'avocado.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "scrolled": true,
        "id": "m8QLt2ZK7k_s"
      },
      "outputs": [],
      "source": [
        "df_avocado = spark.read.csv(path, header=True, inferSchema=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8UW1U6ps7k_s"
      },
      "outputs": [],
      "source": [
        "cols = [c.replace(' ', '_') for c in df_avocado.columns]\n",
        "df_avocado = df_avocado.toDF(*cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXHitM-T7k_s",
        "outputId": "21ed8791-62f4-449d-c6d1-7225da92f826"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Id: integer (nullable = true)\n",
            " |-- Date: date (nullable = true)\n",
            " |-- AveragePrice: double (nullable = true)\n",
            " |-- Total_Volume: double (nullable = true)\n",
            " |-- 4046: double (nullable = true)\n",
            " |-- 4225: double (nullable = true)\n",
            " |-- 4770: double (nullable = true)\n",
            " |-- Total_Bags: double (nullable = true)\n",
            " |-- Small_Bags: double (nullable = true)\n",
            " |-- Large_Bags: double (nullable = true)\n",
            " |-- XLarge_Bags: double (nullable = true)\n",
            " |-- type: string (nullable = true)\n",
            " |-- year: integer (nullable = true)\n",
            " |-- region: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_avocado.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36zfl90V7k_t"
      },
      "source": [
        "We then split data into training and testing datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "EUiv2NJY7k_t"
      },
      "outputs": [],
      "source": [
        "(df_avocado_train, df_avocado_test) = df_avocado.randomSplit([0.75, 0.25], seed=214)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_avocado_train.show(4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7Qs9rLAEHsS",
        "outputId": "564460d0-f545-45c5-878e-f65b1db78a19"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------+------------+------------+---------+---------+--------+----------+----------+----------+-----------+------------+----+----------------+\n",
            "| Id|      Date|AveragePrice|Total_Volume|     4046|     4225|    4770|Total_Bags|Small_Bags|Large_Bags|XLarge_Bags|        type|year|          region|\n",
            "+---+----------+------------+------------+---------+---------+--------+----------+----------+----------+-----------+------------+----+----------------+\n",
            "|  0|2015-12-27|        0.49|  1137707.43| 738314.8|286858.37|11642.46|  100891.8|  70749.02|  30142.78|        0.0|conventional|2015|   PhoenixTucson|\n",
            "|  0|2015-12-27|        0.71|   776404.39|451904.51|141599.36|15486.97| 167413.55| 123158.22|  33065.33|    11190.0|conventional|2015|WestTexNewMexico|\n",
            "|  0|2015-12-27|         0.8|  1020390.64|494425.64|276556.76|84912.97| 164495.27| 136560.04|   12277.7|   15657.53|conventional|2015|   DallasFtWorth|\n",
            "|  0|2015-12-27|         0.8|  2326942.14|976982.58|455203.42|86202.11| 808554.03| 722787.61|  74359.03|   11407.39|conventional|2015|      LosAngeles|\n",
            "+---+----------+------------+------------+---------+---------+--------+----------+----------+----------+-----------+------------+----+----------------+\n",
            "only showing top 4 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuqCCy2u7k_t"
      },
      "source": [
        "## Create ML Pipeline\n",
        "For this pipeline, we will create several transformers using built-in estimators/transformers.  These include:\n",
        "\n",
        "\n",
        "| SparkML Feature | Feature Type | Data Type |\n",
        "|:-----------------|:--------------:|:--------------:|\n",
        "| SQLTransformer  | Tranformer   | Numerical |\n",
        "| MinMaxScaler    | Estimator    | Numerical |\n",
        "| StandardScaler  | Estimator    | Numerical |\n",
        "| StringIndexer   | Estimator    | Categorical |\n",
        "| VectorAssembler | Transformer  | Both |\n",
        "\n",
        "Using these components, we create the following pipeline:\n",
        "\n",
        "| Pipeline Stage | SparkML Feature |\n",
        "|:----------|:----------|\n",
        "| sql_transformer | SQLTransformer |\n",
        "| month_vec_asm_transfromer | VectorAssembler |\n",
        "| month_scaler_transfromer | MinMaxScaler |\n",
        "| numerical_vec_asm_transformer | VectorAssembler |\n",
        "| std_scaler_transformer | StandardScaler |\n",
        "| str_indexer_transformer | StringIndexer |\n",
        "| categorical_vec_asm_transformer | VectorAssembler |\n",
        "| all_vec_asm_transformer | VectorAssembler |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "l9LjUO-W7k_t"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import SQLTransformer, MinMaxScaler, StandardScaler\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woTW48EP7k_t"
      },
      "source": [
        "### Numerical Feature Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YfOBMey7k_t"
      },
      "source": [
        "#### sql_transformer: numeric column selection and log-transform\n",
        "Create a transformer to select columns and log-transform some numerical columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8dXDfm-7k_t",
        "outputId": "c1eddf4d-2d50-40ce-d156-a8b4b3a68c6c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['`AveragePrice`', '`type`']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "cols = ['AveragePrice', 'type']\n",
        "cols = [f\"`{col}`\" for col in cols]\n",
        "cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWb2kdFG7k_t",
        "outputId": "1dc5f774-a6c1-40fb-86ae-6f906d6fc2f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['LOG(`4225`+1) AS `LOG_4225`',\n",
              " 'LOG(`4770`+1) AS `LOG_4770`',\n",
              " 'LOG(`Small_Bags`+1) AS `LOG_Small_Bags`',\n",
              " 'LOG(`Large_Bags`+1) AS `LOG_Large_Bags`',\n",
              " 'LOG(`XLarge_Bags`+1) AS `LOG_XLarge_Bags`']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "log_cols =  ['4225', '4770', 'Small_Bags', 'Large_Bags', 'XLarge_Bags']\n",
        "log_cols = [f\"LOG(`{col}`+1) AS `LOG_{col}`\" for col in log_cols] # logarithm, +1 in case it is 0\n",
        "log_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "9UFKSFFC7k_t",
        "outputId": "3851aab1-bebe-4812-9b43-feffd9423a9a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'SELECT`AveragePrice`, `type`, LOG(`4225`+1) AS `LOG_4225`, LOG(`4770`+1) AS `LOG_4770`, LOG(`Small_Bags`+1) AS `LOG_Small_Bags`, LOG(`Large_Bags`+1) AS `LOG_Large_Bags`, LOG(`XLarge_Bags`+1) AS `LOG_XLarge_Bags`, \\n    YEAR(__THIS__.Date)-2000 AS year, MONTH(__THIS__.Date) AS month\\n    FROM __THIS__\\n    '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "statement = f\"\"\"SELECT{', '.join(cols)}, {', '.join(log_cols)},\n",
        "    YEAR(__THIS__.Date)-2000 AS year, MONTH(__THIS__.Date) AS month\n",
        "    FROM __THIS__\n",
        "    \"\"\"\n",
        "statement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "XhAfOagu7k_t"
      },
      "outputs": [],
      "source": [
        "sql_transformer = SQLTransformer(statement=statement)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_BMxSO_7k_t",
        "outputId": "e0d2c270-69b7-4ef0-a8dd-636187a1baca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------+------------+------------+---------+---------+--------+----------+----------+----------+-----------+------------+----+----------------+\n",
            "| Id|      Date|AveragePrice|Total_Volume|     4046|     4225|    4770|Total_Bags|Small_Bags|Large_Bags|XLarge_Bags|        type|year|          region|\n",
            "+---+----------+------------+------------+---------+---------+--------+----------+----------+----------+-----------+------------+----+----------------+\n",
            "|  0|2015-12-27|        0.49|  1137707.43| 738314.8|286858.37|11642.46|  100891.8|  70749.02|  30142.78|        0.0|conventional|2015|   PhoenixTucson|\n",
            "|  0|2015-12-27|        0.71|   776404.39|451904.51|141599.36|15486.97| 167413.55| 123158.22|  33065.33|    11190.0|conventional|2015|WestTexNewMexico|\n",
            "|  0|2015-12-27|         0.8|  1020390.64|494425.64|276556.76|84912.97| 164495.27| 136560.04|   12277.7|   15657.53|conventional|2015|   DallasFtWorth|\n",
            "|  0|2015-12-27|         0.8|  2326942.14|976982.58|455203.42|86202.11| 808554.03| 722787.61|  74359.03|   11407.39|conventional|2015|      LosAngeles|\n",
            "+---+----------+------------+------------+---------+---------+--------+----------+----------+----------+-----------+------------+----+----------------+\n",
            "only showing top 4 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_avocado_train.show(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uY5m5b2C7k_u",
        "outputId": "bcf81040-0a5a-42dd-aec3-45c7ecec2764"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+------------+------------------+------------------+------------------+------------------+-----------------+----+-----+\n",
            "|AveragePrice|        type|          LOG_4225|          LOG_4770|    LOG_Small_Bags|    LOG_Large_Bags|  LOG_XLarge_Bags|year|month|\n",
            "+------------+------------+------------------+------------------+------------------+------------------+-----------------+----+-----+\n",
            "|        0.49|conventional|12.566747374652527| 9.362499927974252|11.166908098190957|10.313733879047971|              0.0|  15|   12|\n",
            "|        0.71|conventional|11.860764002611406| 9.647818872531012| 11.72123326879331| 10.40627082310141|9.322865162818028|  15|   12|\n",
            "|         0.8|conventional| 12.53017497505446|11.349393905288467|11.824526973139381| 9.415621332905047|9.658771095406955|  15|   12|\n",
            "|         0.8|conventional|13.028501871764691|11.364461534887267|13.490872079413348| 11.21667384527801|9.342104328605496|  15|   12|\n",
            "+------------+------------+------------------+------------------+------------------+------------------+-----------------+----+-----+\n",
            "only showing top 4 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sql_transformer.transform(df_avocado_train).show(4)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_avocado_train.show(4) # still the same"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYvpHBuHFJCu",
        "outputId": "bcc8006d-ba3f-477b-93e4-cfbe63036f9e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------+------------+------------+---------+---------+--------+----------+----------+----------+-----------+------------+----+----------------+\n",
            "| Id|      Date|AveragePrice|Total_Volume|     4046|     4225|    4770|Total_Bags|Small_Bags|Large_Bags|XLarge_Bags|        type|year|          region|\n",
            "+---+----------+------------+------------+---------+---------+--------+----------+----------+----------+-----------+------------+----+----------------+\n",
            "|  0|2015-12-27|        0.49|  1137707.43| 738314.8|286858.37|11642.46|  100891.8|  70749.02|  30142.78|        0.0|conventional|2015|   PhoenixTucson|\n",
            "|  0|2015-12-27|        0.71|   776404.39|451904.51|141599.36|15486.97| 167413.55| 123158.22|  33065.33|    11190.0|conventional|2015|WestTexNewMexico|\n",
            "|  0|2015-12-27|         0.8|  1020390.64|494425.64|276556.76|84912.97| 164495.27| 136560.04|   12277.7|   15657.53|conventional|2015|   DallasFtWorth|\n",
            "|  0|2015-12-27|         0.8|  2326942.14|976982.58|455203.42|86202.11| 808554.03| 722787.61|  74359.03|   11407.39|conventional|2015|      LosAngeles|\n",
            "+---+----------+------------+------------+---------+---------+--------+----------+----------+----------+-----------+------------+----+----------------+\n",
            "only showing top 4 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuF7-42w7k_u"
      },
      "source": [
        "#### month_vec_asm_transformer / month_scaler_transformer: create month vectors and normalize their values\n",
        "\n",
        "After using SQLTransformer, we then tranform *'month'* column into month vector and then normalize their values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apg_YuE-7k_u",
        "outputId": "a997ba24-c053-4b23-b5ae-2bdf424799c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+------------+------------------+------------------+------------------+------------------+-----------------+----+-----+---------+\n",
            "|AveragePrice|        type|          LOG_4225|          LOG_4770|    LOG_Small_Bags|    LOG_Large_Bags|  LOG_XLarge_Bags|year|month|month_vec|\n",
            "+------------+------------+------------------+------------------+------------------+------------------+-----------------+----+-----+---------+\n",
            "|        0.49|conventional|12.566747374652527| 9.362499927974252|11.166908098190957|10.313733879047971|              0.0|  15|   12|   [12.0]|\n",
            "|        0.71|conventional|11.860764002611406| 9.647818872531012| 11.72123326879331| 10.40627082310141|9.322865162818028|  15|   12|   [12.0]|\n",
            "|         0.8|conventional| 12.53017497505446|11.349393905288467|11.824526973139381| 9.415621332905047|9.658771095406955|  15|   12|   [12.0]|\n",
            "|         0.8|conventional|13.028501871764691|11.364461534887267|13.490872079413348| 11.21667384527801|9.342104328605496|  15|   12|   [12.0]|\n",
            "+------------+------------+------------------+------------------+------------------+------------------+-----------------+----+-----+---------+\n",
            "only showing top 4 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "month_vec_asm_transformer = VectorAssembler(inputCols=['month'], outputCol='month_vec')\n",
        "\n",
        "df_avocado_month_ass = month_vec_asm_transformer.transform(sql_transformer.transform(df_avocado_train))\n",
        "df_avocado_month_ass.show(4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lELUkd2v7k_u"
      },
      "source": [
        "Create a transformer that normalizes month vector using an estimator, *\"MinMaxScaler\"*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9Rvgikd7k_u",
        "outputId": "3cf6dc2c-6b57-43f7-8ec1-d34c3d6a10c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---------+--------------------+\n",
            "|month|month_vec|        month_scaled|\n",
            "+-----+---------+--------------------+\n",
            "|    2|    [2.0]|[0.09090909090909...|\n",
            "|    2|    [2.0]|[0.09090909090909...|\n",
            "|    2|    [2.0]|[0.09090909090909...|\n",
            "|    2|    [2.0]|[0.09090909090909...|\n",
            "|    2|    [2.0]|[0.09090909090909...|\n",
            "|    2|    [2.0]|[0.09090909090909...|\n",
            "|    2|    [2.0]|[0.09090909090909...|\n",
            "|    2|    [2.0]|[0.09090909090909...|\n",
            "|    2|    [2.0]|[0.09090909090909...|\n",
            "|    2|    [2.0]|[0.09090909090909...|\n",
            "+-----+---------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "month_scaler_estimator = MinMaxScaler(inputCol='month_vec', outputCol='month_scaled')\n",
        "month_scaler_transformer = month_scaler_estimator.fit(df_avocado_month_ass)\n",
        "\n",
        "month_scaler_transformer.transform(df_avocado_month_ass)\\\n",
        "    .select( ['month', 'month_vec', 'month_scaled'] )\\\n",
        "    .where(df_avocado_month_ass.month == 2).show(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpbPfrDf7k_u"
      },
      "source": [
        "#### numerical_vec_asm_transformer/std_scaler_transformer : assemble numerical features vector and scale all numerical features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCwBEv4s7k_u",
        "outputId": "eff58e22-5a9d-42cb-b208-a4d5a01721a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------------+------------------+--------------------+\n",
            "|year|month_scaled|          LOG_4225|        features_num|\n",
            "+----+------------+------------------+--------------------+\n",
            "|  15|       [1.0]|12.566747374652527|[15.0,1.0,12.5667...|\n",
            "|  15|       [1.0]|11.860764002611406|[15.0,1.0,11.8607...|\n",
            "|  15|       [1.0]| 12.53017497505446|[15.0,1.0,12.5301...|\n",
            "|  15|       [1.0]|13.028501871764691|[15.0,1.0,13.0285...|\n",
            "+----+------------+------------------+--------------------+\n",
            "only showing top 4 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "numerical_vec_asm_transformer = VectorAssembler(\n",
        "    inputCols=[\n",
        "      'year', 'month_scaled', 'LOG_4225',\n",
        "      'LOG_4770', 'LOG_Small_Bags',\n",
        "      'LOG_Large_Bags', 'LOG_XLarge_Bags'\n",
        "    ],\n",
        "    outputCol='features_num'\n",
        ")\n",
        "df_avocado_numerical = numerical_vec_asm_transformer.transform(month_scaler_transformer.transform(df_avocado_month_ass))\n",
        "df_avocado_numerical.select('year', 'month_scaled', 'LOG_4225','features_num').show(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAja4qkT7k_u",
        "outputId": "4020fe9e-ca1d-4cfa-9299-786ddeafabdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|features_scaled                                                                                                                         |\n",
            "+----------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|[-1.2177154955881637,1.6482225355667333,0.9527463109714546,1.0269649008115518,0.5657377199959452,0.8334134211814762,-0.6436162273445295]|\n",
            "|[-1.2177154955881637,1.6482225355667333,0.7058305701685025,1.0954357394643428,0.7803295242390127,0.8574417380503548,2.012648481596976]  |\n",
            "|[-1.2177154955881637,1.6482225355667333,0.9399552148956506,1.5037797059140563,0.8203168521795554,0.6002078289352569,2.1083545825302594] |\n",
            "|[-1.2177154955881637,1.6482225355667333,1.1142436751287843,1.5073956355774096,1.4653967110976907,1.0678725104034048,2.0181300922626053] |\n",
            "|[-1.2177154955881637,1.6482225355667333,1.4787880607250015,1.8713767178927097,1.4321533934378963,1.1582533794554424,2.5870627060190463] |\n",
            "+----------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Scaling the numerical features using a StandardScaler\n",
        "std_scaler_estimator = StandardScaler(\n",
        "    inputCol=\"features_num\",\n",
        "    outputCol=\"features_scaled\",\n",
        "    withStd=True,\n",
        "    withMean=True\n",
        ")\n",
        "\n",
        "std_scaler_transformer = std_scaler_estimator.fit(df_avocado_numerical)\n",
        "std_scaler_transformer.transform(df_avocado_numerical).select(['features_scaled']).show(5, False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmER3BPo7k_v"
      },
      "source": [
        "### Categorical Feature Transformers\n",
        "Transforming categorical features usually involve text transformation e.g. one-hot encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVSruiZT7k_v"
      },
      "source": [
        "### str_indexer_transformer: encoding categorical data\n",
        "We create a transformer using \"StringIndexer\", which is an estimator that produces StringIndexerModel.  This is similar to perform one-hot encoder on the categorical data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uP62OzDf7k_v",
        "outputId": "aa573ef3-9787-4bf9-8f6e-6922e94550d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+----------+\n",
            "|        type|type_index|\n",
            "+------------+----------+\n",
            "|conventional|       0.0|\n",
            "|conventional|       0.0|\n",
            "|conventional|       0.0|\n",
            "|conventional|       0.0|\n",
            "+------------+----------+\n",
            "only showing top 4 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "type_indexer_estimator = StringIndexer(inputCol=\"type\", outputCol=\"type_index\")\n",
        "type_indexer_transformer = type_indexer_estimator.fit(df_avocado_train)\n",
        "\n",
        "type_indexer_transformer.transform(df_avocado_train)\\\n",
        "  .select( [\"type\", \"type_index\"] ).show(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrtUGuQb7k_v",
        "outputId": "7eaf4f82-57ea-4a14-9206-f5a9db5228ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+----------+------------+\n",
            "|        type|type_index|features_cat|\n",
            "+------------+----------+------------+\n",
            "|conventional|       0.0|       [0.0]|\n",
            "|conventional|       0.0|       [0.0]|\n",
            "|conventional|       0.0|       [0.0]|\n",
            "|conventional|       0.0|       [0.0]|\n",
            "+------------+----------+------------+\n",
            "only showing top 4 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "categorical_vec_asm_transformer = VectorAssembler(\n",
        "    inputCols=['type_index'],\n",
        "    outputCol='features_cat'\n",
        ")\n",
        "categorical_vec_asm_transformer.transform(\n",
        "    type_indexer_transformer.transform(df_avocado_train)\n",
        ").select('type', 'type_index', 'features_cat').show(4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITXwf68j7k_v"
      },
      "source": [
        "### Create a pipeline: merge both numerical and categorical features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "OKKJRfKN7k_w"
      },
      "outputs": [],
      "source": [
        "all_vec_asm_transformer = VectorAssembler(\n",
        "        inputCols=['features_scaled', 'features_cat'],\n",
        "        outputCol='features')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "9kdCk7je7k_w"
      },
      "outputs": [],
      "source": [
        "feature_prep_pipeline = Pipeline(stages=[sql_transformer, month_vec_asm_transformer,\n",
        "                                         month_scaler_transformer,\n",
        "                                         numerical_vec_asm_transformer,\n",
        "                                         std_scaler_transformer,\n",
        "                                         type_indexer_transformer,\n",
        "                                         categorical_vec_asm_transformer,\n",
        "                                         all_vec_asm_transformer])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "GwJd2ePB7k_9"
      },
      "outputs": [],
      "source": [
        "pipeline_model = feature_prep_pipeline.fit(df_avocado_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vV5I9P17k_9"
      },
      "source": [
        "### Transform training dataset using the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "Lu7HQwNe7k_9"
      },
      "outputs": [],
      "source": [
        "df_avocado_train_transformed = pipeline_model.transform(df_avocado_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyod0IUq7k_9",
        "outputId": "f989ade6-8825-4e98-fd93-47371da2d66d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------------------------------------------------------------------------------------------+------------+\n",
            "|features                                                                                                                                    |AveragePrice|\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------+------------+\n",
            "|[-1.2177154955881637,1.6482225355667333,0.9527463109714546,1.0269649008115518,0.5657377199959452,0.8334134211814762,-0.6436162273445295,0.0]|0.49        |\n",
            "|[-1.2177154955881637,1.6482225355667333,0.7058305701685025,1.0954357394643428,0.7803295242390127,0.8574417380503548,2.012648481596976,0.0]  |0.71        |\n",
            "|[-1.2177154955881637,1.6482225355667333,0.9399552148956506,1.5037797059140563,0.8203168521795554,0.6002078289352569,2.1083545825302594,0.0] |0.8         |\n",
            "|[-1.2177154955881637,1.6482225355667333,1.1142436751287843,1.5073956355774096,1.4653967110976907,1.0678725104034048,2.0181300922626053,0.0] |0.8         |\n",
            "|[-1.2177154955881637,1.6482225355667333,1.4787880607250015,1.8713767178927097,1.4321533934378963,1.1582533794554424,2.5870627060190463,0.0] |0.81        |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_avocado_train_transformed.select('features', 'AveragePrice').show(5, False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JVPwmVj7k_9"
      },
      "source": [
        "## Model Training\n",
        "We will train a linear regression model using transformed training dataset.  In order to do this, we will have to fit an estimator, *'LinearRegression'* to transformed training dataset to create a model, which is a *transformer*, that can be used to test the testing dataset.\n",
        "\n",
        "Note that this example focuses on how to create a pipeline.  Spark also provides hyperparameter tuning function.  However, this is out of the scope of this example.  Please refer to [First Steps in Machine Learning with Apache Spark](https://towardsdatascience.com/first-steps-in-machine-learning-with-apache-spark-672fe31799a3) for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "S4MY_qnu7k_9"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.regression import LinearRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "Im0DCj6B7k_-"
      },
      "outputs": [],
      "source": [
        "linear_reg_estimator = LinearRegression(\n",
        "    featuresCol='features',\n",
        "    labelCol='AveragePrice',\n",
        "    predictionCol='prediction',\n",
        "\n",
        "    # Hyperaparameters\n",
        "    maxIter=1000,\n",
        "    regParam=0.3,       # Regularization\n",
        "    elasticNetParam=0.8 # Regularization mixing parameter. 1 for L1, 0 for L2.\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "scrolled": true,
        "id": "xx0v8aFo7k_-"
      },
      "outputs": [],
      "source": [
        "linear_reg_model = linear_reg_estimator.fit(df_avocado_train_transformed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOdS438a7k_-"
      },
      "source": [
        "### Inference the testing dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ewl1y__o7k_-",
        "outputId": "9442d58f-0b8a-4dd6-a66a-84f31dc7913e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+------------------+\n",
            "|AveragePrice|prediction        |\n",
            "+------------+------------------+\n",
            "|0.8         |1.4003505112793717|\n",
            "|0.95        |1.4003505112793717|\n",
            "|0.98        |1.4003505112793717|\n",
            "|1.07        |1.4116333911023091|\n",
            "|1.39        |1.4116333911023091|\n",
            "+------------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_avocado_train_pred = linear_reg_model.transform(df_avocado_train_transformed)\n",
        "df_avocado_train_pred.select(\n",
        "  ['AveragePrice', 'prediction']\n",
        ").sample(False, 0.1, 0).show(5, False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QguTLULk7k_-"
      },
      "source": [
        "## Model Evaluation\n",
        "Spark provides several evaluation functions.  We will have to select the right one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "PazlXogd7k_-"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "mSQBASM87k_-"
      },
      "outputs": [],
      "source": [
        "reg_eval = RegressionEvaluator(\n",
        "    labelCol='AveragePrice',\n",
        "    predictionCol='prediction',\n",
        "    metricName='rmse' # Root mean squared error\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imag_6gS7k_-",
        "outputId": "7ef91a74-db7f-4dc5-bfee-91282214ae79"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3978489578943717"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "reg_eval.evaluate(df_avocado_train_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whLM2iUH7k__"
      },
      "source": [
        "## THE END"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "JioG59Bv7k__"
      },
      "outputs": [],
      "source": [
        "spark.stop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjVWwpSl7k__"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}